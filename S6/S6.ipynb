{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "S6_(1)_(2).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tusharkanta/ML_DL/blob/eva/S6/S6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aO-7t1Y7-hV4",
        "colab_type": "text"
      },
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scXmaoqkTEoV",
        "colab_type": "text"
      },
      "source": [
        "Target:\n",
        "\n",
        "Kept the model same as previous as the parameters has hit 9904. Reduced batch size from 32 to 24, changed learning rate from 0.01 to 0.008 and changed random roation param back to -7,7. Result: Parameters: 9,904 Best Train Accuracy: 98.86 Best Test Accuracy: 99.42 Analysis: Validation accuracy has improved and remained quite consistent (does not fluctuate rapidly)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kH16rnZ7wt_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ky3f_Odl-7um",
        "colab_type": "text"
      },
      "source": [
        "## Data Transformations\n",
        "\n",
        "We first start with defining our data transformations. We need to think what our data is and how can we augment it to correct represent images which it might not see otherwise. \n",
        "\n",
        "Here is the list of all the transformations which come pre-built with PyTorch\n",
        "\n",
        "1.   Compose\n",
        "2.   ToTensor\n",
        "3.   ToPILImage\n",
        "4. Normalize\n",
        "5. Resize\n",
        "6. Scale\n",
        "7. CenterCrop\n",
        "8. Pad\n",
        "9. Lambda\n",
        "10. RandomApply\n",
        "11. RandomChoice\n",
        "12. RandomOrder\n",
        "13. RandomCrop\n",
        "14. RandomHorizontalFlip\n",
        "15. RandomVerticalFlip\n",
        "16. RandomResizedCrop\n",
        "17. RandomSizedCrop\n",
        "18. FiveCrop\n",
        "19. TenCrop\n",
        "20. LinearTransformation\n",
        "21. ColorJitter\n",
        "22. RandomRotation\n",
        "23. RandomAffine\n",
        "24. Grayscale\n",
        "25. RandomGrayscale\n",
        "26. RandomPerspective\n",
        "27. RandomErasing\n",
        "\n",
        "You can read more about them [here](https://pytorch.org/docs/stable/_modules/torchvision/transforms/transforms.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YtssFUKb-jqx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train Phase transformations\n",
        "train_transforms = transforms.Compose([\n",
        "                                      #  transforms.Resize((28, 28)),\n",
        "                                       #transforms.ColorJitter(brightness=0.10, contrast=0.1, saturation=0.10, hue=0.1),\n",
        "                                       transforms.RandomRotation((-7.0, 7.0), fill=(1,)),\n",
        "                                       transforms.ToTensor(),\n",
        "                                       transforms.Normalize((0.1307,), (0.3081,)) # The mean and std have to be sequences (e.g., tuples), therefore you should add a comma after the values. \n",
        "                                       # Note the difference between (0.1307) and (0.1307,)\n",
        "                                       ])\n",
        "\n",
        "# Test Phase transformations\n",
        "test_transforms = transforms.Compose([\n",
        "                                      #  transforms.Resize((28, 28)),\n",
        "                                      #  transforms.ColorJitter(brightness=0.10, contrast=0.1, saturation=0.10, hue=0.1),\n",
        "                                       transforms.ToTensor(),\n",
        "                                       transforms.Normalize((0.1307,), (0.3081,))\n",
        "                                       ])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQciFYo2B1mO",
        "colab_type": "text"
      },
      "source": [
        "# Dataset and Creating Train/Test Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4A84rlfDA23",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = datasets.MNIST('./data', train=True, download=True, transform=train_transforms)\n",
        "test = datasets.MNIST('./data', train=False, download=True, transform=test_transforms)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgldp_3-Dn0c",
        "colab_type": "text"
      },
      "source": [
        "# Dataloader Arguments & Test/Train Dataloaders\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8OLDR79DrHG",
        "colab_type": "code",
        "outputId": "3ca225a7-4e0f-4f6a-d0fb-bed557e91e82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "SEED = 1\n",
        "\n",
        "# CUDA?\n",
        "cuda = torch.cuda.is_available()\n",
        "print(\"CUDA Available?\", cuda)\n",
        "\n",
        "# For reproducibility\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "if cuda:\n",
        "    torch.cuda.manual_seed(SEED)\n",
        "\n",
        "# dataloader arguments - something you'll fetch these from cmdprmt\n",
        "dataloader_args = dict(shuffle=True, batch_size=128, num_workers=4, pin_memory=True) if cuda else dict(shuffle=True, batch_size=16)\n",
        "\n",
        "# train dataloader\n",
        "train_loader = torch.utils.data.DataLoader(train, **dataloader_args)\n",
        "\n",
        "# test dataloader\n",
        "test_loader = torch.utils.data.DataLoader(test, **dataloader_args)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CUDA Available? True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-TFjoFekE_va",
        "colab_type": "text"
      },
      "source": [
        "# Data Statistics\n",
        "\n",
        "It is important to know your data very well. Let's check some of the statistics around our data and how it actually looks like"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWZPPo3yEHDW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7l9lNaWYKuik",
        "colab_type": "text"
      },
      "source": [
        "## MORE\n",
        "\n",
        "It is important that we view as many images as possible. This is required to get some idea on image augmentation later on"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXXAg8hbK16u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JF5-8_I3G6ix",
        "colab_type": "text"
      },
      "source": [
        "# How did we get those mean and std values which we used above?\n",
        "\n",
        "Let's run a small experiment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yooPHm_aFc5A",
        "colab_type": "code",
        "outputId": "1accb904-318c-4e6c-d11d-c15c7576f95d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "# simple transform\n",
        "simple_transforms = transforms.Compose([\n",
        "                                      #  transforms.Resize((28, 28)),\n",
        "                                      #  transforms.ColorJitter(brightness=0.10, contrast=0.1, saturation=0.10, hue=0.1),\n",
        "                                       \n",
        "                                       transforms.ToTensor(),\n",
        "                                      #  transforms.Normalize((0.1307,), (0.3081,)) # The mean and std have to be sequences (e.g., tuples), therefore you should add a comma after the values. \n",
        "                                       # Note the difference between (0.1307) and (0.1307,)\n",
        "                                       ])\n",
        "exp = datasets.MNIST('./data', train=True, download=True, transform=simple_transforms)\n",
        "exp_data = exp.train_data\n",
        "exp_data = exp.transform(exp_data.numpy())\n",
        "\n",
        "print('[Train]')\n",
        "print(' - Numpy Shape:', exp.train_data.cpu().numpy().shape)\n",
        "print(' - Tensor Shape:', exp.train_data.size())\n",
        "print(' - min:', torch.min(exp_data))\n",
        "print(' - max:', torch.max(exp_data))\n",
        "print(' - mean:', torch.mean(exp_data))\n",
        "print(' - std:', torch.std(exp_data))\n",
        "print(' - var:', torch.var(exp_data))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:55: UserWarning: train_data has been renamed data\n",
            "  warnings.warn(\"train_data has been renamed data\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[Train]\n",
            " - Numpy Shape: (60000, 28, 28)\n",
            " - Tensor Shape: torch.Size([60000, 28, 28])\n",
            " - min: tensor(0.)\n",
            " - max: tensor(1.)\n",
            " - mean: tensor(0.1305)\n",
            " - std: tensor(0.3081)\n",
            " - var: tensor(0.0949)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubQL3H6RJL3h",
        "colab_type": "text"
      },
      "source": [
        "# The model\n",
        "Let's start with the model we first saw"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FXQlB9kH1ov",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn.functional as F\n",
        "dropout_value = 0.1\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        # Input Block\n",
        "        self.convblock1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=1, out_channels=16, kernel_size=(3, 3), padding=0, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.Dropout(dropout_value)\n",
        "        ) # output_size = 26*26*16 RF=3\n",
        "\n",
        "        # CONVOLUTION BLOCK 1\n",
        "        self.convblock2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=16, out_channels=16, kernel_size=(3, 3), padding=0, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.Dropout(dropout_value)\n",
        "        ) # output_size = 24*24*16  RF=5\n",
        "\n",
        "        # TRANSITION BLOCK 1\n",
        "         # output_size = 24\n",
        "        self.convblock3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=16, out_channels=8, kernel_size=(1, 1), padding=0, bias=False),\n",
        "        ) # output_size = 24*24*8  RF=5\n",
        "        self.pool1 = nn.MaxPool2d(2, 2) # output_size = 12*12*8  RF=6\n",
        "        \n",
        "\n",
        "        # CONVOLUTION BLOCK 2\n",
        "        self.convblock4 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=8, out_channels=16, kernel_size=(3, 3), padding=0, bias=False),\n",
        "            nn.ReLU(),            \n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.Dropout(dropout_value)\n",
        "        ) # output_size = 10*10*16  RF=10\n",
        "        self.convblock5 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=16, out_channels=16, kernel_size=(3, 3), padding=0, bias=False),\n",
        "            nn.ReLU(),            \n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.Dropout(dropout_value)\n",
        "        ) # output_size = 8*8*16  RF=14\n",
        "        self.convblock6 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=16, out_channels=24, kernel_size=(3, 3), padding=0, bias=False),\n",
        "            nn.ReLU(),            \n",
        "            nn.BatchNorm2d(24),\n",
        "            nn.Dropout(dropout_value)\n",
        "        ) # output_size = 6*6*24  RF=18\n",
        "        #self.convblock7 = nn.Sequential(\n",
        "         #   nn.Conv2d(in_channels=16, out_channels=16, kernel_size=(3, 3), padding=1, bias=False),\n",
        "          #  nn.ReLU(),            \n",
        "           # nn.BatchNorm2d(16),\n",
        "            #nn.Dropout(dropout_value)\n",
        "        #) # output_size = 6\n",
        "        \n",
        "        # OUTPUT BLOCK\n",
        "        self.gap = nn.Sequential(\n",
        "            nn.AvgPool2d(kernel_size=6)\n",
        "        ) # output_size = 1*1*24  RF=28\n",
        "\n",
        "        self.convblock8 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=24, out_channels=10, kernel_size=(1, 1), padding=0, bias=False),\n",
        "            # nn.BatchNorm2d(10),\n",
        "            # nn.ReLU(),\n",
        "            # nn.Dropout(dropout_value)\n",
        "        ) # output_size = 1*1*10  RF=28\n",
        "\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout_value)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.convblock1(x)\n",
        "        x = self.convblock2(x)\n",
        "        x = self.convblock3(x)\n",
        "        x = self.pool1(x)\n",
        "        x = self.convblock4(x)\n",
        "        x = self.convblock5(x)\n",
        "        x = self.convblock6(x)\n",
        "        #x = self.convblock7(x)\n",
        "        x = self.gap(x)        \n",
        "        x = self.convblock8(x)\n",
        "\n",
        "        x = x.view(-1, 10)\n",
        "        return F.log_softmax(x, dim=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3-vp8X9LCWo",
        "colab_type": "text"
      },
      "source": [
        "# Model Params\n",
        "Can't emphasize on how important viewing Model Summary is. \n",
        "Unfortunately, there is no in-built model visualizer, so we have to take external help"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5skB97zIJQQe",
        "colab_type": "code",
        "outputId": "d4497cdf-d96a-4088-b2b4-4996dce8868e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        }
      },
      "source": [
        "!pip install torchsummary\n",
        "from torchsummary import summary\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "print(device)\n",
        "model = Net().to(device)\n",
        "summary(model, input_size=(1, 28, 28))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.6/dist-packages (1.5.1)\n",
            "cuda\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 16, 26, 26]             144\n",
            "              ReLU-2           [-1, 16, 26, 26]               0\n",
            "       BatchNorm2d-3           [-1, 16, 26, 26]              32\n",
            "           Dropout-4           [-1, 16, 26, 26]               0\n",
            "            Conv2d-5           [-1, 16, 24, 24]           2,304\n",
            "              ReLU-6           [-1, 16, 24, 24]               0\n",
            "       BatchNorm2d-7           [-1, 16, 24, 24]              32\n",
            "           Dropout-8           [-1, 16, 24, 24]               0\n",
            "            Conv2d-9            [-1, 8, 24, 24]             128\n",
            "        MaxPool2d-10            [-1, 8, 12, 12]               0\n",
            "           Conv2d-11           [-1, 16, 10, 10]           1,152\n",
            "             ReLU-12           [-1, 16, 10, 10]               0\n",
            "      BatchNorm2d-13           [-1, 16, 10, 10]              32\n",
            "          Dropout-14           [-1, 16, 10, 10]               0\n",
            "           Conv2d-15             [-1, 16, 8, 8]           2,304\n",
            "             ReLU-16             [-1, 16, 8, 8]               0\n",
            "      BatchNorm2d-17             [-1, 16, 8, 8]              32\n",
            "          Dropout-18             [-1, 16, 8, 8]               0\n",
            "           Conv2d-19             [-1, 24, 6, 6]           3,456\n",
            "             ReLU-20             [-1, 24, 6, 6]               0\n",
            "      BatchNorm2d-21             [-1, 24, 6, 6]              48\n",
            "          Dropout-22             [-1, 24, 6, 6]               0\n",
            "        AvgPool2d-23             [-1, 24, 1, 1]               0\n",
            "           Conv2d-24             [-1, 10, 1, 1]             240\n",
            "================================================================\n",
            "Total params: 9,904\n",
            "Trainable params: 9,904\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.76\n",
            "Params size (MB): 0.04\n",
            "Estimated Total Size (MB): 0.80\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aV_OBqYN0tTn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "train_losses_normal = []\n",
        "test_losses_normal = []\n",
        "train_acc_normal = []\n",
        "test_acc_normal = []\n",
        "\n",
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "  model.train()\n",
        "  pbar = tqdm(train_loader)\n",
        "  correct = 0\n",
        "  processed = 0\n",
        "  for batch_idx, (data, target) in enumerate(pbar):\n",
        "    # get samples\n",
        "    data, target = data.to(device), target.to(device)\n",
        "\n",
        "    # Init\n",
        "    optimizer.zero_grad()\n",
        "    # In PyTorch, we need to set the gradients to zero before starting to do backpropragation because PyTorch accumulates the gradients on subsequent backward passes. \n",
        "    # Because of this, when you start your training loop, ideally you should zero out the gradients so that you do the parameter update correctly.\n",
        "\n",
        "    # Predict\n",
        "    y_pred = model(data)\n",
        "\n",
        "    # Calculate loss\n",
        "    loss = F.nll_loss(y_pred, target)\n",
        "    \n",
        "    train_losses_normal.append(loss)\n",
        "\n",
        "    # Backpropagation\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Update pbar-tqdm\n",
        "    \n",
        "    pred = y_pred.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "    correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "    processed += len(data)\n",
        "\n",
        "    pbar.set_description(desc= f'Loss={loss.item()} Accuracy={100*correct/processed:0.2f}')\n",
        "    train_acc_normal.append(100*correct/processed)\n",
        "\n",
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    test_losses_normal.append(test_loss)\n",
        "\n",
        "    print('\\nTest set: Avg loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))\n",
        "    \n",
        "    test_acc_normal.append(100. * correct / len(test_loader.dataset))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8x9viLZZ18L9",
        "colab_type": "code",
        "outputId": "326c325a-c56d-4a28-ac24-85317b5368c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model =  Net().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.008, momentum=0.9)\n",
        "EPOCHS = 40\n",
        "for epoch in range(EPOCHS):\n",
        "    print(\"EPOCH:\", epoch)\n",
        "    train(model, device, train_loader, optimizer, epoch)\n",
        "    test(model, device, test_loader)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "EPOCH: 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.21615678071975708 Accuracy=85.89: 100%|██████████| 469/469 [00:12<00:00, 36.41it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.1093, Accuracy: 9706/10000 (97.06%)\n",
            "\n",
            "EPOCH: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.07952123135328293 Accuracy=97.06: 100%|██████████| 469/469 [00:13<00:00, 41.01it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0750, Accuracy: 9776/10000 (97.76%)\n",
            "\n",
            "EPOCH: 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.10465573519468307 Accuracy=97.82: 100%|██████████| 469/469 [00:13<00:00, 35.55it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0447, Accuracy: 9878/10000 (98.78%)\n",
            "\n",
            "EPOCH: 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.0464821420609951 Accuracy=98.10: 100%|██████████| 469/469 [00:12<00:00, 36.43it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0426, Accuracy: 9870/10000 (98.70%)\n",
            "\n",
            "EPOCH: 4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.06591516733169556 Accuracy=98.38: 100%|██████████| 469/469 [00:12<00:00, 37.85it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0341, Accuracy: 9892/10000 (98.92%)\n",
            "\n",
            "EPOCH: 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.0569625049829483 Accuracy=98.47: 100%|██████████| 469/469 [00:13<00:00, 36.07it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0306, Accuracy: 9903/10000 (99.03%)\n",
            "\n",
            "EPOCH: 6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.06781316548585892 Accuracy=98.49: 100%|██████████| 469/469 [00:12<00:00, 37.22it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0347, Accuracy: 9882/10000 (98.82%)\n",
            "\n",
            "EPOCH: 7\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.013681049458682537 Accuracy=98.65: 100%|██████████| 469/469 [00:12<00:00, 37.15it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0264, Accuracy: 9917/10000 (99.17%)\n",
            "\n",
            "EPOCH: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.011867533437907696 Accuracy=98.72: 100%|██████████| 469/469 [00:12<00:00, 37.53it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0254, Accuracy: 9919/10000 (99.19%)\n",
            "\n",
            "EPOCH: 9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.03546585515141487 Accuracy=98.86: 100%|██████████| 469/469 [00:12<00:00, 43.99it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0261, Accuracy: 9918/10000 (99.18%)\n",
            "\n",
            "EPOCH: 10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.02320083975791931 Accuracy=98.79: 100%|██████████| 469/469 [00:13<00:00, 35.88it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0251, Accuracy: 9923/10000 (99.23%)\n",
            "\n",
            "EPOCH: 11\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.01254454255104065 Accuracy=98.86: 100%|██████████| 469/469 [00:13<00:00, 35.61it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0253, Accuracy: 9924/10000 (99.24%)\n",
            "\n",
            "EPOCH: 12\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.008824576623737812 Accuracy=98.95: 100%|██████████| 469/469 [00:12<00:00, 36.68it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0235, Accuracy: 9926/10000 (99.26%)\n",
            "\n",
            "EPOCH: 13\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.03536854684352875 Accuracy=98.88: 100%|██████████| 469/469 [00:12<00:00, 36.50it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0222, Accuracy: 9928/10000 (99.28%)\n",
            "\n",
            "EPOCH: 14\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.013327042572200298 Accuracy=98.96: 100%|██████████| 469/469 [00:13<00:00, 35.41it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0256, Accuracy: 9914/10000 (99.14%)\n",
            "\n",
            "EPOCH: 15\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.031449202448129654 Accuracy=98.95: 100%|██████████| 469/469 [00:13<00:00, 35.97it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0221, Accuracy: 9930/10000 (99.30%)\n",
            "\n",
            "EPOCH: 16\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.005742495413869619 Accuracy=99.05: 100%|██████████| 469/469 [00:13<00:00, 35.44it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0255, Accuracy: 9925/10000 (99.25%)\n",
            "\n",
            "EPOCH: 17\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.06246692314743996 Accuracy=99.02: 100%|██████████| 469/469 [00:12<00:00, 36.98it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0217, Accuracy: 9930/10000 (99.30%)\n",
            "\n",
            "EPOCH: 18\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.046821847558021545 Accuracy=99.03: 100%|██████████| 469/469 [00:13<00:00, 35.41it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0212, Accuracy: 9930/10000 (99.30%)\n",
            "\n",
            "EPOCH: 19\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.016451403498649597 Accuracy=99.03: 100%|██████████| 469/469 [00:13<00:00, 36.06it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0203, Accuracy: 9940/10000 (99.40%)\n",
            "\n",
            "EPOCH: 20\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.036493685096502304 Accuracy=99.05: 100%|██████████| 469/469 [00:12<00:00, 36.18it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0204, Accuracy: 9933/10000 (99.33%)\n",
            "\n",
            "EPOCH: 21\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.024160360917448997 Accuracy=99.11: 100%|██████████| 469/469 [00:12<00:00, 37.58it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0202, Accuracy: 9931/10000 (99.31%)\n",
            "\n",
            "EPOCH: 22\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.026775801554322243 Accuracy=99.12: 100%|██████████| 469/469 [00:12<00:00, 36.31it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0184, Accuracy: 9939/10000 (99.39%)\n",
            "\n",
            "EPOCH: 23\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.01784740947186947 Accuracy=99.13: 100%|██████████| 469/469 [00:12<00:00, 38.04it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0182, Accuracy: 9942/10000 (99.42%)\n",
            "\n",
            "EPOCH: 24\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.11699333041906357 Accuracy=99.13: 100%|██████████| 469/469 [00:12<00:00, 37.98it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0190, Accuracy: 9936/10000 (99.36%)\n",
            "\n",
            "EPOCH: 25\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.009977285750210285 Accuracy=99.17: 100%|██████████| 469/469 [00:12<00:00, 38.94it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0205, Accuracy: 9934/10000 (99.34%)\n",
            "\n",
            "EPOCH: 26\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.04203891381621361 Accuracy=99.22: 100%|██████████| 469/469 [00:12<00:00, 37.54it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0201, Accuracy: 9931/10000 (99.31%)\n",
            "\n",
            "EPOCH: 27\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.02141948603093624 Accuracy=99.15: 100%|██████████| 469/469 [00:12<00:00, 38.16it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0196, Accuracy: 9936/10000 (99.36%)\n",
            "\n",
            "EPOCH: 28\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.02072136662900448 Accuracy=99.14: 100%|██████████| 469/469 [00:12<00:00, 37.91it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0195, Accuracy: 9940/10000 (99.40%)\n",
            "\n",
            "EPOCH: 29\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.04456305131316185 Accuracy=99.21: 100%|██████████| 469/469 [00:12<00:00, 38.44it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0174, Accuracy: 9943/10000 (99.43%)\n",
            "\n",
            "EPOCH: 30\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.005367209669202566 Accuracy=99.12: 100%|██████████| 469/469 [00:12<00:00, 39.02it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0185, Accuracy: 9935/10000 (99.35%)\n",
            "\n",
            "EPOCH: 31\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.027888184413313866 Accuracy=99.17: 100%|██████████| 469/469 [00:12<00:00, 38.12it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0182, Accuracy: 9935/10000 (99.35%)\n",
            "\n",
            "EPOCH: 32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.004966720938682556 Accuracy=99.17: 100%|██████████| 469/469 [00:12<00:00, 38.02it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0183, Accuracy: 9942/10000 (99.42%)\n",
            "\n",
            "EPOCH: 33\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.0025884907227009535 Accuracy=99.17: 100%|██████████| 469/469 [00:12<00:00, 37.23it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0183, Accuracy: 9938/10000 (99.38%)\n",
            "\n",
            "EPOCH: 34\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.007753501180559397 Accuracy=99.21: 100%|██████████| 469/469 [00:11<00:00, 39.34it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0179, Accuracy: 9940/10000 (99.40%)\n",
            "\n",
            "EPOCH: 35\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.03047867678105831 Accuracy=99.23: 100%|██████████| 469/469 [00:12<00:00, 38.10it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0199, Accuracy: 9934/10000 (99.34%)\n",
            "\n",
            "EPOCH: 36\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.0693734660744667 Accuracy=99.16: 100%|██████████| 469/469 [00:12<00:00, 37.14it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0187, Accuracy: 9938/10000 (99.38%)\n",
            "\n",
            "EPOCH: 37\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.015823086723685265 Accuracy=99.17: 100%|██████████| 469/469 [00:12<00:00, 38.04it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0174, Accuracy: 9947/10000 (99.47%)\n",
            "\n",
            "EPOCH: 38\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.005441536661237478 Accuracy=99.26: 100%|██████████| 469/469 [00:11<00:00, 39.40it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0165, Accuracy: 9948/10000 (99.48%)\n",
            "\n",
            "EPOCH: 39\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.013151903636753559 Accuracy=99.23: 100%|██████████| 469/469 [00:12<00:00, 38.23it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0191, Accuracy: 9943/10000 (99.43%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1__x_SbrL7z3",
        "colab_type": "text"
      },
      "source": [
        "# Training and Testing\n",
        "\n",
        "All right, so we have 6.3M params, and that's too many, we know that. But the purpose of this notebook is to set things right for our future experiments. \n",
        "\n",
        "Looking at logs can be boring, so we'll introduce **tqdm** progressbar to get cooler logs. \n",
        "\n",
        "Let's write train and test functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbkF2nN_LYIb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "train_losses_l1 = []\n",
        "test_losses_l1 = []\n",
        "train_acc_l1 = []\n",
        "test_acc_l1 = []\n",
        "\n",
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "  model.train()\n",
        "  pbar = tqdm(train_loader)\n",
        "  correct = 0\n",
        "  processed = 0\n",
        "  for batch_idx, (data, target) in enumerate(pbar):\n",
        "    # get samples\n",
        "    data, target = data.to(device), target.to(device)\n",
        "\n",
        "    # Init\n",
        "    optimizer.zero_grad()\n",
        "    # In PyTorch, we need to set the gradients to zero before starting to do backpropragation because PyTorch accumulates the gradients on subsequent backward passes. \n",
        "    # Because of this, when you start your training loop, ideally you should zero out the gradients so that you do the parameter update correctly.\n",
        "\n",
        "    # Predict\n",
        "    y_pred = model(data)\n",
        "\n",
        "    # Calculate loss\n",
        "    loss = F.nll_loss(y_pred, target)\n",
        "    #xx = nn.Parameter(torch.from_numpy(np.ones((3,3))))\n",
        "    #target1 = torch.from_numpy(np.zeros((3,3,16))).to(device)\n",
        "    #l1_crit = nn.L1Loss()\n",
        "    #l1_crit(xx, target)\n",
        "    #l1_crit = nn.L1Loss(size_average=False)\n",
        "    reg_loss = 0\n",
        "    for param in model.parameters():\n",
        "        reg_loss += torch.sum(abs(param))\n",
        "        #if param.dim() > 1:\n",
        "          #lam * param.norm(1)\n",
        "          #reg_loss += param.norm(1)\n",
        "\n",
        "    factor = 0.0001\n",
        "    loss += factor * reg_loss\n",
        "    train_losses_l1.append(loss)\n",
        "\n",
        "    # Backpropagation\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Update pbar-tqdm\n",
        "    \n",
        "    pred = y_pred.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "    correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "    processed += len(data)\n",
        "\n",
        "    pbar.set_description(desc= f'Loss={loss.item()} Accuracy={100*correct/processed:0.2f}')\n",
        "    train_acc_l1.append(100*correct/processed)\n",
        "\n",
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    test_losses_l1.append(test_loss)\n",
        "\n",
        "    print('\\nTest set: Avg loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))\n",
        "    \n",
        "    test_acc_l1.append(100. * correct / len(test_loader.dataset))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drokW8wWODKq",
        "colab_type": "text"
      },
      "source": [
        "# Let's Train and test our model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMCFxeAKOB53",
        "colab_type": "code",
        "outputId": "51fd0254-bde7-4d27-9917-56126aded7d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model =  Net().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.008, momentum=0.9)\n",
        "EPOCHS = 40\n",
        "for epoch in range(EPOCHS):\n",
        "    print(\"EPOCH:\", epoch)\n",
        "    train(model, device, train_loader, optimizer, epoch)\n",
        "    test(model, device, test_loader)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "EPOCH: 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.19367823004722595 Accuracy=85.75: 100%|██████████| 469/469 [00:13<00:00, 34.93it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.1021, Accuracy: 9727/10000 (97.27%)\n",
            "\n",
            "EPOCH: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.11708955466747284 Accuracy=97.04: 100%|██████████| 469/469 [00:13<00:00, 33.68it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0632, Accuracy: 9821/10000 (98.21%)\n",
            "\n",
            "EPOCH: 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.11993195861577988 Accuracy=97.75: 100%|██████████| 469/469 [00:13<00:00, 34.37it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0414, Accuracy: 9877/10000 (98.77%)\n",
            "\n",
            "EPOCH: 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.14196927845478058 Accuracy=98.09: 100%|██████████| 469/469 [00:12<00:00, 36.25it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0373, Accuracy: 9886/10000 (98.86%)\n",
            "\n",
            "EPOCH: 4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.10013538599014282 Accuracy=98.31: 100%|██████████| 469/469 [00:13<00:00, 35.62it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0369, Accuracy: 9879/10000 (98.79%)\n",
            "\n",
            "EPOCH: 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.10667720437049866 Accuracy=98.34: 100%|██████████| 469/469 [00:12<00:00, 36.22it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0319, Accuracy: 9884/10000 (98.84%)\n",
            "\n",
            "EPOCH: 6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.09560234099626541 Accuracy=98.48: 100%|██████████| 469/469 [00:12<00:00, 44.70it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0302, Accuracy: 9897/10000 (98.97%)\n",
            "\n",
            "EPOCH: 7\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.12485198676586151 Accuracy=98.59: 100%|██████████| 469/469 [00:12<00:00, 36.55it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0280, Accuracy: 9899/10000 (98.99%)\n",
            "\n",
            "EPOCH: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.08013533055782318 Accuracy=98.61: 100%|██████████| 469/469 [00:13<00:00, 35.62it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0255, Accuracy: 9919/10000 (99.19%)\n",
            "\n",
            "EPOCH: 9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.07199496775865555 Accuracy=98.69: 100%|██████████| 469/469 [00:13<00:00, 35.92it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0325, Accuracy: 9889/10000 (98.89%)\n",
            "\n",
            "EPOCH: 10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.06830110400915146 Accuracy=98.67: 100%|██████████| 469/469 [00:13<00:00, 35.24it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0260, Accuracy: 9906/10000 (99.06%)\n",
            "\n",
            "EPOCH: 11\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.07145873457193375 Accuracy=98.73: 100%|██████████| 469/469 [00:12<00:00, 36.30it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0326, Accuracy: 9884/10000 (98.84%)\n",
            "\n",
            "EPOCH: 12\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.07105273753404617 Accuracy=98.73: 100%|██████████| 469/469 [00:13<00:00, 35.99it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0275, Accuracy: 9907/10000 (99.07%)\n",
            "\n",
            "EPOCH: 13\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.086819127202034 Accuracy=98.73: 100%|██████████| 469/469 [00:12<00:00, 36.34it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0265, Accuracy: 9922/10000 (99.22%)\n",
            "\n",
            "EPOCH: 14\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.08056465536355972 Accuracy=98.70: 100%|██████████| 469/469 [00:12<00:00, 36.17it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0268, Accuracy: 9913/10000 (99.13%)\n",
            "\n",
            "EPOCH: 15\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.09531727433204651 Accuracy=98.78: 100%|██████████| 469/469 [00:12<00:00, 36.52it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0241, Accuracy: 9921/10000 (99.21%)\n",
            "\n",
            "EPOCH: 16\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.06018327921628952 Accuracy=98.82: 100%|██████████| 469/469 [00:12<00:00, 37.42it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0271, Accuracy: 9907/10000 (99.07%)\n",
            "\n",
            "EPOCH: 17\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.06512108445167542 Accuracy=98.79: 100%|██████████| 469/469 [00:12<00:00, 36.49it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0308, Accuracy: 9890/10000 (98.90%)\n",
            "\n",
            "EPOCH: 18\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.08004459738731384 Accuracy=98.86: 100%|██████████| 469/469 [00:13<00:00, 35.28it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0240, Accuracy: 9922/10000 (99.22%)\n",
            "\n",
            "EPOCH: 19\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.09238773584365845 Accuracy=98.76: 100%|██████████| 469/469 [00:12<00:00, 36.25it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0245, Accuracy: 9917/10000 (99.17%)\n",
            "\n",
            "EPOCH: 20\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.09406334906816483 Accuracy=98.81: 100%|██████████| 469/469 [00:12<00:00, 37.77it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0249, Accuracy: 9926/10000 (99.26%)\n",
            "\n",
            "EPOCH: 21\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.07779511064291 Accuracy=98.86: 100%|██████████| 469/469 [00:12<00:00, 36.49it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0244, Accuracy: 9923/10000 (99.23%)\n",
            "\n",
            "EPOCH: 22\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.0724337100982666 Accuracy=98.85: 100%|██████████| 469/469 [00:13<00:00, 36.01it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0241, Accuracy: 9922/10000 (99.22%)\n",
            "\n",
            "EPOCH: 23\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.09332773089408875 Accuracy=98.86: 100%|██████████| 469/469 [00:12<00:00, 36.25it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0247, Accuracy: 9925/10000 (99.25%)\n",
            "\n",
            "EPOCH: 24\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.06515240669250488 Accuracy=98.86: 100%|██████████| 469/469 [00:12<00:00, 37.05it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0207, Accuracy: 9941/10000 (99.41%)\n",
            "\n",
            "EPOCH: 25\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.11461126804351807 Accuracy=98.89: 100%|██████████| 469/469 [00:12<00:00, 36.61it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0221, Accuracy: 9935/10000 (99.35%)\n",
            "\n",
            "EPOCH: 26\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.08788740634918213 Accuracy=98.87: 100%|██████████| 469/469 [00:13<00:00, 35.81it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0241, Accuracy: 9924/10000 (99.24%)\n",
            "\n",
            "EPOCH: 27\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.07307475060224533 Accuracy=98.96: 100%|██████████| 469/469 [00:12<00:00, 36.59it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0249, Accuracy: 9911/10000 (99.11%)\n",
            "\n",
            "EPOCH: 28\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.11450636386871338 Accuracy=98.89: 100%|██████████| 469/469 [00:12<00:00, 37.23it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0252, Accuracy: 9915/10000 (99.15%)\n",
            "\n",
            "EPOCH: 29\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.07302866876125336 Accuracy=98.99: 100%|██████████| 469/469 [00:12<00:00, 36.33it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0208, Accuracy: 9933/10000 (99.33%)\n",
            "\n",
            "EPOCH: 30\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.10376831889152527 Accuracy=98.93: 100%|██████████| 469/469 [00:12<00:00, 42.66it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0255, Accuracy: 9921/10000 (99.21%)\n",
            "\n",
            "EPOCH: 31\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.07255908101797104 Accuracy=98.86: 100%|██████████| 469/469 [00:12<00:00, 36.70it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0219, Accuracy: 9925/10000 (99.25%)\n",
            "\n",
            "EPOCH: 32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.09905973821878433 Accuracy=98.88: 100%|██████████| 469/469 [00:12<00:00, 37.01it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0246, Accuracy: 9924/10000 (99.24%)\n",
            "\n",
            "EPOCH: 33\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.08284304291009903 Accuracy=98.94: 100%|██████████| 469/469 [00:12<00:00, 37.17it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0259, Accuracy: 9918/10000 (99.18%)\n",
            "\n",
            "EPOCH: 34\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.11143295466899872 Accuracy=98.91: 100%|██████████| 469/469 [00:12<00:00, 36.28it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0239, Accuracy: 9916/10000 (99.16%)\n",
            "\n",
            "EPOCH: 35\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.17157800495624542 Accuracy=98.95: 100%|██████████| 469/469 [00:13<00:00, 35.26it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0208, Accuracy: 9934/10000 (99.34%)\n",
            "\n",
            "EPOCH: 36\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.07599148899316788 Accuracy=98.98: 100%|██████████| 469/469 [00:13<00:00, 36.04it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0203, Accuracy: 9939/10000 (99.39%)\n",
            "\n",
            "EPOCH: 37\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.09839741885662079 Accuracy=98.94: 100%|██████████| 469/469 [00:12<00:00, 36.81it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0221, Accuracy: 9921/10000 (99.21%)\n",
            "\n",
            "EPOCH: 38\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.10098565369844437 Accuracy=98.95: 100%|██████████| 469/469 [00:12<00:00, 36.13it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0254, Accuracy: 9916/10000 (99.16%)\n",
            "\n",
            "EPOCH: 39\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.11989995092153549 Accuracy=98.92: 100%|██████████| 469/469 [00:13<00:00, 35.90it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0181, Accuracy: 9943/10000 (99.43%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CEox5x9ND17",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "train_losses_l2 = []\n",
        "test_losses_l2 = []\n",
        "train_acc_l2 = []\n",
        "test_acc_l2 = []\n",
        "\n",
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "  model.train()\n",
        "  pbar = tqdm(train_loader)\n",
        "  correct = 0\n",
        "  processed = 0\n",
        "  for batch_idx, (data, target) in enumerate(pbar):\n",
        "    # get samples\n",
        "    data, target = data.to(device), target.to(device)\n",
        "\n",
        "    # Init\n",
        "    optimizer.zero_grad()\n",
        "    # In PyTorch, we need to set the gradients to zero before starting to do backpropragation because PyTorch accumulates the gradients on subsequent backward passes. \n",
        "    # Because of this, when you start your training loop, ideally you should zero out the gradients so that you do the parameter update correctly.\n",
        "\n",
        "    # Predict\n",
        "    y_pred = model(data)\n",
        "\n",
        "    # Calculate loss\n",
        "    loss = F.nll_loss(y_pred, target)\n",
        "\n",
        "    train_losses_l2.append(loss)\n",
        "\n",
        "    # Backpropagation\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Update pbar-tqdm\n",
        "    \n",
        "    pred = y_pred.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "    correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "    processed += len(data)\n",
        "\n",
        "    pbar.set_description(desc= f'Loss={loss.item()} Batch_id={batch_idx} Accuracy={100*correct/processed:0.2f}')\n",
        "    train_acc_l2.append(100*correct/processed)\n",
        "\n",
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    wrong_class_images=[]\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "            \n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    test_losses_l2.append(test_loss)\n",
        "\n",
        "    print('\\nTest set: Avg loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))\n",
        "    \n",
        "    test_acc_l2.append(100. * correct / len(test_loader.dataset))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7LpZvQGNFKH",
        "colab_type": "code",
        "outputId": "cb382118-1aec-4f01-d554-3ba171a6d4ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model =  Net().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.008, momentum=0.9, weight_decay=0.0001)\n",
        "EPOCHS = 40\n",
        "for epoch in range(EPOCHS):\n",
        "    print(\"EPOCH:\", epoch)\n",
        "    train(model, device, train_loader, optimizer, epoch)\n",
        "    test(model, device, test_loader)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "EPOCH: 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.09561777114868164 Batch_id=468 Accuracy=85.69: 100%|██████████| 469/469 [00:12<00:00, 38.54it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.2500, Accuracy: 9238/10000 (92.38%)\n",
            "\n",
            "EPOCH: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.04531943425536156 Batch_id=468 Accuracy=97.07: 100%|██████████| 469/469 [00:12<00:00, 36.39it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0663, Accuracy: 9804/10000 (98.04%)\n",
            "\n",
            "EPOCH: 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.08037713170051575 Batch_id=468 Accuracy=97.79: 100%|██████████| 469/469 [00:12<00:00, 37.54it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0562, Accuracy: 9846/10000 (98.46%)\n",
            "\n",
            "EPOCH: 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.02674666978418827 Batch_id=468 Accuracy=98.15: 100%|██████████| 469/469 [00:12<00:00, 46.22it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0628, Accuracy: 9817/10000 (98.17%)\n",
            "\n",
            "EPOCH: 4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.06382583826780319 Batch_id=468 Accuracy=98.27: 100%|██████████| 469/469 [00:11<00:00, 39.13it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0397, Accuracy: 9891/10000 (98.91%)\n",
            "\n",
            "EPOCH: 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.1045452132821083 Batch_id=468 Accuracy=98.46: 100%|██████████| 469/469 [00:11<00:00, 45.19it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0382, Accuracy: 9887/10000 (98.87%)\n",
            "\n",
            "EPOCH: 6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.04953046143054962 Batch_id=468 Accuracy=98.60: 100%|██████████| 469/469 [00:12<00:00, 39.00it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0372, Accuracy: 9885/10000 (98.85%)\n",
            "\n",
            "EPOCH: 7\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.05843029543757439 Batch_id=468 Accuracy=98.62: 100%|██████████| 469/469 [00:12<00:00, 43.38it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0315, Accuracy: 9900/10000 (99.00%)\n",
            "\n",
            "EPOCH: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.057593267410993576 Batch_id=468 Accuracy=98.68: 100%|██████████| 469/469 [00:12<00:00, 38.48it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0342, Accuracy: 9897/10000 (98.97%)\n",
            "\n",
            "EPOCH: 9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.08477655798196793 Batch_id=468 Accuracy=98.64: 100%|██████████| 469/469 [00:11<00:00, 39.86it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0343, Accuracy: 9897/10000 (98.97%)\n",
            "\n",
            "EPOCH: 10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.013662208802998066 Batch_id=468 Accuracy=98.77: 100%|██████████| 469/469 [00:12<00:00, 38.44it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0308, Accuracy: 9902/10000 (99.02%)\n",
            "\n",
            "EPOCH: 11\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.05974092707037926 Batch_id=468 Accuracy=98.85: 100%|██████████| 469/469 [00:12<00:00, 38.31it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0313, Accuracy: 9897/10000 (98.97%)\n",
            "\n",
            "EPOCH: 12\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.032379377633333206 Batch_id=468 Accuracy=98.84: 100%|██████████| 469/469 [00:12<00:00, 38.88it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0324, Accuracy: 9902/10000 (99.02%)\n",
            "\n",
            "EPOCH: 13\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.033630531281232834 Batch_id=468 Accuracy=98.91: 100%|██████████| 469/469 [00:12<00:00, 38.98it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0283, Accuracy: 9910/10000 (99.10%)\n",
            "\n",
            "EPOCH: 14\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.014581789262592793 Batch_id=468 Accuracy=98.85: 100%|██████████| 469/469 [00:12<00:00, 37.51it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0283, Accuracy: 9910/10000 (99.10%)\n",
            "\n",
            "EPOCH: 15\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.014587040059268475 Batch_id=468 Accuracy=98.96: 100%|██████████| 469/469 [00:12<00:00, 38.01it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0279, Accuracy: 9915/10000 (99.15%)\n",
            "\n",
            "EPOCH: 16\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.007270639296621084 Batch_id=468 Accuracy=98.94: 100%|██████████| 469/469 [00:12<00:00, 37.51it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0263, Accuracy: 9923/10000 (99.23%)\n",
            "\n",
            "EPOCH: 17\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.0241019818931818 Batch_id=468 Accuracy=99.00: 100%|██████████| 469/469 [00:12<00:00, 45.26it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0267, Accuracy: 9912/10000 (99.12%)\n",
            "\n",
            "EPOCH: 18\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.020301729440689087 Batch_id=468 Accuracy=98.98: 100%|██████████| 469/469 [00:12<00:00, 38.09it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0260, Accuracy: 9923/10000 (99.23%)\n",
            "\n",
            "EPOCH: 19\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.019457921385765076 Batch_id=468 Accuracy=99.06: 100%|██████████| 469/469 [00:12<00:00, 36.43it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0277, Accuracy: 9916/10000 (99.16%)\n",
            "\n",
            "EPOCH: 20\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.039283983409404755 Batch_id=468 Accuracy=99.05: 100%|██████████| 469/469 [00:12<00:00, 37.00it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0271, Accuracy: 9923/10000 (99.23%)\n",
            "\n",
            "EPOCH: 21\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.09378242492675781 Batch_id=468 Accuracy=99.06: 100%|██████████| 469/469 [00:12<00:00, 36.93it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0248, Accuracy: 9921/10000 (99.21%)\n",
            "\n",
            "EPOCH: 22\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.061968881636857986 Batch_id=468 Accuracy=99.03: 100%|██████████| 469/469 [00:12<00:00, 38.04it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0265, Accuracy: 9908/10000 (99.08%)\n",
            "\n",
            "EPOCH: 23\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.0679510161280632 Batch_id=468 Accuracy=99.06: 100%|██████████| 469/469 [00:12<00:00, 36.57it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0264, Accuracy: 9918/10000 (99.18%)\n",
            "\n",
            "EPOCH: 24\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.010742053389549255 Batch_id=468 Accuracy=99.11: 100%|██████████| 469/469 [00:12<00:00, 36.51it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0248, Accuracy: 9917/10000 (99.17%)\n",
            "\n",
            "EPOCH: 25\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.01617804728448391 Batch_id=468 Accuracy=99.09: 100%|██████████| 469/469 [00:13<00:00, 35.63it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0267, Accuracy: 9911/10000 (99.11%)\n",
            "\n",
            "EPOCH: 26\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.047126155346632004 Batch_id=468 Accuracy=99.08: 100%|██████████| 469/469 [00:12<00:00, 37.61it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0254, Accuracy: 9918/10000 (99.18%)\n",
            "\n",
            "EPOCH: 27\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.0040097832679748535 Batch_id=468 Accuracy=99.11: 100%|██████████| 469/469 [00:12<00:00, 36.51it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0259, Accuracy: 9913/10000 (99.13%)\n",
            "\n",
            "EPOCH: 28\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.01749347150325775 Batch_id=468 Accuracy=99.14: 100%|██████████| 469/469 [00:12<00:00, 36.53it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0242, Accuracy: 9920/10000 (99.20%)\n",
            "\n",
            "EPOCH: 29\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.026825526729226112 Batch_id=468 Accuracy=99.14: 100%|██████████| 469/469 [00:12<00:00, 37.96it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0242, Accuracy: 9923/10000 (99.23%)\n",
            "\n",
            "EPOCH: 30\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.029300697147846222 Batch_id=468 Accuracy=99.14: 100%|██████████| 469/469 [00:12<00:00, 38.58it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0211, Accuracy: 9931/10000 (99.31%)\n",
            "\n",
            "EPOCH: 31\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.0329931266605854 Batch_id=468 Accuracy=99.16: 100%|██████████| 469/469 [00:12<00:00, 38.13it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0260, Accuracy: 9909/10000 (99.09%)\n",
            "\n",
            "EPOCH: 32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.037151020020246506 Batch_id=468 Accuracy=99.17: 100%|██████████| 469/469 [00:12<00:00, 38.17it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0217, Accuracy: 9926/10000 (99.26%)\n",
            "\n",
            "EPOCH: 33\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.007681066635996103 Batch_id=468 Accuracy=99.17: 100%|██████████| 469/469 [00:12<00:00, 38.03it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0242, Accuracy: 9912/10000 (99.12%)\n",
            "\n",
            "EPOCH: 34\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.040603574365377426 Batch_id=468 Accuracy=99.18: 100%|██████████| 469/469 [00:12<00:00, 38.93it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0261, Accuracy: 9910/10000 (99.10%)\n",
            "\n",
            "EPOCH: 35\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.02747703157365322 Batch_id=468 Accuracy=99.17: 100%|██████████| 469/469 [00:11<00:00, 39.48it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0217, Accuracy: 9935/10000 (99.35%)\n",
            "\n",
            "EPOCH: 36\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.06929884105920792 Batch_id=468 Accuracy=99.16: 100%|██████████| 469/469 [00:12<00:00, 37.57it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0230, Accuracy: 9925/10000 (99.25%)\n",
            "\n",
            "EPOCH: 37\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.03853459283709526 Batch_id=468 Accuracy=99.27: 100%|██████████| 469/469 [00:12<00:00, 38.27it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0252, Accuracy: 9916/10000 (99.16%)\n",
            "\n",
            "EPOCH: 38\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.008044962771236897 Batch_id=468 Accuracy=99.14: 100%|██████████| 469/469 [00:12<00:00, 38.66it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0218, Accuracy: 9931/10000 (99.31%)\n",
            "\n",
            "EPOCH: 39\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.04013790190219879 Batch_id=468 Accuracy=99.19: 100%|██████████| 469/469 [00:12<00:00, 39.07it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0216, Accuracy: 9928/10000 (99.28%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87RaqGSEOWDe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "train_losses_l1l2 = []\n",
        "test_losses_l1l2 = []\n",
        "train_acc_l1l2 = []\n",
        "test_acc_l1l2 = []\n",
        "\n",
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "  model.train()\n",
        "  pbar = tqdm(train_loader)\n",
        "  correct = 0\n",
        "  processed = 0\n",
        "  for batch_idx, (data, target) in enumerate(pbar):\n",
        "    # get samples\n",
        "    data, target = data.to(device), target.to(device)\n",
        "\n",
        "    # Init\n",
        "    optimizer.zero_grad()\n",
        "    # In PyTorch, we need to set the gradients to zero before starting to do backpropragation because PyTorch accumulates the gradients on subsequent backward passes. \n",
        "    # Because of this, when you start your training loop, ideally you should zero out the gradients so that you do the parameter update correctly.\n",
        "\n",
        "    # Predict\n",
        "    y_pred = model(data)\n",
        "\n",
        "    # Calculate loss\n",
        "    loss = F.nll_loss(y_pred, target)\n",
        "    #xx = nn.Parameter(torch.from_numpy(np.ones((3,3))))\n",
        "    #target1 = torch.from_numpy(np.zeros((3,3,16))).to(device)\n",
        "    #l1_crit = nn.L1Loss()\n",
        "    #l1_crit(xx, target)\n",
        "    #l1_crit = nn.L1Loss(size_average=False)\n",
        "    reg_loss = 0\n",
        "    for param in model.parameters():\n",
        "        reg_loss += torch.sum(abs(param))\n",
        "        #if param.dim() > 1:\n",
        "          #lam * param.norm(1)\n",
        "          #reg_loss += param.norm(1)\n",
        "\n",
        "    factor = 0.0001\n",
        "    loss += factor * reg_loss\n",
        "    train_losses_l1l2.append(loss)\n",
        "\n",
        "    # Backpropagation\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Update pbar-tqdm\n",
        "    \n",
        "    pred = y_pred.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "    correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "    processed += len(data)\n",
        "\n",
        "    pbar.set_description(desc= f'Loss={loss.item()} Batch_id={batch_idx} Accuracy={100*correct/processed:0.2f}')\n",
        "    train_acc_l1l2.append(100*correct/processed)\n",
        "\n",
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    test_losses_l1l2.append(test_loss)\n",
        "\n",
        "    print('\\nTest set: Avg loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))\n",
        "    \n",
        "    test_acc_l1l2.append(100. * correct / len(test_loader.dataset))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odozjbIvY12p",
        "colab_type": "code",
        "outputId": "47db5007-4031-43fe-bd3c-c994faf97c2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model =  Net().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.008, momentum=0.9,weight_decay=0.0001)\n",
        "EPOCHS = 40\n",
        "for epoch in range(EPOCHS):\n",
        "    print(\"EPOCH:\", epoch)\n",
        "    train(model, device, train_loader, optimizer, epoch)\n",
        "    test(model, device, test_loader)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "EPOCH: 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.2700701951980591 Batch_id=468 Accuracy=84.31: 100%|██████████| 469/469 [00:13<00:00, 35.10it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.1140, Accuracy: 9707/10000 (97.07%)\n",
            "\n",
            "EPOCH: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.12345415353775024 Batch_id=468 Accuracy=96.82: 100%|██████████| 469/469 [00:13<00:00, 34.57it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0647, Accuracy: 9804/10000 (98.04%)\n",
            "\n",
            "EPOCH: 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.15458013117313385 Batch_id=468 Accuracy=97.68: 100%|██████████| 469/469 [00:13<00:00, 35.76it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0394, Accuracy: 9899/10000 (98.99%)\n",
            "\n",
            "EPOCH: 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.1634119302034378 Batch_id=468 Accuracy=97.90: 100%|██████████| 469/469 [00:13<00:00, 35.86it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0376, Accuracy: 9904/10000 (99.04%)\n",
            "\n",
            "EPOCH: 4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.21040678024291992 Batch_id=468 Accuracy=98.15: 100%|██████████| 469/469 [00:13<00:00, 36.03it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0341, Accuracy: 9901/10000 (99.01%)\n",
            "\n",
            "EPOCH: 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.10251493752002716 Batch_id=468 Accuracy=98.33: 100%|██████████| 469/469 [00:13<00:00, 36.01it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0350, Accuracy: 9894/10000 (98.94%)\n",
            "\n",
            "EPOCH: 6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.0714876800775528 Batch_id=468 Accuracy=98.38: 100%|██████████| 469/469 [00:12<00:00, 36.28it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0317, Accuracy: 9912/10000 (99.12%)\n",
            "\n",
            "EPOCH: 7\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.11426730453968048 Batch_id=468 Accuracy=98.50: 100%|██████████| 469/469 [00:12<00:00, 36.12it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0317, Accuracy: 9899/10000 (98.99%)\n",
            "\n",
            "EPOCH: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.0820944681763649 Batch_id=468 Accuracy=98.57: 100%|██████████| 469/469 [00:14<00:00, 32.81it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0302, Accuracy: 9914/10000 (99.14%)\n",
            "\n",
            "EPOCH: 9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.15359129011631012 Batch_id=468 Accuracy=98.59: 100%|██████████| 469/469 [00:13<00:00, 42.00it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0304, Accuracy: 9905/10000 (99.05%)\n",
            "\n",
            "EPOCH: 10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.09181872010231018 Batch_id=468 Accuracy=98.70: 100%|██████████| 469/469 [00:13<00:00, 34.49it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0269, Accuracy: 9925/10000 (99.25%)\n",
            "\n",
            "EPOCH: 11\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.08798161149024963 Batch_id=468 Accuracy=98.69: 100%|██████████| 469/469 [00:13<00:00, 34.64it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0279, Accuracy: 9910/10000 (99.10%)\n",
            "\n",
            "EPOCH: 12\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.08381909132003784 Batch_id=468 Accuracy=98.67: 100%|██████████| 469/469 [00:13<00:00, 33.88it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0267, Accuracy: 9921/10000 (99.21%)\n",
            "\n",
            "EPOCH: 13\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.12663103640079498 Batch_id=468 Accuracy=98.69: 100%|██████████| 469/469 [00:13<00:00, 40.13it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0293, Accuracy: 9915/10000 (99.15%)\n",
            "\n",
            "EPOCH: 14\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.07889233529567719 Batch_id=468 Accuracy=98.73: 100%|██████████| 469/469 [00:13<00:00, 34.03it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0264, Accuracy: 9917/10000 (99.17%)\n",
            "\n",
            "EPOCH: 15\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.1143006980419159 Batch_id=468 Accuracy=98.66: 100%|██████████| 469/469 [00:13<00:00, 34.07it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0345, Accuracy: 9900/10000 (99.00%)\n",
            "\n",
            "EPOCH: 16\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.1204448938369751 Batch_id=468 Accuracy=98.77: 100%|██████████| 469/469 [00:13<00:00, 34.25it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0253, Accuracy: 9919/10000 (99.19%)\n",
            "\n",
            "EPOCH: 17\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.09523659944534302 Batch_id=468 Accuracy=98.73: 100%|██████████| 469/469 [00:13<00:00, 34.30it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0269, Accuracy: 9918/10000 (99.18%)\n",
            "\n",
            "EPOCH: 18\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.10104475915431976 Batch_id=468 Accuracy=98.78: 100%|██████████| 469/469 [00:13<00:00, 34.68it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0276, Accuracy: 9917/10000 (99.17%)\n",
            "\n",
            "EPOCH: 19\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.10535165667533875 Batch_id=468 Accuracy=98.80: 100%|██████████| 469/469 [00:13<00:00, 35.12it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0314, Accuracy: 9900/10000 (99.00%)\n",
            "\n",
            "EPOCH: 20\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.14095982909202576 Batch_id=468 Accuracy=98.69: 100%|██████████| 469/469 [00:12<00:00, 36.24it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0252, Accuracy: 9924/10000 (99.24%)\n",
            "\n",
            "EPOCH: 21\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.06360840052366257 Batch_id=468 Accuracy=98.73: 100%|██████████| 469/469 [00:12<00:00, 36.36it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0289, Accuracy: 9907/10000 (99.07%)\n",
            "\n",
            "EPOCH: 22\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.0741286501288414 Batch_id=468 Accuracy=98.80: 100%|██████████| 469/469 [00:12<00:00, 44.37it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0292, Accuracy: 9914/10000 (99.14%)\n",
            "\n",
            "EPOCH: 23\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.09754364937543869 Batch_id=468 Accuracy=98.80: 100%|██████████| 469/469 [00:12<00:00, 36.56it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0292, Accuracy: 9908/10000 (99.08%)\n",
            "\n",
            "EPOCH: 24\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.060233224183321 Batch_id=468 Accuracy=98.83: 100%|██████████| 469/469 [00:13<00:00, 35.04it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0229, Accuracy: 9932/10000 (99.32%)\n",
            "\n",
            "EPOCH: 25\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.070098377764225 Batch_id=468 Accuracy=98.83: 100%|██████████| 469/469 [00:12<00:00, 36.31it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0287, Accuracy: 9913/10000 (99.13%)\n",
            "\n",
            "EPOCH: 26\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.06073327735066414 Batch_id=468 Accuracy=98.82: 100%|██████████| 469/469 [00:13<00:00, 36.05it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0266, Accuracy: 9915/10000 (99.15%)\n",
            "\n",
            "EPOCH: 27\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.10354676097631454 Batch_id=468 Accuracy=98.84: 100%|██████████| 469/469 [00:12<00:00, 37.11it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0231, Accuracy: 9933/10000 (99.33%)\n",
            "\n",
            "EPOCH: 28\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.07167559862136841 Batch_id=468 Accuracy=98.81: 100%|██████████| 469/469 [00:12<00:00, 36.13it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0224, Accuracy: 9931/10000 (99.31%)\n",
            "\n",
            "EPOCH: 29\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.06623752415180206 Batch_id=468 Accuracy=98.83: 100%|██████████| 469/469 [00:13<00:00, 36.02it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0283, Accuracy: 9908/10000 (99.08%)\n",
            "\n",
            "EPOCH: 30\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.07440988719463348 Batch_id=468 Accuracy=98.83: 100%|██████████| 469/469 [00:12<00:00, 43.27it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0233, Accuracy: 9933/10000 (99.33%)\n",
            "\n",
            "EPOCH: 31\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.11703306436538696 Batch_id=468 Accuracy=98.89: 100%|██████████| 469/469 [00:12<00:00, 37.27it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0266, Accuracy: 9921/10000 (99.21%)\n",
            "\n",
            "EPOCH: 32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.056263476610183716 Batch_id=468 Accuracy=98.86: 100%|██████████| 469/469 [00:12<00:00, 36.22it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0254, Accuracy: 9921/10000 (99.21%)\n",
            "\n",
            "EPOCH: 33\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.061264410614967346 Batch_id=468 Accuracy=98.90: 100%|██████████| 469/469 [00:12<00:00, 36.26it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0225, Accuracy: 9926/10000 (99.26%)\n",
            "\n",
            "EPOCH: 34\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.08500335365533829 Batch_id=468 Accuracy=98.87: 100%|██████████| 469/469 [00:12<00:00, 36.19it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0217, Accuracy: 9929/10000 (99.29%)\n",
            "\n",
            "EPOCH: 35\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.0766678974032402 Batch_id=468 Accuracy=98.78: 100%|██████████| 469/469 [00:12<00:00, 36.64it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0247, Accuracy: 9922/10000 (99.22%)\n",
            "\n",
            "EPOCH: 36\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.06890277564525604 Batch_id=468 Accuracy=98.84: 100%|██████████| 469/469 [00:12<00:00, 36.40it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0217, Accuracy: 9935/10000 (99.35%)\n",
            "\n",
            "EPOCH: 37\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.1729113608598709 Batch_id=468 Accuracy=98.87: 100%|██████████| 469/469 [00:13<00:00, 45.00it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0277, Accuracy: 9912/10000 (99.12%)\n",
            "\n",
            "EPOCH: 38\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.12180983275175095 Batch_id=468 Accuracy=98.88: 100%|██████████| 469/469 [00:12<00:00, 36.29it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0278, Accuracy: 9911/10000 (99.11%)\n",
            "\n",
            "EPOCH: 39\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss=0.05921757593750954 Batch_id=468 Accuracy=98.91: 100%|██████████| 469/469 [00:12<00:00, 36.84it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Avg loss: 0.0233, Accuracy: 9926/10000 (99.26%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fgUNxDBJZD8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4rc_hCfbqsi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 624
        },
        "outputId": "e29aae23-639c-47ec-c71b-023c05801712"
      },
      "source": [
        "# Let's visualize some of the images\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "fig, axs = plt.subplots(1,2,figsize=(15,10))\n",
        "axs[0].plot(test_acc_normal, label='no l1/l2')\n",
        "axs[0].plot(test_acc_l1, label='l1')\n",
        "axs[0].plot(test_acc_l2, label='l2')\n",
        "axs[0].plot(test_acc_l1l2, label='l1+l2')\n",
        "axs[0].set_title(\"Accuracy\")\n",
        "axs[0].legend(loc=\"upper left\")\n",
        "\n",
        "axs[1].plot(test_losses_normal,label='no l1/l2')\n",
        "#axs[0, 1].set_title(\"Test Loss\")\n",
        "axs[1].plot(test_losses_l1,label='l1')\n",
        "axs[1].plot(test_losses_l2,label='l2')\n",
        "axs[1].plot(test_losses_l1l2,label='l1+l2')\n",
        "axs[1].set_title(\"Loss\")\n",
        "axs[1].legend(loc=\"upper left\")\n",
        "#axs[1, 1].set_title(\"Test Accuracy\")"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fcfe4fce470>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2cAAAJOCAYAAAAzn38vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nOzdd3RURRvA4d9k03sPJKRSA6FH6UVR\nqoCC0gQEqVaKon52wILSsSECUgWRJiAgTXpvUkJNIwkhCel9N7vz/bExEAghkRCCzHPOHpJ7586d\n3STMvjsz7wgpJYqiKIqiKIqiKMqDZfKgG6AoiqIoiqIoiqKo4ExRFEVRFEVRFKVCUMGZoiiKoiiK\noihKBaCCM0VRFEVRFEVRlApABWeKoiiKoiiKoigVgArOFEVRFEVRFEVRKgAVnCmKoiiKoiiKolQA\nKjhTHnlCiJ1CiGQhhMWDbouiKIqiPMyEEBFCiKcedDsU5WGlgjPlkSaE8ANaARLoVo73NS2veymK\noiiKoigPBxWcKY+6gcBBYAHw0j8HhRBWQoipQohIIUSqEGKvEMIq/1xLIcR+IUSKECJKCDEo//hO\nIcTQm+oYJITYe9P3UgjxmhDiEnAp/9jM/DrShBDHhBCtbiqvEUK8L4QIFUKk55/3FkJ8J4SYevOT\nEEKsE0KMuR8vkKIoiqLcKyHEMCHEZSFEUn6f5Zl/XAghpgsh4vP7wtNCiKD8c52FECH5fWCMEOLt\nB/ssFOX+U8GZ8qgbCCzNf3QQQnjkH58CNAaaA87AO4BBCOELbAK+AdyABsDJUtzvWaAJUDv/+yP5\ndTgDvwC/CSEs88+NBfoCnQF74GUgC1gI9BVCmAAIIVyBp/KvVxRFUZQKRQjxJPAl0AuoDEQCy/NP\ntwdaAzUAh/wyifnn5gEjpJR2QBCwoxybrSgPhArOlEeWEKIl4AuskFIeA0KBfvlBz8vAKClljJRS\nL6XcL6XMBfoB26SUy6SUOillopSyNMHZl1LKJCllNoCUckl+HXlSyqmABVAzv+xQ4EMp5QVp9Hd+\n2cNAKtAuv1wfYKeUMu4eXxJFURRFuR9eBOZLKY/n96X/A5rlLy3QAXZALUBIKc9JKWPzr9MBtYUQ\n9lLKZCnl8QfQdkUpVyo4Ux5lLwFbpJTX87//Jf+YK2CJMVi7lfcdjpdU1M3fCCHeFkKcy586mYLx\nU0PXEtxrIdA//+v+wOJ7aJOiKIqi3E+eGEfLAJBSZmAcHfOSUu4AvgW+A+KFEHOEEPb5RXtinD0S\nKYTYJYRoVs7tVpRyp4Iz5ZGUv36sF9BGCHFNCHENGAPUxzjlIgeoWsSlUXc4DpAJWN/0faUiysib\n2tAK43TJXoCTlNIR44iYKMG9lgDdhRD1gUBg7R3KKYqiKMqDdhXjTBUAhBA2gAsQAyClnCWlbIxx\nyn8NYFz+8SNSyu6AO8Z+bkU5t1tRyp0KzpRH1bOAHmNH0CD/EQjswbgObT4wTQjhmZ+Yo1l+qv2l\nwFNCiF5CCFMhhIsQokF+nSeBHkIIayFENWDIXdpgB+QBCYCpEOJjjGvL/jEXmCiEqJ6/YLqeEMIF\nQEoZjXG92mJg1T/TJBVFURSlAjATQlj+8wCWAYOFEA3y+9IvgENSygghxGNCiCZCCDOMH3LmYFzj\nbS6EeFEI4SCl1AFpgOGBPSNFKScqOFMeVS8BP0spr0gpr/3zwDi14kXgPeA0xgAoCfgKMJFSXsE4\nxeKt/OMnMY62AUwHtEAcxmmHS+/Shj+BzcBFjNM9cig87XEaxk8Jt2DslOYBVjedXwjURU1pVBRF\nUSqWjUD2TY+2wEfAKiAW46yQPvll7YGfgGSMfWEiMDn/3AAgQgiRBozE2D8ryn+akFLevZSiKBWO\nEKI1xumNvlL9ISuKoiiKojz01MiZojyE8qd/jALmqsBMURRFURTlv0EFZ4rykBFCBAIpGBOXzHjA\nzVEURVEURVHKiJrWqCiKoiiKoiiKUgGokTNFURRFURRFUZQKwLQ8b+bq6ir9/PzK85aKoijKA3Ds\n2LHrUkq3B92Oh4XqHxVFUR4dxfWR5Rqc+fn5cfTo0fK8paIoivIACCEiH3QbHiaqf1QURXl0FNdH\nqmmNiqIoiqIoiqIoFYAKzhRFURRFURRFUSoAFZwpiqIoiqIoiqJUAOW65qwoOp2O6OhocnJyHnRT\nKiRLS0uqVKmCmZnZg26KoiiKUo5U/3h3qo9UFOW/5oEHZ9HR0djZ2eHn54cQ4kE3p0KRUpKYmEh0\ndDT+/v4PujmKoihKOVL9Y/FUH6koyn/RA5/WmJOTg4uLi+p4iiCEwMXFRX1qqiiK8ghS/WPxVB+p\nKMp/0QMPzgDV8RRDvTaKoiiPLtUHFE+9Poqi/NdUiOBMURRFURRFURTlUaeCs3v06aefMmXKFAB+\n++036tSpg4mJSZGbiTZu3Jjc3Fz8/Py4fv06UVFRPPHEE9SuXZs6deowc+bM8m6+oiiKotwXqn9U\nFEUpPRWclaGgoCBWr15N69atbzsXHh6Ol5cXFhYWBcdMTU2ZOnUqISEhHDx4kO+++46QkJDybLKi\nKIqi3Heqf1QURSmZRz44i4iIIDAwkGHDhlGnTh3at29PdnY2ACdPnqRp06bUq1eP5557juTk5GLr\nCgwMpGbNmkWe27x5Mx07dix0rHLlyjRq1AgAOzs7AgMDiYmJKYNnpSiKoij3RvWPiqIo5e+Bp9K/\n2fj1Zwm5mlamddb2tOeTrnWKLXPp0iWWLVvGTz/9RK9evVi1ahX9+/dn4MCBfPPNN7Rp04aPP/6Y\n8ePHM2PGjH/Vjs2bNzN9+vQ7no+IiODEiRM0adLkX9WvKIqi/Hep/lH1j4qiPBoe+ZEzAH9/fxo0\naAAY571HRESQmppKSkoKbdq0AeCll15i9+7d/6p+rVZLdHQ0AQEBRZ7PyMigZ8+ezJgxA3t7+3/3\nJBRFURSljKn+UVEUpXxVqJGzu32Cd7/cPM9do9EUTNsoK3v27KFly5ZFntPpdPTs2ZMXX3yRHj16\nlOl9FUVRlP8G1T+q/lFRlEeDGjm7AwcHB5ycnNizZw8AixcvLviUsLQ2b95Mp06dbjsupWTIkCEE\nBgYyduzYe2qvoiiKopQH1T8qiqLcPyo4K8bChQsZN24c9erV4+TJk3z88cfFll+zZg1VqlThwIED\ndOnShQ4dOgCwc+fOIjuuffv2sXjxYnbs2EGDBg1o0KABGzduvC/PRVEURVHKiuofFUVR7g8hpSy3\nmwUHB8tb9zc5d+4cgYGB5daG8hYdHc2wYcPYtGnTv67jv/4aKYry3yOEOCalDH7Q7XhYqP7x3/uv\nv06Kovz3FNdHqpGz+6xKlSr33PEoiqIoyn+N6h8VRVFup4IzRVEURVEURVGUCkAFZ4qiKIqiKIqi\nKBWACs4URVEUpQhCiI5CiAtCiMtCiPeKOD9WCBEihDglhNguhPC96ZxeCHEy/7GufFuuKIqiPKwq\n1D5niqIoilIRCCE0wHfA00A0cEQIsU5KGXJTsRNAsJQySwjxCvA10Dv/XLaUskG5NlpRFEV56Kng\nTFEU5T9ASkn49UyuZ2hJytSSnGX8NylTS3KmlqQs47/mpiZ0b+BF9wae2FmaPehmV2SPA5ellGEA\nQojlQHegIDiTUv51U/mDQP9ybeEtQlNCcbBwwNXK9UE2Q1EURbkHKjgDbG1tycjIAKBjx44cPHiQ\nli1bsmHDhgfcMkVRlLu7npHLuytPsf18/G3nrM01OFmb42xjjpONOXGpOXy49gyf/3GOLvUq0/dx\nbxr5OCGEeAAtr9C8gKibvo8GmhRTfghwc+pBSyHEUSAPmCSlXHvrBUKI4cBwAB8fn3tusFavJc+Q\nd8/13Ez1j4qiKOVLBWe3GDduHFlZWfz4448PuimKoih39df5eMat/Ju0nDzGdahJ/SqOONmYGYMx\na3MszTSFyksp+Ts6lV+PXGHdyausPBZNdXdbej/mTY9GVXC2MX9Az+ThJYToDwQDN++m7CuljBFC\nBAA7hBCnpZShN18npZwDzAHjPmdl0A7u596lqn9UFEW5/1Rwdot27dqxc+fOB90MRVFuYTBIQhMy\niEnJpmU1V0w1j3Y+o2ytni82nmPxwUhqVbJj6dCm1Kxkd9frhBA08HakgbcjH3apzYZTV1l2OIrP\n/jjH15svMCIggfY1HKjTvCsmj/ZrHAN43/R9lfxjhQghngI+ANpIKXP/OS6ljMn/N0wIsRNoCITe\nen1ZEggk9y84U/2joijK/VexgrNN78G102VbZ6W60GlS2dapKBVYaraO41eSORqRRLbWwItNfajq\nZvugm1Vq2jwDp2NSORKRxNGIJI5GJpOSpQOgdmV7vuxRl/rejvfl3tlaPYsPRnA9Q0u7Wu4E+zmj\nMak40/7OxKQyavkJQhMyGdrSn3Eda2Jhqrn7hbewsTCl92M+9H7Mh/PX0vj18BXaHf8Yl+gUaNaZ\nRzyh7xGguhDCH2NQ1gfod3MBIURD4Eego5Qy/qbjTkCWlDJXCOEKtMCYLOTfK0H/6J2XhUZoQGNR\nsjpV/6goilLhVKzgTFEecpfj06nkYIWtRfn9acWmZnMkwhiMHYlI5vy1NKQEjYlAIwQ/7w+nY51K\nvNq2GnWrONy4UEpY9wZEH4Vmr0K9PmD64Ka05ej0HApP4kh4Eocjkvg7KoXcPAMAAa42tK/twWN+\nzphqBJM2nefZ7/fxUjM/3mpfo8wSW+gNklXHopm69QJxabmYaQRzdofhbGPOU4HutK9diZbVXW+b\nKlgUKSVJmVoiErOo5maLg/W9t1FvkMzZHca0rRdwtjFnyZAmtKxeNskfalWy55N6KXD8IvEtP8fE\n9NFOFiKlzBNCvA78CWiA+VLKs0KICcBRKeU6YDJgC/yWv2bvipSyGxAI/CiEMGCMcCfdkuVRURRF\nUYpUsYIz9Qme8pDSGyQzt19i1vZLuNiYM/qp6vR53Aez+zQt7ExMKvP3hnM4Iono5GzAmPihkY8T\no9vV4DE/Jxr4OJKl1fPzvnAWHYhk05lrtKzmyqttq9KsqgviwLdwYjE4eBuDtL++hGavQeNBYFE+\nI22p2Tp2Xohny9k4dl6IJ1OrR2MiCPK0Z0BTX4L9nAn2c8LVtvBIQLtAD6b8eYGFByLYfOYa47vX\noUOdSv+6HVJKdl5MYNLG81yIS6eBtyPf9G1EbU97dl1I4M+z19h0+horjkZjba6hTQ032tfx4Mma\nHthYaIhKziY0PoPQhH8emYQmZBSM9NmYa3ixqS9DW/rjbm9Z2sbBlQOkhWxjVEQz/orU0imoEl88\nVxensl4ftmca2Ljh3npI2db7kJJSbgQ23nLs45u+fuoO1+0H6pZpY0rQP15NvoyFqQXedt53Laso\niqJUTBUrOFOUh1BKlpZRy0+y62IC3ep7EpeWw0e/n+XnfRG807EWHep4lFkmvMzcPKZtvcjP+8Kx\nszSjeVUXBrfw53E/ZwIr2922Dsva3JRxHWoxsk1Vlh66wtw94fSbe4gBHhFMSP0YArsjXlgAYTtg\n7wzY8gHsngxNRkCTkWDtXCbtvllcWg5bQuLYcvYaB8MS0eklbnYWdG/oRfvaHjzu74y1efH/Ndlb\nmjGhexDPNvTi/dWnGbH4GO1rezC+ex0qO1iVqj1nYlL5ctM59l1OxNfFmu/6NaJz3UoFP7Mu9SrT\npV5ltHkGDoYl8ufZa2wNiWPTmWuYmghMhECrNxTU52ZnQVU3G7rUrUxVN1s8Ha3443Qsc/eEsWBf\nBD0bV2FE6wD8XG2Kb1hGArrjS9AeWYhNejj2wAuyGZ17zuH5YO+yz64Y+zeEbod2H4NZ6V5DpWK4\n3wlBFEVRlPtPlOd/5MHBwfLo0aOFjp07d47AwMBya0NRbk4V3KpVK86fP09GRgYuLi7MmzePDh06\nPND2VYTXSCna2aupjFxyjGupOXzStQ4vNjGmw95+Lp5Jm89zOT6DYF8n/tc5kMa+Tvd0r20hcXz8\n+xmupubwYhMf3ulYCwer0k09y9Hp2bzvMG13vkCcwYGx9lN49vGa1KhkR1U3GzzTz2Cybzpc2Ahm\n1sZRtGavgUOVe2p7fFoOa07EsOnMNU5GpQDg72pD+zoetK9diYbejpj8yzVdOr2BeXvDmbHtIhoh\neLtDTQY287vrGrHo5CymbrnImhMxOFmb8Wa76rzYxBdz07uPdhoMkr+jU9h2Lo48g6Samy1V3W2p\n6nrn6YuRiZn8uDuMlUejyTMY6Fy3Mq+0rUodz5ummhr0ZJ7fRureuXhc3Y4GPUcMNVgjnqKVayad\nEhfCcz9C/T6leo1K5LdBcHk7jDkDlg53LX43QohjUsrge2/Yo6Es+sewlDA0Jhp87X3LrF0VvX8E\n1UcqivLwKa6PVMHZQ0C9RhXTqmPRvL/mNE7W5nzfvxGNfAoHX3l6AyuORjNt60WuZ+TSuW4l3ulQ\n6+4jJreIS8vh03Vn2XTmGjU8bPmyR10a+/7LES1dNsxrj0yOYEfrX5lyVM+52LSC01ZmGgLcbGhh\nn8Bzmb9R8/qfCGGCockraJ7+FExKnnQiT29g18UElh+JYsf5ePQGSb0qDnSoU4n2tT2o5m5bpqM/\nUUlZfLD2DLsvJuDtbIWT9Z2n/EkJF+LSEcDLLf15pW1V7MtpQ+b4tBzm7Qtn6cErZOTm0aqmLabO\nS2iRpqN7xH7c9HEkSVs2mjxBfPXeNGzchMZ510n7cTYe/ucwyz4Hr+wFJ7+ya1RiKHwbDC1GwVOf\nlkmVKjgrnbLoH8NTwxEI/Bz8yrh1FZvqIxVFedgU10eqaY2KUkraPAMTN4Sw+GAkTQOc+bZfo9vW\nRAGYakzo18SH7g08+WlPGHN2h7HlbBwvNvGhXaAHVd1tqWxveccRI71BsvRQJF9vvoBOb2Bch5oM\naxVQopGdIkkJ60fBtdOIfr/SrkZznmwuSczU5q+XMq6TuhyfwcY4R35K6Y+n7MAo09X0OjCLI8cP\ns6/+JOpX9aKxr9Mdg5mopCxWHI3it6PRXEvLwdXWgmGtAnheF0klRwPmAVaYudn8u8BMlwPhu6Fa\nu9sCRW9naxYOfowNh0I5sXkP4a61oZh71Peuwqttq+HpWL5T+NztLflfp0BebVuNJQcjWXNqEnEm\nhzgKXHCwp4njawS07E0/Pw9MTAS5ly4ROXQo+uRkaNeaKlXOw+oRMOgP0JTRf+H7ZoCJGTR5pWzq\nUx6I+51KX1EURbn/VHCmKKVwLTWHV5ce4/iVFIa3DuCdDjXvut+WjYUpo5+qQb/HfZi+7RKLD0ay\n8EAkYEziEeBmQ1U32xsPdxt0eZKPfj/DyagUWlV35bNng/B1Kd2I220O/QinfoUnPoAaxqlIGTt2\nYBITQ5OBA2kS4FKoeLZWT/j1TC4ntGfzsZ94+soMLA8O5uXd47guHKlVyZ7H/JwI9nOmobcjf0en\n8OuRKPZevg5AmxpufNqtDu0C3cn+czMx77xFVH7dwsICc39/LAL8MfcPwDzAH4uAAMz9/DCxKiZY\n2vwuHFsAdZ6D5+bcll1SCEHjtfOotnYtzi+/jPu4t8t+bVYZcbAyY8BjtiyNPESLHD32vu3ZxHaS\nPU7ztecAY2AWFkbk4JcRpqY49OxB6qrVZH02GuszE2DvNGjzzr03JO0qnFwGjQaCnce916c8MEII\nDAbD3QsqiqIoFZYKzpSHWmZuHuevpdHA2+me9qG6GJdO+PXMYsuk5+QxadN5srR5fNevEV3qVS7V\nPdztLfmyR13GdajJxbj0glGq0IRMjkYk8/vJq4XKu9iYM6N3A7o38Lz3ACNiL/z5PtTsAq3eBiAv\nOZmr776HISMDMx8f7Nq2LXSJlbmG2p721Pa0h/qfwIUmBK0czF67z1hRYyp/Jpiz8lg0i/IDTQBP\nB0tGtavOC8HeeOWPSOliY4n9dDyW9evhMW4cueHhaEPDyA0PI/v0GdI2bTaO6mEM2rx/nI1N06a3\nP4dzG4yBWZXH4ewa0GZCr0WFkldcO3+c5N/XkuRsCvPnY8jIoNInHyM0pd8DrDws/mM46QJGN/uA\nWvVepPnltUw8MJFe63sxveo7WI76DACfhQsw8/AgY/du4lcdw7fn84idk6Dqk1Cl5DMHZx2fxS/n\nfyHINYhG7o1o5NGIeifXYC0N0OLN+/U0lXKiRs4URVEefio4Ux5aeXoDwxcfZd/lRLwcrXghuAq9\ngr1LPE0tMzeP9X9fZfmRqIIkFXcT4GbDsmFNqO5h96/b7WxjTtMAF5reMlKVpc0jLH9qYVKmluca\neuFYzLqpEkuNhhUvgXMAPDcbTIwjfYlz52LIzMTM25trH32M9Yb1aByKSQRRsyNi8CYsfunNgJAR\nDOi1iDy/9pyLTedEVDI+zta0qu5WKEiWej1X330PmZeH19dfY+7ri3Vw4WDCkJuLNiISbXgY8VOn\nEff5F/ivXVM4oEq/Zkz3X7m+cTrfyaWwYQwseR76LsNgYcvqS6tJ/2giDUzhwwEa3rxcndorVmDI\nyMDzq0kIs/Ldt0sXF0f2sWNknz6DVcMG2D39dKEgO/XMShZnhfK0tRe16r0IwLPVnqWGUw0+W/UG\nqSNGg4k1NZYswyIgAAC3N9/k2kcfk97vC+ztD8HqYTBiT4m2Plh1cRU/nf6JYI9gUnNTmf33bCQS\njZTUCqhBo8sraOTeiAbuDXC1Kpu905TypYIzRVGUh58KzpT7Lk9vIDo5u2APqH9Gi1KytHzarQ6t\nqrv9q3on/3mBfZcTGdrSnwtx6czYdomZ2y/RpoYbfR7zoV2g+237jEkp+Ts6leWHr7D+76tkavVU\nc7flwy6BNA1wKW6JEgBV3WxLtAHxv2FtbkqQlwNBXveeKa+ALgd+7Q95udDnF7C0Nx6+do3kJUtx\n6NYNp4EDiOjVm7gvvsDzq6+Kr8+zAQzbDkt7wdLnMX1mBnUbDSi8ufVNkn7+mazDh6n8+eeY+xad\nQc7EwgLLmjWwrFkDhAkxo0aRumYNjs8/byxgMMDaV43JTHrMNU5lDB4MFnawZgShizszwdOH+HOn\nmHpGj+mAF+gSbMt46yX86juAtO8XY8jMxGvmDEwsS7nHWAlJgwFtWBhZx46Tdewo2ceOo4uJyX+C\nJvDzz1g1bIj7uHFYN2oI6XEs2P0BWdbmvNJueqG6qmU78OkyAxl6De/1yiE4YQnvB7yPhcYCxx49\nSF60mPhvZmP33XeIpd1h83vQ/dti23cw9iCfHfyMFl4t+PbJbzE1MSVdm86p7R9y7OIaTvjXZsWF\nFSwOWQxAbZfaLO+yvMJOCVWKplLpK4qiPPxUcKaUmczcGyM/N4KwDCKuZxXaB8rV1rgPlN4gGbH4\nGMuGNaW+t2Op7rX+76v8uDuM/k19+PCZ2sCNRBQrjkYxcskxXG0teL5xFXo/5o2TtRlrT8Sw/EgU\n56+lY2Wm4Zl6lenzuDeNfJzK701objocXwy27uDbHOw979+9pIQ/3oKrJ6D3UnCrUXDq+nffIw0G\nXN94A/MqXriOGMH177/HrkMH7J58svh6HarAy5vht5dg3euQHA5PfFgwIveP7LNniZ85C7v27XHo\n8VyJmmzX/mmsGjYkYeYs7Dt1wsTGBg7PMe6/1WVaoeeQW7src+L2Mj96GzYJqUw9Ww2NVRQBr4xh\npI2GDaEbmFT9AtM/+Zi4CROJGj6CKt9/j8a2ZGv3jscdJycvh+ZezYs8r09JIXXDH2Tu30/28ePo\nU4yjrxoXF6wbN8Z54ACsGjXGomYNUn//neuzviGyXz/snn4a82qXWGpvSkfPFlR3rVNQpy42liuD\nBiEzs6i5aBkddX8x59QcLiRdYFrbaXjaeuI+7m2iho8g+cAVnFuOMa49q9EBArsW2c6w1DDG7hyL\nn4Mfk1tPxtTE+N++HSa0OLWOFt7NoNuv6PQ6QpJCCNu8CpPTcdClRC+TUoGokTNFUZSHnwrOuLGP\ny8mTJ3nllVdIS0tDo9HwwQcf0Lt37wfdvHIjpSTuyy8xdXbBdeSIIstka/UkZuZyJTGLywkZhbL8\nxabmFJTTmAh8na0JcLPliVruVHWzpdot+0DFp+XQc/Z+Bi84wm8jm1HV7e5TswDOX0vjnZWnaOzr\nxMfP3Hhj6+1szVvtazKqXfWCFO4/7Qlj9q5QzDUmaPUG6no58PlzQXSr74ldOaVOL3DlEKwZjiEh\nApN//vIcfcCn2Y2Ha43bgpxSydPCtVMQud+Y1fDyVmj9DgQ+U1AkNzyclNWrcerXD/MqXgC4jhxB\n+o4dxH7yCVYNG2LqdJc92Sztod8KY/C3ZyokR0D378HMODJlyM7m6rh3MHVyotL4T0sc/AohcH9n\nHJF9+5H48wLcXmgLWz+GGp0g+OWCcodiDzHx4EQi0yJ5xuNxRv+1jaQDF3Aa1BdTJyfsgTcavcGE\nAxM43Lovzb7+mqvvvceVlwbi/VZ3TGN2GNPHWzuDtcstD2fCyGPkycnkGnRMazuNdj7tAOPfSNah\nw6SsXEn6li1IrRYzXx9sn3wS68aNsW7cCDNf39uer9MLL+DQpQuJP/9M4pwf0W/X0rehhm6f3/g7\n08XFEfnSIPSpqfjMn49VUBBvEESQSxDv732f3ht6M7HFRNq0aoNN82Zc/+47HDZtQBO6wzjl0ysY\n7Auvg0zOSea1ba9hZmLGt+2+xc78pum4xxZCdhK0HAuAmcaMmslWWM7YiJm3N1KrRVjcnoVUqbju\nx8iZ6h8VRVHKl9rnjBudz8WLFxFCUL16da5evUrjxo05d+4cjo6lG9Upa+X1GiVt2Ejc228BcPS5\nYRyp9wTJWVqSMrUkZ2pJytKSoyucCczWwpSq/2QbdLct+NrXxaZEKd/Dr2fy/A/7sTTTsPrV5njY\nFz/tLCVLS7dv95Gj07PhjZa436V8XFoOPx7YS3xmAiObdL6nKYP7r+7HwcKBOi517l74Zvo82P01\n7J5Mis6LmHWC9F4t8GjtQ5WrIZhFHYLMeGNZKyfwbgrej4G9V0GwUBA4mNsWTg+fkwbRR+DKAbhy\nEKKPQl628ZxzANR6Bp4aXyjgix4zhoxdu6m2dQumLjfWveWcP0/48y9g37EjXlMml+y5SWlMw77t\nUwhoC32Xg5kV1yZMIPmXZVQrRdQAACAASURBVPjMn4dN86JHnooTPXoMGbt2UrWfBWZch1cOkGNp\nx5nrZ1hzeQ3rQtfhbefNh00/pLlnc6KG9Cfr8FGq9RVohq0Ft5roDXr6/NGHlOxE1vn2Im/DKmJW\nRWFul4d3Z4FZ1fqQkwpZicZHjnHkK1sI+nl6kKTR4KmXXDQ3Z07QJ/geSyRl1Up0kVcwsbfHoWtX\nHJ/viWVp/jbjzxE/60lWhDrzxN8SUytrXIYNw75LZ6KGDScvIQGf+fOwql+/0GWRaZG8vettzied\n54UaL/CmbVdie72I88uD8Rj8LPzYGrwfh/5rCn7WWr2WYVuGceb6GeZ3nE99t5vqzNPCrAbGvdIG\nbzQeun6diF69kTodfit+xaxy6RLe3Ertc1Y6ZdE/Xs24Spo2jVrOtcqsXRW9f4SK8T5CURSlNNQ+\nZyVUo8aNKVOenp64u7uTkJBQITqf++lyfAard52l9eefEu/gRZKlPcFr57E/y4KMmg2oZG9JYGV7\nnG3McbI2x8naDG9na6q62eJhb1HkqIjU64u/acoV2DYe/+CXWTD4cfrMOcDAeYdZMaJZwcjarfQG\nyajlJ4lNzWb58GY3AjODocjRpixdFosufMequCUYpIFa8YnU8Xyt1FMYpZT88PcP/PD3DwB0qtyC\nN5p9gLed990vTgyF1cPRxxxlbeATyCXh1NFqsV26i3FCQ6i3Gd7VA/G3bIO/QeCfmYR/wgUCLm3G\ntqgPTjTm+YGaKyAhPgSkAYQJVKoHjQeBbzNjgFdEWvTsM2dJ37QZ11dfLRSYAVjWqoXrKyO5/s23\n2HVoj/3TT9/9+QkBLceArYdxXdiv/UmvNILkX5bhPHjwvwrMANzHjiF965+c2pPKrje6cHz3GM4m\nniXPkIepMGVY3WEMrzccS1NLss+cJWPfMVwH90Gj+QV+7gTdv0OTcJ53464x2CyFBQc+5xU3V7xf\nbUPU3ENE7nXHe+BkzNzdb9xUr4ecZCYf+Yroq3uY6duXgP372XvoMhaTPiBBgnWDINxe+wq79u1L\nv34tLxdWDeVnTweW1TDlmf99h+bH5STMmEHCjBkIa2t85v50W2AG4Gvvy9LOS/n2xLcsOLuAI/ZH\n+KpTW5IXLcapbz/MO3wBG0bDoR+g2WtIKflk/yccjz/O5NaTCwdmYNxSIS0Gus4CwJCTQ9Rrr5GX\nlITvkiX3HJgpD8b9XHP2qPaPiqIo5a1CBWdfHf6K80nny7TOWs61ePfxd0t93eHDh9FqtVStWrVM\n21NRZGv1/HE6ll+PXOFIRDJjTqzALjeTvC+n0b55fa4OHMDofQvwe/0XLKpXL1Xd6Tv+4uq4cVjW\nrYvr8GFYN2tWOCDKSYNfehsDizOrqNtyDD+9OIxBi/5m6KIjLB7SpMikG9O2XmDXxQQ+fy6Ixr5O\nxgBv4ziIOQYD14FH7YKyu6N389nBz4jNjOWFGi+gM+j48dSPRGdEM6H5BMw1JcuCqNVr+XT/p6wP\nW0+39Awq5elZZNjD1lWd6esWzIjWn+NgV8S6MSnhxBLkpnfZY23J9MBgzC5eZvwlPdr+3TD76xAf\nb8ph32fPcUHGEp4azu60K+TJPLABUzt/Pq//Jp2dgm6M7GQlQtb1/H+TQK+FWl2M0yGrBBsTZNxF\nwvTpaBwdcX55cJHnXYcPJ337dq59Oh7r4OC7T2/8R4N+YMgjb8UoYqddwKJmTdzGjC7Ztfl0eh1b\nI7dyJO4IJ6L30qIRdD5qwV+nduMYWI+BtQcWZBN0sLgxAnr9m28wcXDA+bW3IXcALHoWlvUBINiz\nIR1sfJlvYs6zz66nsp0nvq3+5srwEYR16lxkO17If8BikoEgRwe2NMlmXx0dU7U7cdA5QGpVsCzl\nCOr2CcRdP8cKX1+6Ve2KX72W8F1Lso4cIWnJUpwH9Me6UaM7Xm6uMWds8FhaerXk/b3v80bAfmYK\nSfz0aVSZMgUubYUtH0HUYea4VWLDlY283uB1Ovp3LFyRQQ/7ZkKlulCtHdJg4Or//kfOqdN4zZqJ\nVVApn5dSLkrSP2r1WvIMeVibWZeoTtU/KoqiVDwVKjirKGJjYxkwYAALFy7E5F7W/9xHUkquZ2gL\nkm9oQ/fglnyKE76DCka4nG3M8v81x8nGHEcrM85fS2f5kSv8fuIq6bl5BLjaMClAS/21h3EZOoQ6\nnVoC4P3D94T37k3UyFfwW/HrbaMsd5K0eAlxX36JRdUAtKGhXHl5CJZBQbgMG4bd008hpAFWvgwJ\nF4xJKi5uhr3TaF55B3M6f8HgDcm8/stxZvdvXGhz502nY/nur1D6POZNv2BP2P8N/PUFIIz7XC3p\nAUO2EG9uyaTDk9gauZVqjtVY3Gkx1cO1pK5bQxtdfXbtX893207Rt8kI7N290Dg5GR8ODrfthZWa\nm8rov0ZzNO4or9vVZnjEVsSIXfS++AffXVjO0oQjrF35NMNsatCv6btYeDcxjiRlJcH6Nzkbuplp\nXn4cFrn4mFrwyXFvTN2zqPn2eHKfCyWyT1+6LAtj5A8/IExM0Bl0RKdHE54azsKzC3n/5Ew0rb+i\nQ81b3lz/S5kHD5K5bx/u776Lxrbo9X3CzAzPLycR/vzzxE2ciNe0aSWuXzYcwNWvlmPIDcOrnQkm\nmpKNUEop2Rq5lZnHZ3Il/Qq2pjY0yEzHNdgccU7DN+cb4vfW3CKvzT55koxdu3AbM8b4nGxtYeg2\n43o732bgUIWxGVfZubYb045PZ3KbyVjVr4//r8tJ3/FXwf5qAIk5iSw9txQPaw9eqPECJsIEMx9v\n7Nq0wSwrihUbBzDC4MCii5twOf0bVO8ArcaCTxF7st0q9C848C0/1WqOQXuN4fWGF5yyfuwxrB97\nrESvFcDjlR9nVbdVfHbwM9YG/0HPPzZy5YXO+Dz7Pez6mk0XfuPbbEu65sLw5BRIjQEHrxsVnN8A\niZfg+fkgBAmzZpG+aTPub79VstFSpUK73wlBHob+UVEU5WGm1pxxY049QFpaGm3btuX999/n+X9S\neT9gISHniDNx4UJcen4CDmMSjtRsHQD2ZLLdYhxuIoUecjLHc72Krc/C1ITOdSvT5zFvgitbE/7s\ns2CQBKz7HROrG3uEZZ8+TeSAgVjWqoXPwgWYFJMcQOr1xH31FcmLFmPbrh1ek78GjYbU338ncd48\ndJFXMPf3x+VxOxwMmxHdZxjToQOErIP1b4Iuh4M1xtLneG16N/JiQlMXZGYmUc5VePa7fVT3sGNF\nVwvMN44xJr2o0RE6T4acNAw/d+Y3Jxdm2FmgNegYWX8kg+oMgutJhD3T1Tj1UUoMWVlFPwEh0Njb\nFwRrWjtLDmSdIc4sm+a12hN0eR2aKjWweXuFMYOglFwKWcX0k7PYk5eMpy6PN6Qdnav3JPb4fGZZ\n6tloY4WThRMj6o+gS7QbsW+MotKE8Tj16gVA0i+/EDdhIu5vv4XL0KGFmpOly2LktpGcTjjNlLZT\nChJSlFSuPpevD3/N5ojN2Jvb42ThyLBvQrFLy2PXlBdwsHfD0cIRJ0snqjtWx8fep9D112fPJmHG\nTLxmzMC+Y4c73scgDfwZ8Sc/nf6JNoezab8yAucXW+OhXw61n4We80Bz58+ATsSfYMrRKZxKOEU1\nx2qMaTSaFnt/RHNpCwzbQeKmY8R//TXe8+Zi26LFbddfGTKUnJAQqm3bavy53MH3J7/nh79/YEHH\nBTT2aHzb+ey8bPr90Y+knCR+6/ob7tbut5U5GX+SYVuGEWDvy3y7htgcnmtMqOHgbUzk4loDXKvf\n+NrW/Uaw/kNzYi1s6Oxg4Llqz/Fxs4/v2NaSklLyx5mVuA76hGsuJpj+8CVV7LwZ8ucQgqwr8VOG\nBvPwXcYpr9WehsYvQfX2MPcpyE2D14+Ssm49se/9D4fne1J54sQyzVqq1pyVTln0j/FZ8SRkJVDb\npXaZ/Swrev8IFeN9hKIoSmkU10eq4IwbnY9Wq6VTp0507dqV0aNLNyXrfjp84hS9fo0CwM3OoiDp\nRjV3W6q62dL41Hiszy5FmJhB/T7kdJpOSpbOmMjjn4QeWVoSM7S42lnQrZ7njYyJ06aTOGfOHRM3\npG3+k5jRo7Hv3BnPqVOK7PANWVnEjHuHjO3bcX5pIO7vvFNoFErq9aRv2cL16V+SeyUBUwdLnF8Z\nhdMLL4AQaCMiyD17HO3m2eReiSYj04HcFD3mBuO6tfltB3PIK5BN9XZhc3Ie2LhD568hsBsIwcXk\ni4zf+Tan0sJpYjDj465L8XENREpJ1IgRZB05SsDaNZj7+mLIyeHkpT1M3vYRdlnwesBAqugd0Ccl\noU9JJi85mdS4KK7GXMAmS49jjgahyyt4Lpa1a+O7fBkm5jemRR6K2M7UQ19wLicef62OaDMzTDRm\nDKjzEi8HvYytxhgAS10eARvWI0yNwYqUkpgxY0nfuhXfxYtum9KWoc1gxLYRhCSGMKPtDNp4tynR\n70tsRixjdhrXaHX064iJMMHl8GW6zg3hl+ec+DMoj+x/koZgTL/9pM+TDK07lCDXIGPb8vKI6N0H\n3dWrBGxYX+TI6ZFrR5h2dBpnEs/QLNeb12dFcMYHvu3vwDM2fvQ8s5WaNbtDjzlgUnhUMjw1nJnH\nZ7L9ynbcrdx5veHrdKvaDc3JpcbMg09PhBZvYtBqCevUGRNbW/xXryr0e5V17BiRL/bHfdw4XIa8\nfGvzCsnOy6brmq44WzqzrMsyNLe055P9n7Dm0hpmPzX7jqnzwThd9s0dbxJcKZjvW03G/PRKiDoM\n1y/C9Uugy7xR2MLBGKzl5ULCeT5t3pd1sfvY2GMjlWwqFdve0ghb8AO5k2bxdU8TTtWyxMPGg6Wd\nl+Jk6QRJ4XBiifGRcc2YcCY7GbrOJMtQh8iXh2DdqBE+P81BmJfBhuc3UcFZ6ZRF/5iQlUB8VjyB\nLoGYiLIZ1aro/SNUjPcRiqIopVFsHymlLLdH48aN5a1CQkJuO1bebGxspJRSLl68WJqamsr69esX\nPE6cOPFA22YwGORfB4/Lnt/vkylZ2tsLhO+V8hN7afjjPan7ZbiUEz2kzEwsUd3Z58/LkDpBMubd\n94otl/DjHBlSs5aMnznrtnO6+HgZ1vN5GRJYWyYuWnznSi78KQ2fOMr0CZ1lxIABMqRmLXmuXn0Z\nUrPWjUdgbXmpdRMZ+WSAjHq2qpzSd5Bc36qzPFknSKa9X1PKTxyk3DBWyuwUaTAY5LFrx+T7e96X\nDRY2kK2WtZLr9kyUhk8dpVz0rJS6XJm8cqUMqVmryHZFpEbIzqs6y0aLGsnN4ZsLjm+J2CIbL24s\nO67sKMNSwqTBYJB5P3WVuZ8EyuQVK2RIzVoydsLE2+rTG/Ryfeh6+cKa7vKD3f+TsRmxBeeS16yR\nITVrydRNm267Li8tTV566ml5sU1bqUtKuu18Wm6a7L2+t2y4qKHcE72n4LhBry+y/P6Y/bLlspay\nydImclvkNmNZnU5e7txFXu7UWRp0OimllFm6LBmbESvPXj8rvzn+jWz2SzMZtCBIDvlziNwfs18a\nDAaZc/GiPBdUV0a98aY0GAwF97gUfUqOnzdQvvJWbTl9WLA8NLinvNC8hbzQtJk8fOZPOW7XONlw\nUUMZtCBI9vmxuvxtWXeZkZMqpZTyetZ1OfHARFl/YX35+JLH5Y9//ygzc1KlvLxDyg1vSflZJSkX\nPCOlXl9wv9Q//pAhNWvJ5FWrC/8MB74kL7RoKfVZWbe9DkXZGLZRBi0Ikr9d+K3Q8XWX18mgBUFy\n5rGZJarn98u/y6AFQXLsX2Nlnj7vxgm9XsqUKCkvb5fy4Gzj7+qCZ6ScWlte2TVJNljYQH5+8PMS\n3aM0DDqdvNSpkzzatpnsufpZGZoSenuhPJ2U5zdKubS3lHOflrmhF+WFx5vIyx07ybyUlDJvk5RS\nAkdlOfYvD/ujLPrHhKwEeSbhTOHfy3tUkfvHf1SE9xGKoiilUVwfqUbOKrgsbR77jp4iycyV3o8V\nnnqGLgdmt0Tqcog624SsI0dwD0rA6dX3EC1HFVuv1OuJ6NMXXUwMAX9sKDbxg5SS2A8+JHX1ajwn\nf41DV+Nmt7mXLnFlxAj0ySl4TZ2K3ZNPFF1B3FmY1wGc/WDwZrCwJfvkSVI3/IGpqwvm/gFYBPhj\n5utrHJGKO4tcNRQRH8LpDF8stuRgam+O34LZpFSpzfrQ9ay6tIrw1HBszGzoVrUbr9Z/FUdLRzi+\nCNa9gc67G2E/nMcyMBCfhQsQRayNSM5J5s0db3Iy4SSjG41GIzRMOzaNem71mPXkLJwtnY37d82s\nD23fh7bvEvflJJIWLsRr5kzsO7Qv9jUGjCM/HTuhcXLC77cVRbYj+8xZIvv2xaZ5c6r88P1tZVJz\nUxm2ZRihKaF80+4b6oVL4idPIff8eWxatcJl2FCsgoOZf3Y+35z4Bn97f2Y8MQM/Bz8AUlatJvaD\nD/CaNRP79kW3OVOXyW8XfmNRyCISshOo41KHIXWH0GBzGNenz8C+cyeyr8eTeikE6+Qbo26YmmLu\n42Ocsjrk5YLRv5ScFP4I/4OVJ2ZzWZeCFSa09HmSfVf3o9Vreb5ad0baVMcldJdx3WFOKphaQfWn\noNPkQvt1SSmJ6N2HvLg4qm7ehImVFZkHD3Fl0CA83v8fzgMH3vXn8E89gzYPIiItgvXPrcfe3J6w\nlDD6/NGH2i61mdt+bsEGzXez4MwCph6bSu+avfmgyQd3nUL24d4P2RS+iU09NxU5ZfJepf/1F9Gv\nvIrHRx/i/OKLxZbVp6YS0bsP+uRk/Fb8irmvb5m3B9TIWWmVRf+YmJ3Itcxr1HSuWeLf5f8C9T5C\nUZSHjZrWWIEZcnLIi4/H1MOjyDVdMSnZnDt3jscb1sX+1k2Td3yO3PU119J7k7JxDxa1A8kNOYeN\nt8BzyV+YetyeSv0fSYsWEffFl3hOnoxD12fuWO4fUqvlypChZJ88ic/CBcicHKLfHIWJlRVVZv+A\nVZ07ZHhLj4O57cCQB0O3F05MUBxdDvpt4+HEEjIcenL1mz8518qbia0TyDPk0cCtAT2q96CDX4fb\nMpPJ3VOI+vg7spJsCNiwEXMfnzvcxLg268O9H7I5YjMA7X3b83nLz7E0zU+Tvn0C7J0Oo8+AgxdS\nqyWi/wC0YWH4r1mNuXfx6fSTFi0m7osv8J47F9uWt6+ZKii3dClxEz/DfdzbuAwZctv5lJwU3l/4\nIm1+j6RemB4zLy/s2rcndd069ImJXAtwZGGjNFzbdWRCy4kFr4khN5fQjp0wdXXFb8Wvdw0itHot\n60LX8fOZn7mSfoUAG18+WqbHIiyGSCc9MS7gUqs+zZv1wqVWPcy9vRFmd97MW0rJ6T/fZtXl1Wy3\ndyTYzp/RWRK/8P2Ql2OcZlejk3GT7IAnwLzoLHNZR48S2X8AbqNH4TJiBJH9B6CLiqLq1i3FroW8\nVUhiCH029GFA7QG83vD1u64zK87Uo1NZcHYBTSo1IdAlEH8Hf+PD3t/4QUG+yLRIuq3tRr9a/f5V\nZrySkFJyZdBgcs6exTo4+EaiGydHTAu+dkLj6Mi18RPIOn4c35/nYx18/2InFZyVTln0j0k5ScRm\nxFLDqQZmmjv/Xf7XPOrvIxRFefiofc4qKGkwoIuKxpCbgyErG3N/v0JvNA1SkpqlxcpMc3tgFhcC\ne6eRnNGSlI17cBk6BLe33iJ56rvE/7yOsK5dqDxpcpGjWbqYGOJnzMSmVSvsn+lSorYKc3OqfDOL\niN59iBr5CoasLCwCAvCe/QNmnkWkkgfQZcPyvsbU74M3FQrMcvW5bI/cXmjt022qBhNXqQq/h66j\nbVPBs3uieKtuG5oNHEdVxzuncE6J9SHzmiUejRMxj1wJPmPvWNZCY8FXrb+ilnMtJJKXg16+sVZD\nrzOu1aneoaDtwtwcr2nTCO/Rg5jRY/Bd9kuh9Wc302dkcn32bKybNMGmRfH7fTn160fW4SPET5uO\nVcNGWDdqWHBOd+0aWTNn8cbacLIsBb88bcGz73xGNe+mZLzUlZXTRtBiVwLvrgTzkxfRpW9DduqE\nMDMjedky8mJj8fzyixIlCDDXmPN8jed5rtpzbL2ylfmn5zO42zmQkqf9OjCq0Sh87Us+0iKEoF6H\nKdQzc2D8nqlAmDGBRuNBxg2yfZoVmzDkH9bBwdg9/RSJc37CrHJlso8dw+Pjj0oVmAHUdqlNj+o9\n+OXcL0SkRRCaEsrsp2b/q9GssY3HYq4xZ2fUTn459wtag7bgnJOFU0GwFpEWgbmJOUPq3h50lxUh\nBJU+/YT4SV+hi48j58IF9ElJyNzcIstXnvTlfQ3MlAdDYPwbv98ZGxVFUZT7R42cPUC62FjyEhMx\nq1SJvIQEMDHB3N+/4M1+WraOiMRM9EnRNKwXdONCgx7mdyD9ZDjROyyxa/ckXjNnGqfD6XXkflKP\nmD0W5Mbl4ti7Nx7vvoOJtXFEQkpJ1MiRZB05StX16zDzKuFIVj5tRAQR/V7EsnZtvGZMv2NKdgwG\nWDkYQn6H3kuMIyP5DsUeYsKBCVxJv1Kiezat3JSeAc9S86MlaC9cxG/VSiz8/Yssq4uJIaxbdyyD\ngvB5RoM4uxK6fQuNBpTqeQJwbj382h/6/gq3pLNP37aN6NffwKl/fyp9+EGRlyd8/z3XZ32D36/L\ni9xY+Fb69HTCe/RE6nT4r1mNMDMjcc5PJC1cCAYDTgMGIF56nqEHRhGXGcfQukOZe3oulqaWTGkx\niRrHE0j86SdyL13GzNMT50Evcf2H2capnfPnlf75Y/x9ORp3FGsza+q43MP+V1LChY1g7wWV6xuz\nGJZSbng4YV27gcGAaSUPqm7efMfAuDiJ2Yk8s+YZMnQZDKs7jDcbvVnqOm6lN+i5mnmV8NTwQo+I\ntAiScpLK7D6lIaVEZmejT04mLzkFfXIy+pRkTF1dsWnW7L7fX42clU5Z9I8puSnEpMdQzakaFprS\nfXDxMHuU30coivJwUiNnFZA+PYO8xERMnZ0xdXXFxMYGbUQE2vDwggAtOUuLqYkJpqa3rFM6Mo+c\n0yeI2eOFZWANPL/66sY6JY0ZFu1fxk98xnWz10lctoKsQ4fwnDIFq6A6pG3cSOau3Xj8771SB2YA\n5n5+VNv5F8LMrPiRmL8+g5C1xqx7+YFZck4yU45OYV3oOrztvPm+3fdUdyp+g2srU6uCDYd10xoR\n/lwPYsaMxW/5MkwsLQuVlVJy9cMPQUoqf/45opIb5CQb0/Rbu0CtojcdvqNjC8DOE6o9ddspu6ee\nwvmlgSQtXIT1Y4/dtv4sLzmZpHnzsXv6qRIFZgAaOzu8pk8nsm9fooYOQ3f1KvrkZOy7dsVt1CjM\nqxh/XvPaz2Pwn4OZdWIW9dzqMbXNVGP2vypg/8wzZOzcReKcOcR98SUAbmPGlO5530QIwWOVSr4H\nVzEVGTfMvgcW/v449e5N8tKluI4c+a8CMwAXKxc+af4Jh2IP8WqDV++pTf/QmGjwtvPG286b1lVa\nFzqXrk3HxuzOaf7vFyEEwtoaE2vrf/W3rjx8CkbOyvFDV0VRFKVsqeDsAZB5eehiohEWFphWMqbU\nNrGywtzPD214BNqICEx9/UjLycPFxpzU1JuCoNRodOsnELXfE42TC1W+/75gVKxAo0GY7Poa98Za\nbNr/zNX33iOiTx9cR4wgeflyLOvWxal//6Ibd3qlcX8m/9ZFn4e7vym+chD2TIVGA6H5G0gp+T30\nd6YenUqG1jhaMbze8BvrukrIrHJlPL+aRNSIkcR9OYnK4z8tdD7l11/JOnCQSuPHFwQy9FoEC7vC\nqiEwfCe41SzZzZIj4fJ2aPPOHafdub/1FlnHTxD74YdY1g4stP4s8cc5GLKzcRtVfGKWW1kF1cH9\nf+8RN2Ei1k2a4D5uHFZBhUes3Kzd+LnDz+yK3kX3qt0LrS0RJibYPfkEtk+0JfvoUfISk7CqG3Tr\nbR5a7mPHYNWwYbF7r5VER7+OdPQrm82978bO3K5c7qMoalqjoijKw69sNkL5DzJotci8vLsXLCUp\nJbqrV5F6PeZVqhTKzGcM0HwhLw9teDgafR6O1mY3X4xh7Vii/7JCn2eK9w/fY+ZRxFoZWzeo04P/\ns3fn0XVf9b333/sMmi1LnuJBtpNgZ4JAAiFAISGQQEMYmxAKKVygLWE9hTL1wkOhDBcutFCgPLdP\nWqA3XGgoZSjzFBKmXMotISEDTeIkdmI7lkfZmixrONO+fxxJtmzJVhzJ1j56v9byiv07g/bxylo/\nf853f7+bu75M83lnc/p3vk3r85/H3uuuo9zby4oPf2jCeVHjHrypGmK++prqwbnH9wHhpr+CluVw\n+d+wpX8rf3rTn/K+X72PU1tP5Wsv/hpvefJbHnUwG/9oz342i//0T+j96lfp+8EPxq8XOjvZ/fG/\npfn3fo+2V1x98AX1LfDKL0O+Cb72WihMcQj14e68ofrf86feDhnq6lj1d5+CENj+9ndQKVR7joo7\ndtDz5S+z8GUvo37dukf9GRddcw3rfvFz1nzhfx0RzMYsbVrKy894+ZRN/yGEakXvMYaYuSbT3MzC\nF71w/Kw4SQeN7WawciZJ6ZpWOAshvDWEcE8I4d4QwttGrz0phPAfIYT/DCF8L4TQOrtLnT0to31T\nsVLh9y+7jLbWVl74vOcxfP/9DD/4IIXt2yn19FAZGZnypveFL3yBN7/5zQB86lOf4pxzzuGJT3wi\nF1/yHB7avHn8eeWeHsr9/eSXLSPT2HjE+2SamsivPRXKJToO7KUhHPx58Z5vsuOG3zDcnWPVJz9F\nw9H22D/tWigMwN3/SnbhQlZ+8pOs+vSnWfXJT9Bw1llHPr9vO3zrjbDocTCyH37+kWn8zU3ivm9D\n520ULnk3n9lwA1d99yo27NvA+57+Pr74gi8ecxvjdCx961tpPP98dr3v/RS2bCFWKux8718RQmDF\nf//wkdstW1dUD0LuHhgYEAAAIABJREFUuh9+9M5j/4ByCe64AdY/D9qOPo2xrqODlR/9CMP33MOe\nv/0EAF3XXQcxsvTNbzrej0h++fJpDfCQpDGzUTlrOaSv+PLLL6etrY0XvejYE34PNdX98dJLL2Xr\n1q0ztlZJqgXHDGchhCcAbwAuBJ4EvCiEsA74n8C7Y4znAt8CpvGv3rmruGMnIw88wFtf+Uqu//jH\nydTVkR8db1/p76e4fTsjGzcy8sADnLp6NaW9e6kMDk0a1s4//3z+49bf8M2f/IqLn/8i3vaO6l9N\nZWSE4q5dZJqbyS5ZMuVayvX1bG9eQr5SojgaPhjqoevD72F/ZyPL3vnOqc8UG7PqKdVfv/kcVCqE\nEGi9/PdpvXySrVzlEsV/ez035yN/fsZ5vOvMp/Af9/wLlV3/+aj+DimN0PfTD/AvK9dz1bZvcN1d\n1/GcNc/hOy/7Dq848xUHpyA+RiGfZ9WnPknI5+l829vp/sIXGbz11mof3VSTI9ddChf9RXX64l3/\nevQfsPHHMLCrOlFwGsb6z3puuIG9n/ksfd/6Nu3XvGrqtUjSLJjtytk73/lObrjhhqM+59RTTz3q\n4+effz633347v/vd73j5y1/Ou971rhlcoSSlbzr/Wj4buDXGOBhjLAG3AFcCZwD/e/Q5NwNXzc4S\nZ0cslyl1dzPy0ENQqVDq6SbT0sLvv/KVLDrzzGo/2NKl1K1dS/1ZZ1G/bh35lSvJtLQQK5Hirl2M\nPPwQhYceojwwMOG9n/Gsi9k5UGG4WOEZT38GnZ3bODBcpNjZSQiB/KpVR62K9AwWGcrVk1m9hkqh\nQGnvXm75yz9g3+8yLHzxpSx6/eun9yEvfCPs2wQP/3zKp2zu28ynvv2HXBY6ecfiBdy3fyu/qhzg\n2uVLueLG/8Ln7v4suw/sPvrfZYzctus23v3dV/HcBRX+pn6Epnwz1116HZ949idY2rR0eut9FPIr\nVrDiY3/DyP33s+fjH6f5ootYeNUx/he85C9h7TPhB++Argemft5vv1Ddlrl++lsCl/3FX9Bw7rl0\nffrTZBoaWPzGN077tZI0E2a75+zSSy9lwYLH1kP5nOc8h6bRPumnP/3pdHZ2zsTSJKlmTKdx4x7g\nIyGExcAQcAVwO3Av8FLg28DVwKT7v0II1wLXAqw5ymHAALs++lFGNtw/3bVPS/3ZZ7H8Pe+ZcK3U\n3U1p1y5ipUKor4cQaDjzzPE+lsODUwiB0NBQnQ64aBEhn6P+zDOp7N9PqauLwpYtFPfuJZZKDAwX\n2do9SAiB05c2848f/Rcufu7zGdixi9ahIepWrz7qQI0YI72DBdrrKtTnA6WlC4i7drHsxt3cfWrg\nuif9lif+7M2cv+x8nrzsyTx+yeOnHpn8+JfBTe+tVs/WXTp+ebg0zM1bb+YbG7/Bb3f/lmyMXNKw\nnCsv/iDPXPlMSrHET3/2Xr7x0Hf4+7v+f667+x+4eNXFXLn+Si7quIhcpvr3tHdoL9/Z9B2+telb\nbO3fyoJK5A8ybVz1on/i7MWzP9Z4wSWXsOTP/ozef/u3ah/dsbYBZnNw1fXwmWdV+8/e8LMjDz3u\n3QYbb4aL/+u0zt8aU+0/+zu2XnMNi173OnKLFh3HJ5KkyU3n/liOFUJpiD25BrrDJH3Fh5ns/ngi\nXX/99bzgBS84aT9fkuaiY/7rM8a4IYTwMeAm4ABwF1AG/hj4HyGE9wHfBQpTvP5zwOegeo7LDK37\nMSnt3Ueoq6tWwhobIYRjDhh405vexK9+9SsAduzYwZOfWh0v/vKXv5x3v/GNMFKg3NfHgUc6aWhp\nZ/XSFr72lX/lt7/9Ld//1vdo3rebUnMrjQsXTnzjWIGhXigNQ2mYWBxmfXmETAViD+zM5ehvgvy5\nLSx491u4dOQh7txzJ/+7s1q0zGfynLvkXM5fdj7r2teRPfyGfPZzq+d1/ecXic1LuavrLr7/8PfZ\nX9jP6uYVvHX/CC/LLmbJH/0A8tUeuCxZrnju33DFxl/xSN8A33zGa/jO5h/wi85fsKxxGS983AvZ\n1r+NX2z7BaVY4snLnswbwyIuu/t7NL7xK3ACgtmYpW/5c5a86c8mH3AymbH+sy9dVe0/e+l1Ex+/\n80vV/x5lEMhU6jpWse7nP5v+WiRpBh38eurE3moPvz+ed955AFx99dW8972TnwP5pS99idtvv51b\nbrnlhK1TklIwrdJAjPF64HqAEMJHgc4Y4/3A80evnQE8tkOM4IR8gxdjJBYLZBcvJnv4CPqjuO66\ng/+IP/XUU7nrrrsmvOdg22JGsnlaC4O09gzxs1/dy0c+8hF+8bOf0dLfTSmbY1t+AetLFfJj55bF\nCvRsgeG+6p+z9YzEPAM0snhhK12VIfpH+mhoauWpX78NOPiX3DPcw5177uTOPXdyx547+OK9X6QU\np5guuWwJ3FEdVlGXqeOytZdx1eNexgU3foBM/wG49mAwG5fNweV/zZp/filvG4I3vfwmftn5S76x\n8Rt88d4v0lbfxqvPeTVXrr+S08rAdRfCedfA8hM/tv1Rh6Gx/rNffgJOvQie9Mrq9XKpOqVx3aXQ\nvvbErEWSpmE698eR0gibejexeMEq2urbTsCqqo52f5zMT37yEz7ykY9wyy23UF8/fw7LlqTpmFY4\nCyEsizHuCSGsodpv9vRDrmWAvwI+M5sLnSmxVIIYCcd5gO3hKjHS2TNE/0iZ2NhE3fp1/PZnP+PP\n3vEOvvtP/0Tb0BCVYpH82lOp9JfZ0TfE2sXN1ZHzPVurwax1FTQvoULg4Z39LGjI0Z8tsneoj/aG\ndjJ1R7YGtje089w1z+W5a54LwFBpiJ0Hdk6+yBvfUz177PU/YEnralrrWuEnH4Rtt8KV/xOWTDFB\n8fRL4KwXwS8/Rf68a8Z/Xt9IH025poNj3L/+esjk4DmTf0M6J13yl/DIf8D33w4rz6+ef7bpJ9C/\nHV7wsZO9Okl61FIYpX/nnXfyxje+kRtvvJFlyyY5CkaS5rnpjs/7RgjhPuB7wJtijL3Aq0IIDwL3\nAzuA/zVLa5xRcfQsqqnC2UUXXcTVV1/NT3/6Uzo6Ovjxj3885XuVyhU2dx2gd7DAwsY8zXVZsvX1\nvOeTn+TAyAh/9I538NQrruDqv/gL6he0sHRBPX1DRfYPF6F3Kwz3QuvK6qHPIcP+4RLlSqSxocyO\nAztozjezvHn5tD5XY66R0xeePvmvp7+F0w/0cPrW26rBbOPN8O9/B09+LTzx6qO/8fP/O1RK8JP/\nNn5pYf3Cg8Fs221w7zfhGW+ufpZUjPWf5Zvg66+rnn/22y9Ayylwxok5nFiSZtJsDwR5NPfHqbzz\nne9kYGCAq6++mvPOO4+XvOQls7BSSUpXOJHfsF1wwQXx9ttvn3Btw4YNnH2087pmWKmnh+L27dSf\nccZRB3McS7kS2bSnj0IZVrc30dZ05HvFGImFAqGujhAClUpk4579LK/sYSH7YcEKWHAwfG3dd4AD\nhWEydV1kM1lOW3gauUzusf8dxQifuai6jfKPvlb9/YIV8IafHrmdcTI//RD88pPwJz+B1U+d+L6f\nvxy6H4a33AH1j22K10mx6SfV/rMzXwgP/gie9Xa49P0ne1VS8kIIv40xXnCy15GKmbg/liolHuh+\ngOXNy1ncuHimlzhnneh/R0jSY3W0e+TMHDyVkGrl7NgDQI6la/8QpdwOcg07GSjvoW+kj3KlPOE5\nIQQy9fXjW00yAU7LdbOQ/QzULZ0QzErlCv3DBULdPgiwtnXt+FTExyyE6qHUe+6FL7wQSiPwii9O\nL5gBPOsd1dHyP3oXVCoHr2/4Hmz7NTznPWkGM4B1l1X7zx74QTW8Pvm/nOwVSdJxme3KmSRp9s3L\ncBbq8oTM8X/0QqnM3gMHgEhDroGB4gCd+zt5oOcBtvZvpWe4h2KleNgPjtDXSV2hh77sIraMLKBQ\nOhjm+oYKhPw+YiyxesFq6rIz0xM37tyrobG9OoDkxZ+eus9sMvUt8Lz/BjvugN99pXqtVICffACW\nnnVckw3nlEveA2e8AJ74h9B+6slejSQdlxR6ziRJRzdDpZnHJsZ47DOqZupnjW4zfCx29g1Dphq+\nVjavpC5bx2BpkP2F/fQX+tkxsAOApnwTC+oW0JhtoG6wm9zgPkLLMhqblsPuAXb0DnPqkmZijHQN\n7SZkRljZsormfPPB9c7UTTbfCC/8FOzfCU98xaN//bmvgN/8U3WQyNkvhru+XN3OeM3XH9V5YHNS\nNgfXfKUaoCVpDnk098f5WDkziEqqNSf9X9UNDQ3s27ePxYsXn5CAFgsFMq2tR39SpQz7d0E2D81L\nIByssg0Ml+gbKtLSXGG4EqjLVvvJmvPNNOebOaXpFEbKI/QX+tlf2M/uA7vHX5upq6e+MkL90C5a\nmrPsH4R9B6AYD1AOAzRl22lrODj+OMbIvn37aGhomJkP/4Qrj/+1mQy84OPwP58LN38A7v0WnHYx\nrH/ezKxtLjhBXxBI0nQc7/1xvoSzGb9HStIccNLDWUdHB52dnXR1dc36z4qVCqVdu8js30+2v3/y\nJ5VGYLAbxrYlZnLQ0AZ1TcQIe/YPEyP01x2gEivcv+f+o/zASBzuo1QYoJRvoJSto1TpplQpUY7V\nLY17to8+t1LHshbYsKtvwls0NDTQ0dHxGD/5DOl4CjzpGrj9eiBUJzkaaCRpVhzP/XH3wG4G6gbo\nruuexZXNHXPqHilJM+Ckh7N8Ps9pp512Qn7W8P33s/lNb2bVpz9N64UXTnywXKoeSnzLx6vnjl35\nWSgOwk3vqw7SWPUUbup4M9feUs8//NGT+e8bXs3TVjyNjz7lo0f+oL2b4M5/rm79O9AFF/xxdUvh\nIUFmf2E/399wN+/74c8IociTFz2Pr177+Fn+G5gBl32gOjzj7BfDiied7NVIUs06nvvj67/8eq5c\nfyXvetK7ZmlVkqTZdNLD2YlUeOQRAPKrD/uWrfth+Oa10HlbdSjEFX8LDQurj53+HLj7K1R++mGe\nv/31fH3h01m/6CP8v0N7WN9+yFCN4hDc9124459h679DyMKZL6hO/1v//CMqTAvqFvCqJz2L39zf\nwrfu3M5Vl52YgPqYLVgOb70b6hee7JVIkg6Tz+QplovHfqIkaU6aV+GsuK0TgLo1a6oXYqxWt370\nrmqYuup6OPflE1+UycL5f8RfP3IW9bd9hrfnf8hdN7wIVixlXf0S2HUP3PFF+N1XYbgP2k+DSz8A\n510zYVT+VN7/onNYs6iJlzwpoQOcG9tP9gokSZPIZ/JHTguWJCVjXoWzQuc2sgsXEpuaqQzsI/PD\nt8N934G1z4I/+Ay0rZ70dRt37+fzt+7mlU99C9nn/zWbbnwTDNzH+q/9CRRHIFsP57ykWiVb+6zq\n8Ixpam+u4+3PO2OmPqIkaR4znElS2uZVOCs+so386tX83fU38LodH2RxZj+Zyz4Iv/eWaoVsEjFG\nPvT9+2iuy/KO550BzfVsXHUuLQ9t4ZTz/gssflx1K2TTohP5USRJOkIukzOcSVLC5lU4K3Ruo/Hx\nj+fKnZ9gOGZ58dAHWb35GXzw3CLLF04ezn52/x5+uXEv73/ROSxuqQdgU+8m1rWfQbjiEydy+ZIk\nHVU+k6dUKZ3sZUiSjtP0998lLpbLFLfvILNsCY+Lj7BlzVW88Pcv5+cP7OGyT93CP//HFsqViWfD\nFEoVPvz9+1i3rIXXPGNt9X1iHA1n607Cp5AkaWr5rNsaJSll8yacFXfuglKJQm4QgPKqC/mzS9Zx\n09sv5vw1bbz/O/dy1T/+HzbsPHj+2f/61Wa27BvkfS86h3y2+le1d2gvfSN9rGsznEmS5hZ7ziQp\nbfMnnHVuA6BS2U0pZmg89akArF3czD//8YV8+g/PY1v3IC/6+3/nr3+0gW3dg/z9zzZx2dnLePYZ\nS8ffZ2PvRgDWt60/8odIknQS5TN5SmW3NUpSquZNz1lhWzWc1RcfYkNcw8plS8YfCyHwsvNX8ewz\nlvLXP9rAZ295mM//+2YA3vvCcya8z8aeajhzW6Mkaa6xciZJaZs/lbNHtkEux+LifdwRz2TFwoYj\nntPeXMfHX/4kvnLt0zlreStvu+wMTlvSPOE5m3o3sahhEYsanM4oSZpbnNYoSWmbP5Wzzm3ULV9C\nPY/wUMPjyWWnzqVPP30x3/vzZ0362KaeTaxvd0ujJGnusXImSWmbP5WzbZ3k26uj8Pe2n3dc71GJ\nFR7qe8h+M0nSnJTPOkpfklI2b8JZYds28o3D7GERjYvXHtd7bB/YzlBpyEmNkqQ5yW2NkpS2ebGt\nsdzXR6Wvj3ymn1+Xz6BjUdNxvc+mnk2Aw0AkSXNTPpOnWDacSVKq5kXlrNDZCUBdbh+/rayno73x\nuN5nU281nD1u4eNmbG2SJM0Ue84kKW3zIpwVR8fo1zWX+G3lDDraj69ytrF3IyubV9JS1zKTy5Mk\naUa4rVGS0jYvwtnYGWeZ1hz3xbWPqXLmlkZJ0lxl5UyS0jYvwllxWyfZxgy7288hZvKTnnF2zPeo\nFNnct9lhIJKkOctpjZKUtnkRzgpbt5BvGuH+/Nksb2046hlnU3mk/xFKlZLhTJI0Z1k5k6S0zYtw\nVtz6MHUtRW4vH/8wkI29GwE8gFqSNGflM3kqsUK5Uj7ZS5EkHYeaD2exWKS4Zx/55jK/GDzt+IeB\n9GwkG7KctvC0GV6hJEkzI5/JA1g9k6RE1Xw4K+7cCZVIfvkSHtyfP/5hID2bWNO6hvps/QyvUJKk\nmZHLVI8vNZxJUppqPpwVHqlOaiyfeiYx8tgmNdpvJkmaw6ycSVLaaj6cFe+/A4DuNU8BOK5tjUOl\nIbbt38b6NvvNJElzVz5bDWdObJSkNNV8OCvcfwchE9m05ALg+CpnD/c9TCR6xpkkaU6zciZJaav5\ncFbc8hD5BZEN5RVkM4EVCxv4h7v+gc/e/dlpv8emnk0AbmuUJM1p4+GsbDiTpBTlTvYCZlth1z7y\nSxfS2TvC8tYGyhT5wr1foFQpcdUZV7Gkcckx32NT7ybqMnWsXrD6BKxYkqTjY+VMktJW05WzeGAf\nxb4SdatX09kzSEd7I7fuvJWh0hDFSpGvPfC1ab3Pxt6NnN52+vgULEmS5iKnNUpS2mo6nJU33EKl\nmKFu/RPo7Bmio72JX2z7BU25Jp6x4hl89YGvMlIeOeb7bOpxUqMkae6zciZJaavpcFa8+xYAwtkX\nsrt/mFVtDdyy7RaeueqZ/PG5f0z3cDc/fPiHR32P/kI/uwd3G84kSXOe0xolKW01Hc4KD9wFQN+S\n1VQiZBu3s2doD5esvoSnLX8a69vXc8OGG4gxTvkeD/U+BMD6dsfoS5LmNitnkpS22g1n5SLFR7YC\nsKNxEQC7ineQCRkuWnURIQRec/Zr2Nizkd/s+s2Ub7OxZyOAZ5xJkuY8pzVKUtpqN5zt+k8KfRWy\nbS10DlUrY/f1/QfnLT2P9oZ2AK44/QoWNSziS/d9acq32dS7ieZ8M8ubl5+QZUuSdLysnElS2mo3\nnG37DcUDOerWrKWzZ5BcXR8P9z/IJasvGX9KfbaeV5z5Cm7pvIWt/VsnfZuNPRtZ17aOEMIJWrgk\nScfHaY2SlLYaDme3UhisJ3/q6XT2DNG+pLo98dmrnz3haX945h+Sy+T4lw3/csRbxBjZ1OukRklS\nGqycSVLaajacVbb8mtIBqFu9hs6eIbItG1jbupbTWk+b8LwljUt4wWkv4Nubvk1/oX/CY/uG99E7\n0uswEElSEpzWKElpq81w1tdJceduiJBf3cG23m4Gsw9wScclk25PfM05r2GoNMQ3H/zmhOtjw0Cs\nnEmSUmDlTJLSVpvhbNutFA9U992HlavYW/lPIqUjtjSOOWvRWTx1+VP58v1fnvBt46beTYDhTJKU\nBqc1SlLaajSc/YbCUCMAPQuXkW3eQEO2hfOXnT/lS1599qvZeWAnP33kp+PXNvVuYlHDIhY3Lp71\nJUuS9FhZOZOktNVmOHvk1xTjCkJ9PZ2hnmzL/Txp0TPGp1hN5tkdz6ajpYMb7rth/NqmHoeBSJLS\nMdZzZjiTpDTVXjgrHKiecVZYQH51B7/eeReZ3CDPWXPJUV+WzWR59Tmv5u6uu/ld1++oxIqTGiVJ\nSckFR+lLUspqL5xtvwNimWJvmbrVa/ht178TY5YXPG7yfrNDvWzdy2jJt/ClDV9i54GdDJYGndQo\nSUpGNpMlEzL2nElSomovnG37NTFCYU8v+dUdbB68jVxhHYsaFx7zpc35Zq5cfyU3b7mZX23/FeAw\nEElSWvKZPKXoKH1JSlHthbOdd1NuPJ04NMTAkmYOxB0syUw9CORw15x9DRUq/I87/wdgOJMkpSWf\nyVs5k6RE1V44695CIawE4J6GvQCsb7lw2i9f1bKKS9dcSt9IHyuaV9BS1zIry5QkaTbkM3l7ziQp\nUbUVzmKEns0UC9UtjL+sbKQ8vJz1i9c+qrd59dmvBqyaSZLSk8/kJ5zZKUlKx9Sz5VM0uA8KAxRG\n6gC4pbyB0sCz6WhvfFRvc/6y87lq/VVcuHz6FTdJkuaCXCZn5UySElVb4ax7MwDFvgqlxQsZyR2g\ntP+cRx3OQgh88Pc+OAsLlCRpduWz9pxJUqpqa1tjTzWcFfYeYG97lpZcO5XhVaxubzrJC5Mk6cRw\nWqMkpavGwtkWAAq7utjUvJ+V+SeTCRmWL2w4ueuSJOkEcVqjJKWrtsJZ92YqjSso7+lie2uZptIT\nWbGwkXy2tj6mJElTcVqjJKWrtlJLz2aKmVUAdC/KM9R/OqseZb+ZJEkpcyCIJKWrxsLZFgqlxQAs\nW3cuO3rKj3oYiCRJKbNyJknpqp1wVhyC/TvZPlD941nnXsqu/mE6HAYiSZpHctmcPWeSlKjaCWej\nw0A69/YxnId1Hc+hErFyJkmaV5zWKEnpmlY4CyG8NYRwTwjh3hDC20avnRdC+HUI4a4Qwu0hhJN7\nYvPoGWflvfvpXpRncLgZMJxJkuYXpzVKUrqOGc5CCE8A3gBcCDwJeFEIYR3wceC/xRjPA94/+ueT\nZ7Ry1tJdoHdxPZ09QwCecSZJmlfsOZOkdE2ncnY2cGuMcTDGWAJuAa4EItA6+pyFwI7ZWeI09Wwm\n5hewYN/QaDgbJBPwjDNJ0rxiOJOkdE0nnN0DXBRCWBxCaAKuAFYDbwP+NoSwDfgE8JeTvTiEcO3o\ntsfbu7q6ZmrdR+reTLlhDflChf7FjXT2DHnGmSTpuIUQLg8hPBBC2BRCePckj78jhHBfCOF3IYSf\nhhDWHvLYa0MIG0d/vfZErttR+pKUrmMmlxjjBuBjwE3AjcBdQBn4f4C3xxhXA28Hrp/i9Z+LMV4Q\nY7xg6dKlM7bwI/RsoRBPAWD/kiY6e4Y840ySdFxCCFngOuAFwDnAq0II5xz2tDuBC2KMTwT+jdHt\n/SGERcAHgKdRbQn4QAih/USt3cqZJKVrWmWlGOP1McanxBgvBnqAB4HXAt8cfcrXqd6ATo5KGXq3\nUixUd1kOLG2ms2fQYSCSpON1IbApxvhwjLEAfAV46aFPiDH+PMY4OPrHXwMdo7//feDmGGN3jLEH\nuBm4/AStm3w2T6nitEZJStF0pzUuG/3vGqr9Zl+m2mP27NGnPBfYOBsLnJb+HVAuUBysA2BgcZNn\nnEmSHotVwLZD/tw5em0qfwL86NG8dra2/TutUZLSlZvm874RQlgMFIE3xRh7QwhvAP6/EEIOGAau\nna1FHtPopMZCX5n+1hyFXJ1nnEmSTogQwquBCzj4heW0xBg/B3wO4IILLogztZ6xbY0xRkIIM/W2\nkqQTYFrhLMZ40STX/h14yoyv6Hj0VM84K+47QE97nmKpejMynEmSjtN2qsOvxnSMXpsghHAZ8F7g\n2THGkUNee8lhr/3FrKxyEvlMnkikHMvkwnS/g5UkzQW1McqwezNkchR2drG3PcvIaDjzjDNJ0nG6\nDVgfQjgthFAHvBL47qFPCCGcD3wWeEmMcc8hD/0YeH4IoX10EMjzR6+dELlMNZA5FESS0lMb4axn\nC7Glg9Lu3extzzJcCJ5xJkk6bqPner6ZaqjaAHwtxnhvCOFDIYSXjD7tb4EW4OshhLtCCN8dfW03\n8GGqAe824EOj106IfCYPGM4kKUW1sd+hZzPFzCqobGZPW2C4gGecSZIekxjjD4EfHnbt/Yf8/rKj\nvPbzwOdnb3VTy2er4cyJjZKUntpIL92bKZQXA7B7YWRwBM84kyTNS+OVMyc2SlJy0q+cDfXAcC/F\ncrW/bOfCyIHhSMdSw5kkaf5xW6MkpSv9ytnoGP3iQIaQz7O3uczASPSMM0nSvGQ4k6R0pR/Ouqtj\n9Avdw+RXrWKEEjFmHaMvSZqXnNYoSelKP5yNnXHW1UuuYxWVWAbDmSRpnrJyJknpqoFwtgWal1LY\nvpPcqpXVazHnGWeSpHnJaY2SlK70w1n3ZsqNa6j09RFWrqhei1nPOJMkzUtOa5SkdKUfznq2UIyn\nABBWLQdgYUODZ5xJkuYltzVKUrrSTjClAvR1Uii0Vv+8chkAyxa4pVGSND8ZziQpXWmHs95HgEhx\nsA6AkWXVg6hXLlxwEhclSdLJ47RGSUpX2uFsdFJjoa9MZuFCNo+UAehobzmZq5Ik6aSxciZJ6Uo7\nnI2ecVbcO0BdRwcP7ukFYE27lTNJ0vzktEZJSlfa4axnC+QaKe7qIt/RwUNd/QB0tFk5kyTNT05r\nlKR0JR7ONhPb1lLcvp261R1s6qpWzupzdSd5YZIknRxua5SkdKUdzro3U8p3EItF8h0dbO3eDxy8\nMUmSNN8YziQpXemGsxirZ5yVqhMah5acQu/QMHBwUpUkSfONPWeSlK50w9nAbigNURhqBGBzvg1C\ndVqjlTNJ0nzlKH1JSle64WxsUuNABkJgQ7kJQvVbwrFvDSVJmm9yYTScORBEkpKTbjjr2QJAoWeY\n3Irl3Nc1RFvODNbrAAAgAElEQVRT9eNYOZMkzVfZTJZsyFo5k6QEJRzONgOB4p5e6jpWs2HXfla1\nV6c02nMmSZrP8pm8PWeSlKB0w1n3ZljYQbFzO9mVq9i0Zz8r2qrhzMqZJGk+y2fyVs4kKUHphrOe\nzVRa1lDq6mL/omUUy5FlrVnAcCZJmt/yWcOZJKUo4XC2hSLLAdjR2A7A0tbqdkbDmSRpPsuFnOFM\nkhKUZjgb2Q8HuigUFgCwMbuQulyGhY3Vj2PPmSRpPstn805rlKQEpRnORic1Fg9Ue8zuKjVxxikt\nVPCcM0mSHAgiSWlKO5z1lwmNjdzeFzh7eev4Fg7POZMkzWe5jNsaJSlFaYaz0QOoC3sHyKxYyd4D\nBc5acTCcjR3AKUnSfOS0RklKU5rhrGczNLRR3LmHwSWnAHD2igUUy0XymTwhhJO8QEmSTh6nNUpS\nmhINZ1uI7adS3LaNvS2LATh7eSulSslhIJKkec9pjZKUpjTDWfdmyvUdVAYH2VrXzvLWBtqb6yhW\nig4DkSTNe05rlKQ0pRfOyiXo20axVK2Y3UcLZ62ojtQ3nEmS5LRGSUpVeuGsbxtUShSGm4DqGP2z\nV7QCo+HMSY2SpHnOgSCSlKb0wtnYGP391aEfnQ3t4+GsVCk5qVGSNO8ZziQpTQmGs+oY/WLPCKXW\nNkZy9Zy9/JBtjVbOJEnznNMaJSlN6YWz7s2QraOwu5v+9mXU5TKctqQZYHyUviRJ85nTGiUpTemF\ns54t0LaW4vbt7GhaxBmntJDLVj+GA0EkSXJaoySlKsFwtpnYupbizp08lG3l7OWt4w95zpkkSaPT\nGqPTGiUpNWmFsxihewvFzClQLvNwvm18GAhYOZMkCUYHglg5k6TkpBXOBruhsJ9iYSEAu5oWjZ9x\nBoYzSZLAaY2SlKq0wtnopMbCgWoA29W8aMK2Rqc1SpJ0cFpjjPFkL0WS9CikFc66R8fo95WpZLJk\nly2nvblu/OFipeg5Z5KkeW/sXmjfmSSlJa1wNnYA9b4B9rUs4qxVCyc8XKqUrJxJkua9sXuhfWeS\nlJa0wtna34Pn/hUjnTvobGjnrEOGgYDnnEmSBIzfC62cSVJa0gpnpz4TLn4nw9s62dm0aMKkRnAg\niCRJcDCcWTmTpLSkFc6A8sAAoa+XXU2LOOeQSY0w2nPmOWeSpHluPJw5sVGSkpJcOCt2dgLQ1bqE\nUxc3T3isVClZOZMkzXvjPWeGM0lKSrLhrHH1anLZict3W6MkSQenNRrOJCktyYWzwrZqOFu07rQj\nHvOcM0mSnNYoSalKLpz1PbyFgVwDjzt9xYTrMUa3NUqShNMaJSlVyYWz/s1b2d28iLNWTpzUOHYD\nciCIJGm+c1qjJKUpuXBW7uxkZ9NizpnkjDPAypkkad5zWqMkpSmpcBYrFer27magfSltTXUTHhu7\nARnOJEnzndMaJSlNSYWzUtdecqUimVUdRzxmOJMkqWq856xiz5kkpSSpcDa4dSsAraevPeKxsRuQ\nPWeSpPlu7F5oz5kkpSWpcLb9vocAWH7W4454bLxy5ih9SdI8N95zFg1nkpSSpMJZ14ObqRBY94Sj\nhDO3NUqS5jmnNUpSmpIKZ/euPZfPPPkqTlu56IjHnNYoSVKVPWeSlKakGrSu/dMr2Hn1c8llj8yU\n9pxJklTltEZJStO0KmchhLeGEO4JIdwbQnjb6LWvhhDuGv21JYRw1+wuFXLZDKsXNU36mNsaJUmq\n8pwzSUrTMctMIYQnAG8ALgQKwI0hhO/HGP/wkOd8EuibtVVOg+FMkqQqpzVKUpqmUzk7G7g1xjgY\nYywBtwBXjj0YQgjAK4B/nZ0lTo/TGiVJqhrvOYv2nElSSqYTzu4BLgohLA4hNAFXAKsPefwiYHeM\nceNkLw4hXBtCuD2EcHtXV9djX/EUxnvOgj1nkqT5zcqZJKXpmOEsxrgB+BhwE3AjcBdQPuQpr+Io\nVbMY4+dijBfEGC9YunTpY1zu1KycSZJUlQkZciFnz5kkJWZaA0FijNfHGJ8SY7wY6AEeBAgh5Khu\ncfzq7C1xeuw5kyTpoHw2bziTpMRMaw9gCGFZjHFPCGEN1TD29NGHLgPujzF2ztYCp8tzziRJOiiX\nsXImSamZboPWN0IIi4Ei8KYYY+/o9VdykgeBjBnrOTOcSZJUvR/acyZJaZlWOIsxXjTF9dfN6Goe\ng7FvBz2EWpIkK2eSlKJp9ZylwJ4zSZIOymfy47tKJElpqJlwNr6t0WmNkiRVtzVaOZOkpNRMOLNy\nJknSQU5rlKT01Fw4s+dMkiQrZ5KUotoJZ+Ui2ZAlE2rmI0mSdNxymZzTGiUpMTWTZEqVklsaJUka\nZeVMktJTM+GsWCkaziRJGuW0RklKT02FM/vNJEmqsnImSempmXDmtkZJkg4ynElSemomnBUrRc84\nkyRplKP0JSk9tRPOyvacSZI0xmmNkpSe2gln9pxJkjTObY2SlJ6aCWf2nEmSdJDTGiUpPTUTzhyl\nL0nSQVbOJCk9NRXO3NYoSVKV4UyS0lNT4czKmSRJVU5rlKT01Ew4K1VK5LJWziRJguq0xlKlRIzx\nZC9FkjRNNRPOrJxJknTQ2D3RoSCSlI7aCWeecyZJ0rixe6JbGyUpHbUTzqycSZI0znAmSempmXBW\nqpSc1ihJ0ijDmSSlp2bCmZUzSZIOymftOZOk1BjOJEmqQeOVs7KVM0lKRW2Fs6zhTJIkYHyrv9sa\nJSkdNRPO7DmTJOkge84kKT01E87c1ihJ0kGecyZJ6amJcFaulKnEiuFMkqRRVs4kKT01Ec7GbjyG\nM0mSqsb6sA1nkpSOmgpn9pxJklTltEZJSk9NhLOx/fRWziRJqnJaoySlpybC2fi2RkfpS5JmSAjh\n8hDCAyGETSGEd0/y+MUhhDtCCKUQwssPe6wcQrhr9Nd3T9yqD3IgiCSlpyb2AdpzJkmaSSGELHAd\n8DygE7gthPDdGON9hzztEeB1wH+d5C2GYoznzfpCj8KBIJKUntoIZ2V7ziRJM+pCYFOM8WGAEMJX\ngJcC4+Esxrhl9LHKyVjgsRjOJCk9NbGt0Z4zSdIMWwVsO+TPnaPXpqshhHB7COHXIYSXTfaEEMK1\no8+5vaur67GsdVJOa5Sk9NREOHNboyRpjlkbY7wAuAb4dAjhcYc/Icb4uRjjBTHGC5YuXTrjCxgf\nCOK0RklKhuFMkqQjbQdWH/LnjtFr0xJj3D7634eBXwDnz+TipsNtjZKUnpoKZ/acSZJmyG3A+hDC\naSGEOuCVwLSmLoYQ2kMI9aO/XwI8k0N61U4UpzVKUnpqIpzZcyZJmkkxxhLwZuDHwAbgazHGe0MI\nHwohvAQghPDUEEIncDXw2RDCvaMvPxu4PYRwN/Bz4G8Om/J4Qlg5k6T01ESpyXPOJEkzLcb4Q+CH\nh117/yG/v43qdsfDX/d/gHNnfYHH4CHUkpSemqicjTU7WzmTJKkqhEAukzOcSVJCaiOcORBEkqQj\n5DN5pzVKUkJqIpyN9Zw5EESSpIOsnElSWmoinFk5kyTpSPlM3nAmSQkxnEmSVKPymbyj9CUpIbUV\nzpzWKEnSOCtnkpSW2ghnZQ+hliTpcPms4UySUlIT4awUPYRakqTDOa1RktJSE+HMc84kSTqS0xol\nKS21Ec4qRQKBbMie7KVIkjRn2HMmSWmpmXCWy+QIIZzspUiSNGc4rVGS0lIT4axUKbmlUZKkw1g5\nk6S01EQ4K1aKjtGXJOkwTmuUpLTUTjizciZJ0gRWziQpLbURzspFzziTJOkwuUzOUfqSlJCaCGel\naM+ZJEmHs3ImSWmpiXBWLLutUZKkwzmtUZLSUhvhzJ4zSZKOYOVMktJiOJMkqUY5rVGS0lIT4axU\nKTkQRJKkw7itUZLSUhPhzHPOJEk6Uj6Td1qjJCVkWuEshPDWEMI9IYR7QwhvO+T6n4cQ7h+9/vHZ\nW+bRua1RkqQj5TI5SrFEjPFkL0WSNA3H3AsYQngC8AbgQqAA3BhC+D6wGngp8KQY40gIYdmsrvQo\niuUi+XrDmSRJhxr74rJUKbnDRJISMJ1GrbOBW2OMgwAhhFuAK4ELgL+JMY4AxBj3zNoqj6FY8RBq\nSZIONxbO3P4vSWmYzrbGe4CLQgiLQwhNwBVUq2ZnjF6/NYRwSwjhqZO9OIRwbQjh9hDC7V1dXTO3\n8kOUKh5CLUnS4cYCmRMbJSkNxwxnMcYNwMeAm4AbgbuAMtWq2yLg6cA7ga+FEMIkr/9cjPGCGOMF\nS5cuncm1j7PnTJKkIx1aOZMkzX3TGggSY7w+xviUGOPFQA/wINAJfDNW/QaoAEtmb6lTc7uGJElH\nGg9nTmyUpCRMq1ErhLAsxrgnhLCGar/Z06mGsecAPw8hnAHUAXtnbaVHUaqUyAV7ziRJOtRYP7aV\nM0lKw3QTzTdCCIuBIvCmGGNvCOHzwOdDCPdQneL42niSZvVaOZMk6UiHTmuUJM190wpnMcaLJrlW\nAF494ys6Dg4EkSTpSPacSVJaptVzNtcVyw4EkSTpcE5rlKS0JB/OYoyUYslzziRJOow9Z5KUluTD\n2dg+eitnkiRN5LRGSUpL8uFs7NtAw5kkSRPZcyZJaamdcOa0RkmSJnBaoySlpWbCmeecSZI0kT1n\nkpSW5MPZeM+ZlTNJkiZwWqMkpSX5cDbW5GzPmSRJE9lzJklpST+cORBEkqRJOa1RktJiOJMkqUbZ\ncyZJaUk+nI31nHkItSRJEzmtUZLSknw4s3ImSdLk7DmTpLTUTjhzWqMkSRM4rVGS0pJ+OHNaoyRJ\nkxo7A9RwJklpSD+cjR1Cbc+ZJEkThBDIZ/JOa5SkRCQfzsYPobZyJknSEXKZnJUzSUpE8uHMgSCS\nJE0tn8kbziQpEYYzSZJqWD6Td5S+JCWiZsKZPWeSJB0pn7VyJkmpSD6cjfecOUpfkqQjuK1RktKR\nfDhzW6MkSVNzWqMkpSP9cOY5Z5IkTclpjZKUjvTDmT1nkiRNyW2NkpSO5MPZWM+Z4UySpCM5rVGS\n0pF8OCtWiuRCjkxI/qNIkjTjnNYoSelIPtEUK0UnNUqSNAW3NUpSOmoinOWCWxolSZqM0xolKR3J\nh7NSpWTlTJKkKTitUZLSkXw4K1aKDgORJGkKDgSRpHSkH87KRc84kyRpCvacSVI60g9nFcOZJElT\ncVqjJKWjJsKZ2xolSZqc2xolKR3Jh7NSpWTlTJKkKTitUZLSkXw485wzSZKmZs+ZJKWjNsKZlTNJ\nkiblKH1JSkf64axsz5kkSVPJZ/KUY5lKrJzspUiSjiH5cGbPmSRJUxvb+u9QEEma+5IPZ25rlCRp\namP3SLc2StLcZziTJKkGxHKZysjIEdfHtv47sVGS5r6aCGf2nEmS5rMYIw+c/2T2/sM/HvGYlTNJ\nSkfy4cyeM0nSfBdCILOwlXL3viMeM5xJUjqSD2eecyZJEuQWLaa0r/vI66O7SxwIIklzX22EMytn\nkqR5Lrd4EeV9k1TOslbOJCkV6YczzzmTJIls+yJKPT1HXHdboySlI/lwZs+ZJEmQnapyNhbOnNYo\nSXNe0uEsxui2RkmSqPacVQ4coDI8POG6lTNJSkfS4awcy0Si4UySNO9lFy8CoNw9cSjI+DlnhjNJ\nmvOSDmdjNxqnNUqS5rvcomo4K3VP7Dsb+wLTaY2SNPfVRDjLBQeCSJLmt3JrW/W/h5115rRGSUpH\n0uFs7FtAK2eSpPmsXIm8+Ev3Ahxx1pk9Z5KUjqTD2djkKXvOJEnzWTYTqFu6BJikcua0RklKRtrh\nrGI4kyQJYMmSNorZPKVuK2eSlKqaCGceQi1Jmu9WLWqiv6GF8j6nNUpSqpIOZ+M9Z1bOJEnzXEdb\nI935Zor7Jt/W6LRGSZr7kg5nbmuUJKlqVXsjvfUtDHftnXDdaY2SlI7aCGdOa5QkzXMd7U301rVQ\nmqJyZjiTpLkv7XBWtudMkiSAVW2N9NU3Q28vMcbx605rlKR0JB3OStGeM0mSAFa0NdBb30KmWKBy\nYHD8ejZkCQQrZ5KUgKTDmeecSZJUVZ/LUlnYDkw86yyEQC6TM5xJUgLSDmcOBJEkaVz9ksUAk/ad\nGc4kae6riXBmz5kkSdB0ylIAyj09E67ns3lH6UtSAqYVzkIIbw0h3BNCuDeE8LbRax8MIWwPIdw1\n+uuK2V3qkTznTJKkgxauWAZAca+VM0lK0TFLTiGEJwBvAC4ECsCNIYTvjz78dzHGT8zi+o7KUfqS\nJB20uOMUAPp27mHRIdfzmbzTGiUpAdPZD3g2cGuMcRAghHALcOWsrmqa7DmTJOmgVae0MZirp7hz\n94TrVs4kKQ3T2dZ4D3BRCGFxCKEJuAJYPfrYm0MIvwshfD6E0D7Zi0MI14YQbg8h3N7V1TVDy67y\nnDNJkoBKBf7+KZz78PX01rcwtGfvhIed1ihJaThmOIsxbgA+BtwE3AjcBZSBfwQeB5wH7AQ+OcXr\nPxdjvCDGeMHSpUtnat2APWeSJAGQycDIAG3DnfTVtVDqPmwgiJUzSUrCtAaCxBivjzE+JcZ4MdAD\nPBhj3B1jLMcYK8A/Ue1JO6Hc1ihJmi0hhMtDCA+EEDaFEN49yeMXhxDuCCGUQggvP+yx14YQNo7+\neu0JWXDrSnIHdnGgaQH0HhnOnNYoSXPfdKc1Lhv97xqq/WZfDiGsOOQpf0B1++MJZTiTJM2GEEIW\nuA54AXAO8KoQwjmHPe0R4HXAlw977SLgA8DTqH5x+YGptv7PqNaV0L+D8sJ26vb3Tngon7VyJkkp\nmO45Z98IIdwHfA94U4yxF/h4COE/Qwi/A54DvH22FjmVYqVIJmTIZrIn+kdLkmrbhcCmGOPDMcYC\n8BXgpYc+Ica4Jcb4O6By2Gt/H7g5xtgdY+wBbgYun/UVt66E/u2EtnYaB/cTKweX5bRGSUrDtCZp\nxBgvmuTaa2Z+OY9OsVIkFxwGIkmacauAbYf8uZNqJex4X7vq8CeFEK4FrgVYs2bN8a3yUAtWwHAf\njYtbycYK5b4+cu3Vgl0+k2e4NPzYf4YkaVZNt3I2J5UqJc84kyQlacYHZrVW8197W/W+uG/7wXH6\nDgSRpDQkHc6K5aL9ZpKk2bCdg8fGAHSMXpvt1x6/1mor+OL26q19zyM7xx9ylL4kpSHtcFYxnEmS\nZsVtwPoQwmkhhDrglcB3p/naHwPPDyG0jw4Cef7otdk1Wjlb3FqdytjdObFy5rRGSZr7kg9nHkAt\nSZppMcYS8GaqoWoD8LUY470hhA+FEF4CEEJ4agihE7ga+GwI4d7R13YDH6Ya8G4DPjR6bXYtGK2c\nNRcA6N/VNf6Q0xolKQ1JJ5tSpWTlTJI0K2KMPwR+eNi19x/y+9uoblmc7LWfBz4/qws8XF0TNLTR\nlK2O0R/u2jv+kNMaJSkNyVfODGeSJI1qXUlmcDcH6psp7ds3ftmeM0lKQ/rhzGmNkiRVjZ51NtzS\nCr0945ed1ihJaUg+nHnOmSRJoxasgP6dlFvbqNvfN37ZcCZJaUg6nHnOmSRJh2hdBQO7ybS30TK8\nn/7haiDLZXJOa5SkBCQdzjznTJKkQ7SuBCKNbU0sHBlge88QUJ3WWI5lypXyyV2fJOmokg5nTmuU\nJOkQrSsBaFlYx8LCINv37gcYv1eWotUzSZrLkg5nnnMmSdIhRsNZa2sWgN3bdgEHw5nj9CVpbks+\nnFk5kyRp1OhB1M3N1QpZ9449wCHhzKEgkjSnJR3O3NYoSdIhGtsh10guewCA/buq4Wxsl4nhTJLm\ntqTDmeecSZJ0iBCgdQW50A/A8J69wCE9Z05slKQ5Le1w5rRGSZImal1FNu4DoLSvG2D8i0wrZ5I0\nt6UdzhwIIknSRAtWkC3sopLJkNvfx1Ch7EAQSUpE0uHMnjNJkg7TupIwsItKaxttIwNs7x1yIIgk\nJSLpcOa0RkmSDtO6EsoFMgsXVA+iNpxJUjKSD2dua5Qk6RCjZ53VtzXTVhigs2fQaY2SlIhkw1kl\nVijHspUzSZIOtaAazhpa66vbGnuGnNYoSYlINpyN3WAcpS9J0iFGK2e5pkBb4UB1W6PTGiUpCcmG\ns7EbjJUzSZIO0bIMQpZcXZmm4jC7u/qd1ihJiUg3nI3eYOw5kyTpEJksLFhONj8MQP+uLgeCSFIi\n0g1nVs4kSZpc60pymf0AFPftg5it/t5wJklzWrLhbLznzHAmSdJEC1aQjb0AtI4M0HOgAhjOJGmu\nSzacjd1g3NYoSdJhWleRq+wBoG1kgK791Xum0xolaW5LPpw5rVGSpMO0riA7uq2xbWSAPf1lwMqZ\nJM116YezYDiTJGmC1lVkcpGQz9NWGGBPX/We6bRGSZrbkg1nnnMmSdIUFqwgBMi2tbC8Msiuvuo9\n08qZJM1tyYYze84kSZrC2EHULQ0sLQ+xs3e0cmY4k6Q5Ld1wVnaUviRJk1qwAoBsc5b2wgG29w4T\nCIYzSZrj0g1nnnMmSdLk8g3QtJhcfYWWof3s7B0mn8k7rVGS5rhk9wQaziRJOooFK8nWFWgY6KdU\nrpDL5K2cSdIcl2zlbOzbP3vOJEmaROtKctlBMsUCDeUCGXJOa5SkOS7ZcOY5Z5IkHUXrCrKhH6ie\ndRbIWjmTpDku/XDmtkZJko7Uuopc6AOq4SxGw5kkzXXphjOnNUqSNLXWlWQbKgB0hGFixXAmSXNd\nsuHMnjNJko5iwQpy9dVwtjY7QrmScVqjJM1xyYYztzVKknQUravI1pcBWBmHKZUzVs4kaY4znEmS\nVItaV5DJQaYhz9LSIIVScFqjJM1xhjNJkmpRfSvUtZBtztNeGKBSyTJYLJzsVUmSjiLZhi17ziRJ\nOooQqn1njdAytB9ilgOFkZO9KknSUSRdOctlcoQQTvZSJEmam1pXkq0vU3+gH2KWoaLhTJLmsnTD\nWbnolkZJko6mdSW5/DDZvt5qOCu5rVGS5rJ0w9lo5UySJE2hdSXZzAEqvT3kyVIoORBEkuayZMNZ\nqVKyciZJ0tEsWEGuvgSlEosrOQqO0pekOS3ZcFasuK1RkqSjal1FdvQg6mWO0pekOc9wJklSrWpd\nQa6hehD1sgKUY+kkL0iSdDRJhzN7ziRJOorWVWQbqpWzpYVIhRJ9Q1bPJGmuSjeclYvks1bOJEma\nUtMSso1ZABaPVAihzP9l776jo6y2Po5/nymZ9Eo6KUASeg8gXYqKiIBY6KIiiA1R8eoVrwVfsVe6\nioqAIgIiF1RQKQoKSq9CIIQkJKT3MvW8fwwXQVoCQwnsz1pZk8w8c2ZP0JX8cs7Z50hBxWUuSggh\nxJnU2HBmU9IQRAghhDgrnQ5DUAgAgZV20OwcKZRwJoQQV6oaG87knDMhhBDi3LSASPTuOvwqbaDZ\nScsvv9wlCSGEOIOaG85kz5kQQghxbr7h6N0VXmUWNE1xOK/0clckhBDiDGp0OJOZMyGEEOIcfCPR\nu1kxFTuXM6bkF13mgoQQQpxJjQ1ncgi1EEIIUQU+4RjcrLgVOZczHs4vucwFCSGEOJMaG85k5kwI\nIYSoAt8I9O4ODMXOcHakqAS7Q13mooQQQpxOzQ5n0kpfCCGEODvfCAwmB4bSSnQOhc1hJ0M6Ngoh\nxBWp5oYzuzQEEUIIIc7JNwK9ux1NgU8FoNlIlY6NQghxRaqx4UzOORNCCCGqwDsMg8kBgG8ZoNk5\nnCfhTAghrkRVCmeapj2madouTdN2a5o27h+PPalpmtI0rdbFKfH05JwzIYQQogoMbuj9fQHwLVe4\n6RWH88ouc1FCCCFO55zhTNO0JsAooC3QHOijaVrcsceigBuB1ItZ5OlIQxAhhBCiagy1ggHwK4dQ\nP4PMnAkhxBWqKjNnDYGNSqlypZQNWAsMOPbYu8C/gEve9kkOoRZCCCGqRh8aCYBfGYT5G0mRmTMh\nhLgiVSWc7QI6a5oWpGmaJ9AbiNI0rR9wRCm1/WxP1jRttKZpmzRN25STk+OCkp3knDMhhBCiavQh\nUShN4VuuCPE1kJpfjlLSTl8IIa4055x6Ukrt1TTtdWAlUAZsA0zAsziXNJ7r+R8CHwIkJia65CeB\nUkpa6QshhBBVpPlFgEnhVw52HwPlFju5pRaCfUyXuzQhhBAnqFJDEKXULKVUa6VUF6AA2A3UAbZr\nmpYC1Aa2aJoWdtEqPYFN2QBk5kwIIYSoCt9I8HDgWw61fPQA0hRECCGuQFXt1hhy7DYa536z2Uqp\nEKVUrFIqFkgHWimljl60Sk9gtVsBZM+ZEEIIURW+4WgmB75likDv/4UzaQoihBBXmqqmm0WapgUB\nVuBhpVThRazpnGTmTAghhKgG30g0dwd+ReDmoUOn2WXmTAghrkBVCmdKqc7neDzWJdVU0f9mziSc\nCSGEEFXgE47O5MCvHMo1GxH+nhzOl5kzIYS40lRpWeOVxuqQcCaEEEJUmckbg5cBTzPYzZXEBHnK\nskYhhLgC1ehwJnvOhBBCiKox+vsAUJ5zlOhAL1nWKIQQV6AaHc5k5kwIIYSoGr/AIAA27F5BTKAH\nBeVWiiqsl7kqIYQQJ6qR4czmONYQRM45E0IIIarEEBwOQF5mMjqPNABSZWmjEEJcUWpkOJOZMyGE\nEKJ6DKG1AQiudGNH8fcAHM6XpY1CCHElqZnhTLo1CiGEENViiK4DKDqpWH4/+jOavkyaggghxBWm\nZoYzaQgihBBCVIuuVixGbzuN8wxYHBb8QrZJUxAhhLjC1MhwdnzPmcycCSGEEFXjG4HJz4pbWg6t\nQ1uj8/2dlLzSy12VEEKIE9TIcCZ7zoQQQohq8ovC5GvDnJHDoLg7sepySS7dUu1hDhcf5v82/B8W\nu+UiFCmEENe2mh3OpFujEEIIUTUe/pjCfMHuoLOKx0PnT5npFyqt9ioP4VAOJqybwFf7vmJn7s6L\nWKwQQlybanQ4M2iy50wIIYSoKrf4BADsySm0C+6N3nsff6YfqPLzv973NdtztgOwv2D/RalRCCGu\nZTUynAgVAsUAACAASURBVMk5Z0IIIUT1mZokAgrzvj30rzsA0Fi4/+sqPTerLIv3trxHu/B2+Jn8\nJJwJIcRFUCPDmbTSF0IIIapPF9Mao5cdy55ttIqsg62kIb9nf4/Zbj7nc1/74zWsDivPX/c8CQEJ\n7M+XcCaEEK5WM8OZNAQRQgghqi+sGSY/G+YDB/H3NGIs60SFo5iVKSvP+rSfU3/mp9SfGNN8DNG+\n0SQEJJBUmIRDOS5R4UIIcW2o0eFMzjkTQgghqsE3AlOQAUtmHtjtxHg1x6TCmL9v/hmfUmopZdLG\nScQHxDOi8QgA6gfUp8JWQXpJ+qWqXAghrgk1MpzJOWdCCCHEedA03GJqo+wKS1oaMUFe6Es7sCNn\nB3vy9pz2KZO3TianPIcX2794/OduQoCzsYjsOxNCCNeqkeFMWukLIYQQ58fUoDEA5n1/ERPoSd7R\nZrjr3Vmwb8Ep1+7I2cGXf33J4AaDaRbc7Pj99fzrodN07CvYd8nqFkKIa0GNDmfSSl8IIYSoHlOz\n9gBYdm4kNsgLm82drpE3sTx5OUXmouPXWR1WXvz9RUI8QxjbauxJY7gb3InxjZGmIEII4WI1M5zZ\nreg0HXqd/nKXIoQQQtQourptMXraMP+1i+ggTwBa+t9Cpb2SpQeXHr9u9u7ZJBUkMaHdBLyMXqeM\nkxCQIMsahRDCxWpkOLM5bLLfTAghhDgfgfVwC1CYU9KIDXKGLoc5gubBzflq31c4lIPU4lRmbJ/B\nDTE30C2622mHSQhIIL00nVJL6aWsXgghrmo1MpxZHVYJZ0IIIcT50OkwhQdiySoh2NOAyaDjcG4Z\nA+sP5HDxYTZkbmDihokYdUaeafvMGYepH1AfgAOFBy5V5UIIcdWTcCaEEEJcY0xxdVE2hT09jehA\nTw7nl3Nj7I0EmAL4z7r/sDFzI+NajSPEM+SMY0jHRiGEcL0aGc5sDpuccSaEEEKcJ1OjFgCYt/9G\nTJAXqXnlmPQmBsQPILsimxbBLbiz/p1nHSPMKwwfow/78qVjoxBCuEqNDGcycyaEEEKcP7dWXQEw\n79hITJAnh/PLUEoxuMFgrgu/jpc6vIROO/uvCJqmER8QLzNnQgjhQjU3nMkZZ0IIIcR50ce2xuBp\nx5y0n9ggTyqtDrJLzIR6hfLRjR9R179ulcapH1ifpMIkHMpxkSsWQohrQ40MZ9KtUQghhLgABjdM\nwe5Y0o4SfaxjY0puWbWHSQhIoMxaxpHSI66uUAghrkk1MpxZ7bKsUQghhLgQpqgwzDmVRPuZADic\nX17tMaQpiBBCuFbNDGcOqzQEEUIIIS6AW3x9lF0jNOcv9DqN1Lzqh7M4/zg0NAlnQgjhIjUynMmy\nRiGEEOLCmJq3A8C+7Rci/T1Iyav+skZPoyfRvtHsz5dwJoQQrlAjw5l0axRCCCEujKl1DwAsu7cR\nE+RJ6nksawTn0kaZORNCCNeoseHMoJdljUIIIcT50geHY/DSMCcfIibI87wagoAznKWVpFFuPb9w\nJ4QQ4m81NpwZNZk5E0IIIS6EKcwXc0Y+MYFeFFfaKCy3VHuMhIAEFIqkwqSLUKEQQlxbamQ4szls\ncs6ZEEIIcYHc6kRhLnBQz6sSgJTzaAoiHRuFEMJ1amQ4k26NQgghLjZN03ppmrZP07QDmqY9c5rH\nTZqmfXXs8Y2apsUeuz9W07QKTdO2HfuYcalrrypTg6Yom4562VsBOHweTUEivSPxMnpJUxAhhHCB\nmhnO5JwzIYQQF5GmaXpgKnAz0AgYrGlao39cNhIoUErFAe8Cr5/w2EGlVItjH2MuSdHnwdSiEwB+\nyZsBzqudvqZp0hRECCFcpGaGM+nWKIQQ4uJqCxxQSiUrpSzAfKDfP67pB8w+9vlCoIemadolrPGC\nmZq0AsCetJdQX9N5LWsE59LGpIIklFKuLE8IIa45NTacybJGIYQQF1EkkHbC1+nH7jvtNUopG1AE\nBB17rI6maVs1TVuraVrn072ApmmjNU3bpGnappycHNdWX0V6f3/03gbMh9OJCfQiNf/8OzaWWEvI\nLMt0cYVCCHFtqZHhTA6hFkIIcQXLBKKVUi2BJ4AvNE3z/edFSqkPlVKJSqnE4ODgS17k/5gia2HO\nLicuQHdBM2cgTUGEEOJC1chwZnVYpVujEEKIi+kIEHXC17WP3XfaazRNMwB+QJ5SyqyUygNQSm0G\nDgIJF73i82SKq4elyEBLt3RySsyUW2zVHiM+IB6Affn7XF2eEEJcU2psODNosqxRCCHERfMnEK9p\nWh1N09yAQcDSf1yzFBhx7PM7gFVKKaVpWvCxhiJomlYXiAeSL1Hd1WZq3AqHTUf9wl0ApOZXf/bM\ny+hFbe/aMnMmhBAXqMaFM7vDjkM5ZOZMCCHERXNsD9kjwApgL7BAKbVb07SJmqb1PXbZLCBI07QD\nOJcv/q/dfhdgh6Zp23A2ChmjlMq/tO+g6kxN2gBQK90ZzlJyz29pY/3A+hLOhBDiAtW46Sebci63\nkD1nQgghLial1HfAd/+47/kTPq8E7jzN8xYBiy56gS7iFh8HgDH1EARxQU1BVqetpsJWgYfBw5Ul\nCiHENaPGzZxZ7VZAwpkQQgjhCoaAAPQ+JqwZedTy0C6oKYhDOThYeNDFFQohxLWj5oUzhzOcSSt9\nIYQQwjVM0eFYCnV08Ms7r4OoAeoH1AekY6MQQlyIGhvOZOZMCCGEcA1TQkPMxQbamtI4fJ7LGiN9\nIvEweEjHRiGEuAA1LpzZHLLnTAghhHAltyatcVh1NCrfz5GCCiw2R7XH0Gk64gPiZeZMCCEuQI0L\nZ8dnzqRboxBCCOESpjjnOWWhR5NwKEgvOP+ljfsL9qOUcmV5Qghxzah54UwaggghhBAuZYqr57zN\nzEDDwcjZm1i4OR2bvXozaAkBCRRbiskqz7oYZQohxFWv5oUzaQgihBBCuJQ+MBC9twfWfDtzbgvF\nw6hn/Nfb6fHOWhZsSsNaxZCWEJAASFMQIYQ4XzUunMmeMyGEEMK1NE3DVDcGc7GBTt5HWD62Ex8O\nb423ycC/Fu6g+9tr+OrP1HOGtPgA5/JICWdCCHF+alw4k26NQgghhOu5NWiKuciIytiOpmnc2DiM\nZY924uO7EwnwdOPpRTvp9tYavvwj9YwNQ3zcfIj0jmR/voQzIYQ4HxLOhBBCCIEpPgGHVYftwJbj\n92maRs9GoXz7cEc+vacNQd4m/r14Jze8u5a8UvNpx4kPiGdfgbTTF0KI81Fjw5nsORNCCCFcxxQf\nB4Bl/174R7dFTdPo1iCEJQ914KO7E0nNL+ejXw+ddpz6AfVJKU7BbD99eBNCCHFmNS+c2aWVvhBC\nCOFqpnrOjo3mrDIoOXraazRN44ZGodzaLILPf08hv8xyyjUJAQk4lIODhQcvZrlCCHFVqnHhzKak\nIYgQQgjhavpatdD5eGEuMsDq/wOH/YzXPto9jgqrnVnrkk957H8dG/fly9JGIYSorhoXzuScMyGE\nEML1NE3DFF8fM7GwdS58MwbsttNeGx/qQ++m4cz+7TCF5SfPnkX5ROFh8JCOjUIIcR5qXjiTPWdC\nCCHERWGKi8OSa0F1mwA7F8DCe8F26tJFcM6elZptfLLu5L1nep2eOP84kgqSLkXJQghxVamx4Uxm\nzoQQQgjXMsXVw15UhL3xfXDTJNi7FL4aBtbKU65tEObLzU3C+HR9CkXl1pMeSwhIYE/eHtamrT2+\n4kUIIcS51bhwJodQCyGEEBeHKcG5X+zIU09RammCuvltSFoBXw4ES9kp1z/aPZ4Ss41Pfzt59qxf\nXD90Oh2PrHqE7l935+XfX2Zz1mYc6uyHWAshxLWuxoWz4zNn0q1RCCGEcCnPdu0IfvxxzAcOkPbA\nGA4+/zX5bvdg3/crzL0DzCUnXd8owpcbG4XyybpDFFf+PUPWMqQlq+9czZTuU2gf0Z6lB5dyzw/3\n0GtRL97b/J7sRxNCiDOocRu3ju8502pc6UIIIcQVTdM0aj0wmqB776F45Y8UzJ1L1ucryXaPwq/2\nHgKzb8H02LfgEXD8OWN7xLNyTxaz16fwaI/44/cb9Ua6RnWla1RXyq3lrEpbxfLk5Xy2+zNm7ZpF\nfEA8N8TcQGJoIk1rNcXd4H453rIQQlxRqpRwNE17DBgFaMBHSqn3NE17GegHOIBs4B6lVMZFq/QY\nOedMCCGEuLg0Nzf8+tyCX59bqNi1m4K5cyla9l8KD+TgtaorAU+8gk+vWwFoEulHz4YhfLzuEPd0\njMXH/dSfz55GT/rU7UOfun3Ir8xnRcoKlicvZ/q26SgUBp2BRkGNaBXSilYhrWgZ0hJ/d/9L/baF\nEOKy05RSZ79A05oA84G2gAX4ARgDZCulio9dMxZopJQac7axEhMT1aZNmy6o4KnbpjJj+wx23L0D\nTdMuaCwhhBAXh6Zpm5VSiZe7jprCFT8fLzZbfj6F01+lYNFSbOU6/K+LJGxoV7SASA5Z/Hjkv5nc\nfn0b7ruhDeiqtmuiyFzE9pztbMnawpbsLezK3XV8hUxdv7q0Cm1F/7j+NA9ufjHfmhBCXFJn+xlZ\nlZmzhsBGpVT5scHWAgOUUm+ccI0XcPaU5yJWuxWjzijBTAghhLiEDIGB1JrwJkF39SZn4r/I23AE\nS/KnRHbMp45JsdwE/A5qowHNOwwiWsBtM8Dkc8Yx/Ux+dKndhS61uwBgtpvZnbubLdlb2JK1hR8O\n/cD3h77n6z5fE+UbdYneqRBCXD5V+dPWLqCzpmlBmqZ5Ar2BKABN017RNC0NGAo8f7ona5o2WtO0\nTZqmbcrJybnggq0Oq3RqFEIIIS4TLb4bIXP+JOL116go8Cblz9aYb5hDcvcZ/Md6D1trD4fYjrDv\ne1g4Ehz2Ko9t0ptoFdqK+5vez7Se01jcdzF6Tc9TvzwlLfmFENeEc4YzpdRe4HVgJc4ljdsA+7HH\nJiilooB5wCNneP6HSqlEpVRicHDwBRdsdVjlAGohhBDiMvPr14/oz2fjqDCT8tjLhBDJ4XpDGXXk\nFsr7TIPebzjb8K/8z3m/Rrh3OBM7TGR33m4+2PqBC6sXQogrU5UWhSulZimlWiulugAFwD974M4D\nbnd1cadjc9hk5kwIIYS4Ani2bEmdrxdgjIoibcyDPFm0ibxSM/M2pEKb+6HdGNgwFTZ9ct6v0SOm\nBwPrD+Sz3Z+x7sg6F1YvhBBXniqFM03TQo7dRgMDgC80TYs/4ZJ+wF+uL+9UVodVOjUKIYQQVwhj\nRASx8+bi06MHbjMn82ryf/l49T4qLHa4aRLE3wjLx8PBVdiLiihdt56cadNIG/MgGU8/jb2w8Ixj\nOxwKq93B+MTxxAfEM2HdBHIrci/huxNCiEurqusDF2maFgRYgYeVUoWaps3SNK0+zlb6h3F2cLzo\nZM+ZEEIIcWXReXoS+f575E6ZQotp03kyI42FrWpxR4yJCmsvKrbsp3L5g1iKj/1NWNNwq1MHa1oa\n5Zu3UHvqFNzr1z9pzKNFlQyftZFgHxPz7m/Hm13eZNCyQfz7138z84aZ6LSqdYQEKLeWU2wpxmq3\nYnX84+PYfZqm0Sa0zVXzB2ClFDnvvY9n2zZ4d+x4ucsRQlRRlcKZUqrzae67JMsY/8lqlz1nQggh\nxJVG0+kIHjsWU1wc1qeewfjU3aQce0wfFIiHfyV+DXR43Ps27okd0fv4ULFtG+ljHyNl0GAiXvk/\nfHv3BiC9oJwhH20kraCcpOxS1u7P4fr69Xi67dO89PtLfLrrU0Y2HXnOmuwOO1/89QWTt06mwlZx\nzutbhrTk3evfJcgj6AK+E1eGst9+I2/mTEpWrsRr+TK0Kh5vIIS4vGpcypE9Z0IIIcSVy7d3b4w+\nwXwz+QsOeoUy7L5buL5TE7QjW+Cz3pD8LnTuBoBHixbUWbSQ9MfGceSJJ6nYvZvy4aMZ+ukmSs02\nFjzQnnHzt/Huj/vpmhDM7fG383vG70zZOoXEsMSznn92sPAgz//2PDtydtCldhd6RvfEoDNg1Bmd\nH3rjSV8nFyXz6sZXGbx8MB90/4AGgQ0u1bfM5ZRS5Lz/AZrRiOXQIUpXr8anR4/LXZYQogpq3J9R\nZFmjEEIIcWVr2LkN9340iexWnbjvu1Rm/pKMimzlPPcsbQMsfRSU83hUQ3AwMZ99iv/gQeTP+oRN\ng0ZgKCvhy9HX0SY2kEe7x7E9vYhVf2WjaRovdHiBEM8Qnv7laYotxae8ttVhZcb2Gdz53ztJLU7l\ntc6vMaX7FG6Lv41b691Krzq96BHTgy61u9AhogNtwtrQIqQFA+IH8NnNn+FQDu7+/m5Wpqy81N82\nlyldvYbKHTsInfAsxshI8j6edblLEkJUkYQzIYQQQrhcuJ8HCx5oT++m4bz2/V88uWA7lQl9oftz\nsOMr+OXN49dqbm7kjxrHh+0GUz/7IDPXfUC9ogwAbm9dm+hAT975cT9KKXzdfHm9y+scLTvKxN8n\noo6FPIDdebsZtGwQU7dNpWd0T5b0W8ItdW9B07SzF2u3wqZPaOwexvw+80kISODJtU8yddtUHMpR\n9TedugG+GgZlp29aYnVY2Za9jZ05O6s+ZjUph4OcDz7AGB2N/+23E3jvvVRs3Ur5li0X7TWFEK5T\nI8OZ7DkTQgghrnwebnqmDG7JEzcksHjrEQZ/tIHsFo9A88Gw+hXYOg+UYltaIYM/3MDGBh3xmvEx\nBuUgZfAQiv67DKNex9ge8ezOKGblniwAWoS04JGWj7AiZQWLkxZTaavknc3vMGT5EAoqC/ig2we8\n0fWNqu8d2zgDlj0OSx+hlnsQn9z0Cf3q9WPG9hk8ueZJyq3l5x7DUgaLR8He/8KCu8FmwaEc7Mvf\nx+zds3n454fp9GUnhn8/nCHfDWHe3nkX8J09s5KVKzH/9RfBjzyMZjTiP+A29H5+5M06/+MMhBCX\njnbiX5wutsTERLVp06YLGmPod0PxMnjx4Y0fuqgqIYQQrqZp2malVOLlrqOmcMXPxyvd9zszeWLB\ndvw9jXw8tCmNfxoBqb9R4RfH+4Ud+cWzBzNH3UBUoCe23FzSx42jYtNmPFq2BIOB7elF6ICmtf3Q\nlEIBSQX7KbWUkh/pzYp6ZTTsNoAn247H18236oUVZ8KURDC4Q3ku3PEpNBmAUoo5e+bw9ua3ifOP\n44PuHxDpHXnmcVY+h+O3yaQm3s0f+xazIbw+f+qsFJqdRwXE+sbSNqwtbcPb8l3yd6xKW8X4xPGM\naDzigr6vJ1J2O8m39gVNo+7Sb9H0egByPphM7vTp1F2+DFPdui57vepwmM3Yjh7FLSbmsry+EFeS\ns/2MrHHhbOCygdTyqMXUHlNdVJUQQghXk3BWPddCOAPYdaSI0Z9vIr/cwrsDGhKX/QNlv31MCy0J\npXdHa3IbtL4XotqibDZyJk+hfPNm0CCv1MrBnFLiQn0I8nIDTcPqsLI7ZxexGTbcrApDSAi+N/fC\n9+abcW/e/NzLGQEWjnTOdj34Gyy+HwrT4JE/wTMQgPVH1vPU2qcw6Ay80fUNwjzDyCjL4GjZUTJK\nM8gsyyQzP4mM7J1kGY3YcP5eFWqz0S6oKe2aDqNtWFvCvMKOv6TVYeWZX55h5eGVPNbqMe5ver9L\nvr9F335LxtPPEPnee/j2uun4/bb8fA50645f31sJf/lll7xWddgKCkh7YAyVu3YRM28uni1bXvIa\nhLiSXFXhbMDSAUT7RPNet/dcVJUQQghXk3BWPddKOAPILqnkgTmb2ZpaiFGvUbeWN1/29SJw7zzY\nsQAsJRDSyBnSmg8Edz8A7A7FTe/9ggb8MK4Lep0zeBVbinGrdGD+dT3F339P2dpfUFYrxshIZ1Dr\n3RtTw4anD2qHfoXZfVCdnkJ1fgpdQRJ82BWa3AEDZh6/LKUohUdXPUpKccpJT9dpOoI9gokoySXM\naiGixd1EBcSTGNKS6OXPoB34CYZ/A3W7nvLSNoeNCesm8N2h73ioxUOMaTamamHyDJTVysHet6Dz\n9qbOooWntM7PfPFFihYtJm7VzxiCg6s+cPJa+PF5uOVtqF39/6WtGRmk3j8Ka3o6Oj9f9F7e1Fny\nDTp392qPJcTV4qoKZ7d+cyv1A+vzVte3XFSVEEIIV5NwVj3XUjgDqLTaeem/uzmcV86UIa0I9HJz\nPmAuhV2LYPOnkLEVDB7QYgh0eQp8w1m2I4NHvtjK+4Na0K/F6ZcY2ktKKPn5Z4q/+46y334Hmw1j\nTDSG4GBUpRlHZYXztqICVZKHwwY4AJ2OoJH3Edy8HG3dWzB0IcTfcHzcYksxy5OX4230JswrjAjv\nCEI8QzBumAErn4M7Z0Pj/ie8yWKYdQOUZsGoVRB46nJCu8PO8789z9KDSxnVdBSPtnz0vANawYIF\nHH3+BWpPn4ZPt26nPG45fJiDvW4maNQoQp54vGqD7lgASx4Ch9UZmB/4BapxSLf54EFSR96Po7SU\nqOnTUDYbqffeR+A99xD6zNNVHkeIq81VFc56LepFy5CWvNr5VRdVJYQQwtUknFXPtRbOqiRjK/w5\nC7bPB50e2o7G0WEcN3+0G6vdwcrHu2DQn72vma2ggJIff6Tk559RFZVo7iZ07h7O26KDaJl/oGva\nFy2iEZZDKRQvW4Z39+uJjPsTHRXw8AYw+Zz5BQpSYFp7qNMVBn8J/wxW+cnwUXfwDoWRP4L7qXvh\nHMrBxN8nsihpEfc2vpfHWz9e7YDmMJs5eFMvDKEhxM6ff8bnp499jLING4hbtQq9t9eZB1QK1r0L\nP78EsZ2hxVBYMgZ6vgSdxlWpport20kb/QAYjUR//BHuDZznxmW+9BKF878iZu4cPFu3rtb7FOJq\ncbafkTWu7aEcQi2EEEJcAyJaQr8p0PlJWPMa/DYZ3ebPmBx3L/03N2fp9gwGtKp91iEMAQEE3HUX\nAXfddfIDJUdhciJ0vg6GTgFNQymFR/PmZL36KikpkUQ13ozxp5fgljOs1FEKlj0Bms55zekCUWBd\n54zanNucnRwHfeEMmifQaTqeb/88Bp2BT3d/CiWlDF6rcBQXEzrhWQxB5+44Wbjga2xHjxIx6ZWz\nBrugkfdRsnIlRYsWEjjiDI1IHHb4/l/w58fQ5HboPx0MJue+vDWvQePbIODsTT1Kf11H+tixGIKD\niZ71MW5RUccfCx0/nrJffiXj2Wepu2QJOg+Pc76/01FK4SgtxV5UhL2g0Hlb5Lx1FBXhMJvB7gDl\nQDkU2O0o5QCHcr5HTUfAkMGY6tU7r9cX4mKpceFMzjkTQgghriGBdZz7vzqNg1X/R8Lu9/nNw4/P\nf7gDW+P/w2DyrP6YK/8DdjPc/PrxUKVpGoHDh+FWpw5HHn+cQ6trU7tiNp5NboeY9qeOsfNrOPgz\n3Pwm+J0lJNbt6nyd78bDqpeh54unXKLTdDzb9lmiNx0hfvyX5Fdo6A1Gyv74g4hXJ+HdufMZh3dU\nVJA7cyaebdrg2f40dZ7Ao3lzPBMTyftsNgFDhqAZ//H7lKUcFt0P+5ZDx8egx4vwv71rN78OU9s6\ng9vg+acPo0DRsuVkPPMMpvh4oj+cecr+Np2XF+GTJpE6YgTZ775L2LPPnrXmk96r2czRlyZSuno1\n9uJisNvPfLFeDzqdM6zq9cdv/3efo7ycsnXrnPvfzjMgOioqKFqyBO9u3TCGhZ37CUJUQY0MZ3LO\nmRBCCHGNCWkIg+ZB+mbsSycwNnsWZe8ux3Djc85z0/RV/N0gZT3sXODcxxZ06qyJd6eOxH41n7Qx\nY0hdZSGcMfi9uxGMJzSwKMuDH56ByERoM/Lcr9nmfsja5VwqGNIImp08k2c9epSjE1+mzao1FMXW\n4pluBdQJrMOdX6RjHzWand1i2HJ7IzC5odf0GHQG9JoeL6MXjVckEZObS8aEeyjJ202geyAB7gF4\nGE4fOALvH0n6mAcp/uEH/G699YT3lAtfDIQjm52Bs93ok5/oHwXX/xt+/A/8tRwa9jll7PzP55A1\naRKebdpQe9pU9D6nXxLq1a4tAcOGUfD5HHx69sSrbdtzfgvthYWkPfwIFZs349evL4bwcPR+/uj9\n/ND7+zlv/fzQ+/uj9/VFc3M763hlGzaQes+95HwwmdCn/3XO1z+drEmTKPx6Idqrr+E/aCC1Ro2q\nXrMVFyv+/ns0oxGfnj0vWw3iwtW4PWdt57XlroS7GN9mvIuqEkII4Wqy56x6ZM9Z9Sil+M+7UxlS\n8hmNVBKENHYuLYzpcPYn2q0ws4uz8cjDG8HtzLNu9sJC0kePoHzHfoJubEjweyd0QPzmQWfAe+AX\nVEgjLAcPUr5pE+V//Ik1IwPPtm3x7nY9Hs2aHT9rDJsF5vSH9E1w3/cQ2RrlcFAwfz45b7+DstsJ\nHjuWgOHD+HzfPH48/CNYLPRYlkH79flkhroxd2Aw6SE67A47NmXDXlLC21MrSA7TmDTo5OWSHgYP\nAt0DaRXSiv5x/UkMS0Sn6VAOB8l9+6LpDdRZ8o1zRik/GebeDsUZcPvH0PBWTstuhQ+vh4oCePgP\nMHkD4KisJHfmTPKmz8C7Zw8i334bncl00lMPFh5ke852wr3CifaNJgRfDg+4A5Si7pJv0HmdeQ+c\nJf0IaaNHY01LI+L11/Dt3fvs/85VlPniixR+tYCYL+ZVu71/8Q8rODJuHP6DB6GsVoq+WYJmNBI4\nbCiBI0diCAhwSY1VVb5lC4eHDQcgauaMs862XousmZlU7NyJqqzEUVGJqqzAUVHpbAx07HNlseB/\nx+14Jl78H11XVUOQlnNack/je3is1WMuqkoIIYSrSTirHgln1bd6Xzb3fvoHc9pn0Tn5XShKc86g\n3TARvENO/6Tfp8GKf8PAeaed+fknZbVy9P5eFG7MwLtjIpEfzEDL2IB56l2U+9xMeVEQ5Zs2Yc/P\nB8AQEoIxIoKKnTvBbkcfGIh31654d7serw4d0WsV8FE3KM3G7N6czFWVVCTn4HVdO8JefvmkvVkn\nKhDYewAAIABJREFUKv3lFzKenYCjuJiQp54iYNhQNE0jZ+o0cidPxuOzyRTVC6agsoCCygLyKvMo\nqCwguzyb9UfWU2ItIdI7kr71+tK3Xl+8V/5B5oQJRH38Md6x7vDFXaAcMOQriDrzLJayWLBsXIb5\n0wep9G6P2VEbc1IS1tQ0UAr/O+8g7IUX0AzOWUybw8ba9LV8ufdLNh7deNJYBp2BTjlBPPjREQ71\nqE/hw3cS7RNNw6CG1PKodfy6it27SRszBmW2EDV1Cp5t2pzz362q7KVlJPe9FZ3JnTrfLK5ye39r\nRgbJ/W/DLTaW2Hlz0YxGLCkp5EydRvGyZeg8PQkcMYLAe0ag963GgejnyV5SwqF+/UGnQ+fjgzU1\nlZgvv8A9IeGiv3ZNYM3K4lDfftiLik59UKdD5+GB5umBMltQVivRn8y66GfxXTXhTClFs8+b8WDz\nB3moxUMurEwIIYQrSTirHgln1aeUYsD038gqqmT1Y20w/f4erP8AjJ7Q/TnncsMTm2+UZMGURGf4\nGLrwjHumTnmdsjwKHm5P1kY9hrAwHPlHcZidjxkjIpx7vdq2wbNNG4xRUWiahr2oiNJf11G6ejWl\nv/6Ko7gYzWh0zqi1a4p91ypyf9qP3uAgpGURfnUsaOFNnTN/0ddBdHtnwLSZnbNUFYXYMlPJfHMm\npZv24NUsltABLUh5cwWe13UgauqUM9ZfaatkVeoqlhxYwobMDSgU19VqzdhX9uId5kedVjucrzVs\nMdSKO+m5lsoycn5eQdnKn9AdTMWachhsNueDmsItqjamhk0wxcfj3qQx3l27omkaBZUFLE5azFf7\nviKzLJMwrzAG1h9Ij+ge5FbkklaSRmpxKqklqTSe9wcdfs3jpSE6dsfoMOqMDGkwhFHNRqH/Ywfp\nj41D7+9H9IcfYoqLO807vDCl69eTNvJ+gu4fScj4c6/KUnY7h0eMwLz3L2IWL+SoP9T2qX18y405\nKYmcKVMpWbECna8vQffdR+DwYWedGbwQSikyxj9F8Q8/EDtvLoawMFLuvAvNaCT26wVVaihzyph2\n+9/79Wo45XCQdv8oyrduJWr6NIxhYWgenug83J1h3Gg8/j5tubmkDB2KvbCImDmfX9Rwe9WEM6vd\nSqu5rRjbciyjmo1yYWVCCCFcScJZ9Ug4Oz+/JuUwfNYf9GsRQe+m4bT1ySNgzbOQvAbCmsEt70DU\nsZmWxQ/A7sXw0IbT7jWz2By4Gc7Qmn/Pt5S+P4rcpGDcTCV4DngEr95DMUae/qy1EymrlfItW51B\nbfVqLIcPA+B7662EPv4whvIDkPo7pG6A9D/BVul8osH978//N5aCggOeZG/zQzkApVHnoSa43zf1\nzLOFJzhadpSlB5fybdJiWvyUxrDVDr671wdbp5spdFgoNBdSWFGA78Fsmm3Ko80uCz6VUOgJByI1\niiP9UXVq41WvHmGpi6jnG06dESsxGp1LGPfk7eHLv77ku+TvsDgstA1ry5AGQ+ga1fWM/QIcFRUk\n978Nu9VC2ayX+SbjB7498C0373ZjxLJyTAn1iZ45E2Poud+fQznYkLmBJUlLyCrPQtM0dJoODc35\nOTp0mg400Gt6Woa0pH9cf6yTPqBw0SJi53+JR7NmZ32NnKlTyZ08hYwn7mRyyA4OFh3Ez+RH19pd\n6RHdgw4RHXA3uFO5Zw85H0ymdM0a9EFBRL7zDl7tzr23rrqKvv2WjKefIfixsdR68EEAKnbu4vDw\n4bg3aED07M9OWWJ61vGWLefoCy+g8/XF+/qu+HTrhme7dtUa40qSP2cuWa+8QtiLLxAwaNA5r7ek\nH+HwkCGgFDFfzDvjbPaFumrCWbm1nHZftOOJ1k9wb5N7XViZEEIIV5JwVj0Szs6PUopnv9nJoi1H\nsNgcANSr5cl9gTu4LXsqnpVZqJbD0RJugq+GQefxFHd8hqSsUpKySkjKLmV/VgkHskvJLKokNsiT\n6+oGHf8I8zthmdtXw5zt5FsOd7b4P0/m5EOoygrcGzU69UGbBTK3Q+pvUJYD7v7g4X/sNuD45+aM\nAjJefgP3ACvhtdc5Zwt7vQbNB517RvDAT6glD7GlshTj1wFsjtMz83ZPYiu86bTLTsvNRQRmV2A3\n6sltW4+yHm2wtW5EekUmBwoOcKDwAGkladiVs1OiHo1ov1jc9e7szd+Lh8GDW+veyuAGg4kLqNpM\nV/mWLRweOgz/gXcR9sIL/PXWRJg1n211NBaOiOWhDk/SPar7GWdycityWXJgCQv3L+RI6RH8Tf4k\nBCSgUDiUA6XUSZ87lINKeyUHCg9g0AzcGNyJuydtxt03kDqLF50xiORuXEf2vaP5s4mJt26xkRCQ\nQP+4/uzJ28Pa9LWUWErwMHjQMaIj3aO706V2F9z+SiHj389iSU0lbMKzBAwejEM5yCnPIb00nfSS\ndNJL01FK0aduH2L9Yqv0PQOwpKZyqP9tmBo1JGb27L/3NwLFK1dyZOxj+N5yCxFvvXnOWTBltZL1\n5psUfD6HzDq++IZG4b09GVVRgebhgVeHDvh0ux7vrl3P3fTE4XD+oSFrJ9S/BXzDT34tpdictZnZ\ne2aTVJDElO5TqvzfSnWYDxzg0O134HXdddSeMb3KM4HmpCQODxuOzs/PORt5EZq8XDXhrMhcRKf5\nnXi6zdMMazTMhZUJIYRwJQln1SPh7MKYbXZ2phfxZ0oBm1Ly+TMlH3tlCWMNixlp+AEDdnL1Idyu\ne5/DJX//3uNu1BEX4k18iA9RAR7sPVrCxuQ8iiudS/dODGsdwhyE7P0c2j8MHv7Y7A5KzTZKKm0U\nV1oprXR+rtdrdIqrhfEcB2RfiMJyC88s2omfh5GJHQ2Ylj8G6X9AXE/o856zs+I/WSudh0pvmAbB\nDeH2j0mdtYzSuXNwNG2OfsdWADwTE/Hr3w+fm246Y7dFi93CoaJDHFw6hgOl6RxI6E6+rYybYm+i\nX1w/fN2qv88q6/U3yP/0U7w6daJs3Tr8buvPgQdu5O1t75FclEzr0NY8lfgUjWs1BpyzZL9n/M7C\n/QtZk7YGm7LRJqwNd8TfQY+YHpj0557pSS5KZuH+hSw9uJTYPQVMWOAg/bZ2tHr+bYI8/l4OeLTs\nKF9t+oRW/5qLTVMs/Pd1DE0cRfuI9sd/4bc6rPx59E9Wpa5iVeoqcipyMGgG2oS1oa1PE+q9t5Sw\n7UfY0M6X6d2sVGjW4+P/b3bPruy0C2/HXQl30S2621mPjlJWKynDhmE5lELdJd9gjIg45ZrcDz8i\n5513qPXIIwQ/8rCzocuKCc7Op4l/T3JYs7M58vgTVGzezKbOobzdPheHXser7V6ia3YQJatXU7pm\nLbbMTADcmzXDp3s3AgYPRu/nd2yQCkheC38tg/0/OP+4AKAzQvOB0GEstqB6/Hj4R2bvns3uvN34\nm/zRac7ZzNm9ZhPtG33Of7OqUhYLhwYNwpZ5lLpLv8Ue6Hu80+lpOeywZTbEdILgBCq2b+fwvffh\nFhVFzJzPXb538KoJZ7kVuXRb0I3n2j3HwAYDXViZEEIIV5JwVj0SzlzL4VAkZZfyZ0o+afs20zb1\nE37yuhlzZEfiQ32ID/EmIdSHyAAP9LqT/5pudyj2ZhazITmPDcn5bDyUR8mxsBbu547doSiptFFh\nPfMZWyE+Joa0i2ZIu2hCfKrWZKKq9mYWM3rOJo4WVWK1K5rX9uPDYS0J3TcXfnrJOXPW80VIHPn3\nGWVZe5znl2XvhrYPwA0v8VeelX9N/4kXFk2kyOSN1619aXn/ENxqn/1g75PkJsH0Ds6DqQd8WP03\nYy6F0iwozcaRl86hJ9/FkllArTu7U2v0vWj+Udg8Alh8cAlTt00lvzLfObvkG8vipMVklGUQYAqg\nf1x/BsQPqNas00ll2M38ePhHyl58g8Z/5vD8PW7Uve4Gboy5kbXpa/nu4HIeWWLlun0K3YxXadil\n31nHcygHO3N3Hg9qKcUp+Oi9uGe9G51X55BfP4yjzw4nvHYDahu8CC/JpTBnD9/kbGJh8V4y7RXU\nwsBtypM7zIqI8mKoKITQxjD4S/AMJPu998ibMZPId9/B9+abT1uHUorMZydQ9M03RLz1Jn7272Hr\nXOeD1z0MN/4f5Vu3kj5uHI7SMn4Z2pjJwduY2GEiy5KXsSlrE290eYObYm9CKYV53z5KV6+mZM0a\nKnfsxFAriPCRN+Dtvg8OrgJrOZh8nX8kaHALBDeAzZ9Rum0eizz0zAsKIRMrMT4xDG80nL5xfcko\nzeCeH+7B0+DJ7JtnE+YVdsp7wGY79Uy+c8h+513yPvyQkA/e4duITGbtnEW4Vzjvd3+fSO9/LEcu\nz4eF90HyaghtCg+sBZ3euR9xzIN4NG1K9KyPz/s8vNO5asLZ0bKj3LDwBl7q8BID4ge4sDIhhBCu\nJOGseiScXblODGu7jhThbtTjbTLg427Ex91wwofz65wSM3M2HGbNvhyMeo3eTcMZ0SGWllH+F9xg\nYdmODJ76ege+HgZmDGtNdomZx7/aho+7gY/uTqSZVxH89zHnL5nR7eHWD5yfr/wPuPtCv2mQcCPf\n7cxk/Nfb8TYZeO2WeN77NZXdmSW8OqApdyVWc4/Nqlfglzfg7qXOA7fBuTmuosDZQbMw7dhtKhSl\nQ2n28UCGteykoSyleqylerzCLH/fqXcD30hK/SKYZVJ8bsnAgoN2PnW5o/b1dK99PW7eYeAZCIZ/\nzJY57M7jAQpSoODQsdsUyD/kvL/VcOg24fhSUHtxMftv6U2xyc7T9+jIsxfjYfBgXGZTWn78G8Hj\nxlFrzAPV+vYopaiwVeChGdDyDlC06Esyp3+D3kNHVE8L7m6ZJ11v17ux3i+IBV4mftE7QIPO+gAG\nesbQcfcP6EMbU9bweVJHP4JP/36E/t9EHPy9XNPD4HHSf2fKYiH1vpFUbNtC9PVZeN72GFjKUBum\nU1DcjqwfMzFGRrDh0a68nvclD7V4iAebP0i5tZwHf3qQHTk7eOv6t+gR3ePvIo9soWLO02QsPoSl\n2Ih/AwgZfiP65n0htjMYnGfMZZZmMm/vPBbtX0iprYzWFjsjCvLpGtAIXcdxzgCn07Mnbw8jV4yk\nlkctPu316fFundasLDL+9TTm/fsJf+UVfLp3q9L3vHzzZg4Pv5uCHi35T5dMssuzuS78Onbn7kav\n0/PO9e/QJuzYXtTM7TB/GJQehaZ3wrZ50HcytLobgOIffuDI40/g1aUzUVOmVDsknslVE87SitPo\n/U1vXun0Cn3r9XVhZUIIIVxJwln1SDi7+hzKLePz31NYuCmdErONZrX9uLt9LH2aheNu1J/z+Sey\nOxRvrdzH9DUHaR0TwPShrQjxdc7I7c0s5v7Zm8gtNfPWnc25tVk4bPvCeWRAZTGgIP5G6DcNu2ct\n3vlxH1NXH6RVtD8zhrUmxNedUrONMXM2s+5ALk/3asCYrnWrHiStFTCtvXPJXGjjvwOZpeTk64ye\n4BsJPmHgHXrsI+Tv2//dr9ND0RFnkCtKO3b790du2VEsmiLCdpqZSzcf8AwAj0CwlDoDof2EoKcz\ngF8UBMQ6v05eDYn3Qe+3j88ylqxZQ/qYB/EfM5pDd7UjocSb3MH34tGkCdGffnLSvq5zMpc6l8pt\nnw85fx2vpaLAg/T1QdjNEHF/T3z79IOgePAMAqPH8bCYUZrBwv0LWZy0mLzKPAC8KhRvzrJjMcDT\n9+kxu53879QoqBFvdHmDGN+Y4/fZ1swgZfzbOJQHsd9+hyEwkMyHBlO8YT/e9dzZ89LjjN/9Jn3q\n9mFSp0nH/+3LrGWM/nE0e/L28H639+kSkghrJsHvU8ErBEfTIeSsLyH/6+8wRkQQ/uokvNq2pdhS\nzPRt0/nyry8BuDHmRkY0HkFj3zrO8PP7FGdIDqwLHcdBy+Fszd3OAz8+QJRPFJ/c9Am69VvIfPZZ\nHBYLxohwLAcOEjB8OCHjnzxrcxJbSQl7+/SiyFrM4/coEmo3Z1yrcbQJa8Ph4sOMXTWWw8WH+Veb\nfzHYrKEtG+f8vt81ByJbwSe9nOf+PbrZ+QcNoGDBAo4+/wK+ffoQ8cbrf593eAGumnCWXJhMv2/7\n8UaXN7i5zumncIUQQlx+Es6qR8LZ1avMbGPx1iPM/i2FA9mlBHq5cWdibXo3CadZbb9zhqCicitj\n529l7f4chrSL5sVbG5/SVTK31MyDczfzZ0oBY7vHMa5nArqybFj9CoQ3g8SRFFXaeGz+Vtbsy2Fw\n2yhe7NsYk+HvoGGxOXjy6+38d3sGIzvVYULvhuh0VQxoyWvhmwfAs5Zzv5t/tDME+Ucdu41xzmy5\nojW73QbleSd/VOQf+zz/2EceuHk5Q1hALATWcd761gb9sT1HSsFPL8L696DpXdB/GuidsyIZTz9D\n0bJlxH4xj6MTX8aank6db5dgDAs7Q1H/UJ4PG2fCHzOdM4i12zqPSAhr6gywQfHYCopIf3QsFdu2\nUeuhB6n1yCNn/KXf6rCyOnU1+/L/otkbi6i1I4utw/0p6zUMnd6EpmloaFgdVubunYvNYePF9i/S\nq04v2L8CvhyM2b8DKfOyMYSEoGk6zAcOEDz4RjJMX3NfaCCNAhvy8S1zcdO7nfTaxZZiRq8czf78\nfUwucdAxJwVajXCeJ+jh73y7W7aQ8cy/saalkd+3Ay803U+2vZA7Eu5gVNNRhHuf3BAEhx32LnUe\nfZGxBRJ6Qf/p/F64j8dWPMRDv/nQ7tccTI0aEvn22xgjI8l+6y0KPp+DqaHzPlPdOqd8nzZmbiT5\nqSdotjmfmWOi6X/b03SL6nbS/2OlllL+/cvTrDnyCwNKSpng3Qi3Oz4D72NNP45sho+6Q6fHncuD\nj/nf/r2AIUMI/c9zFzwLftWEs335+7jjv3fw7vXv0jOmpwsrE0II4UoSzqpHwtnVTynFbwfz+Oy3\nFFb9lY3doYjwc+fGxmHc1DiMNrEBGP7RRGR/VgmjPt9ERmEFL/ZtzNB2MWcY3dkU5blvdvH15nR6\nNQ7jnYHN8XRzBpGkrBJGz9lMekH5WcdxOBQTl+3hs99S6NcigjfvaH7m4wWuFr++DT9PdHYVvOMT\nMLpjLyoiuc+t2IuLUWYztadMxqdnFX7vLDrinBXa/Jlz/1X9W5y/5Eed/uBsh8XC0ZdeomjRYud5\nede1w1SvHqZ69XCLiUFzOzkoFS5aROaE5wge0pNajjnOvV2D5p20nPNo2VHGrx3P9pztDKzdnac2\nLMBUKx7u+Y6yrbtIvX8Uei8vIt5+m+IWdRi89E48KwqZl1dO4KD5EN3u5CIrCila8Qz3Z6/mkJsb\nU5uNpV2rU4+z2pn6J1tfeoI263PJC3En6JWXaNj5HKvclII/PoIVz4JPOOb2k9j38gcYD6azqWsY\nd7z7LR6efzfiKFm9msx/P4vDbCbsuefwG3AbdmVnc9ZmZu2chX3NesYvdpA3sBvtX5iMXneaWc6S\nLBxfj2Ba8R5mBvjRvFYz3u32HsGeJ3RkXPwA7P4GHvnj+CyrUorsN98i/5NPCH32WQLvHn7293YO\nV0042527m0HLBzGl+xS6RnV1YWVCCCFcScJZ9Ug4u7YUllv4aW82K3Yf5Zf9OZhtDgI8jfRsGEqv\nJmF0jKvFmn3ZPLlgO54mA9OHtiIxNvCc4yqlmLXuEJO+20v9MF8+HpHIriNFPPHVNjzcDEwf1oo2\n5xhHKcW0NQd5c8U+uiQEM31oK7xMZ+hwd7X44yP4bjzU6QqDvgCTNyWrVpH+0MP4DxpI+Isvnv35\nOfth/fuw4ytQDufepU7jnF0Rz0EpRcG8L8j/7DOsR444AwuAXo9bdDSmuHq41auHMTyCrNdew6NZ\nM+fyyi2zYdk4aNAH7pz994wgzpm2yesn8mnyEhrY4K3enxET3hqAyj170AfVwhzgyfDvh5NVlsXc\nDpOou/RxZ7i8/SNodKzhyd7/wvLxUJZDQbtR3Fe5jyNlGUzrMY3E/2/vzsOjqu89jr9/k0wme4ZA\nAiEJq6yyiiAoKOBSN2q9Km0fQOtS9arUPteiterV1kerbd1uW9wuLm1dqnXXXhVkU1EUBGQTJeyB\nLEQSyD6T+d0/zgABSQyQMOfA5/U8PmfOJE4++Q05v3xzfksn5/JeVlPGI188wmtrX6NDUgdu802g\n61/fIlxSSvsrLift7LNJ7NXrO4XmPm2weREV91xG0UcN+BKTKLzpp9xY/w9G547mkXGP4I/bO88r\nVFzM5l/dRN3ni1k/Io8Hx1dRbHbRtT6de5+oIaVLd3q8+OKB54Zt/gxeutRZXOWCv/B+Wjq3f3w7\naf40Hh73MAOzBjqfV1HobFjf6yyY+Ow+71XZ408QvOTiQ9rcu7GjpjhbWrKUKf83hcfOeIxTck9p\nxWQiItKaVJwdHBVnx67q+jDz1pTy7soiZq8uYVddmOSEOKrrGxicH+TxycP23W+tBeasKeEXzy8B\nA7tqwwzOD/LY5BPIyWj5anP//HwTt766nIG5GTz1s+G0T/XmJsQttuxFeP06Z97RpJchqR11BQUk\ndOt24Hlm4TpnhcIl/4Cv3nHuXp1wKZw81RnWeQgiNTXUr19PXUEBdQUF1BcUUFewztm4vKGBuIyM\nfYdXfvoYvHuLUwxe+LgzXw+gajvMOJN5kV3clp1FGLt3mCMQjoSZOnsqn2z9hEfPeJRRnUdBVRm8\n8BNnf7Lxt0HRclj1hrN64QV/hs5DKasp44r3rmBb1Tamnz6dr779iulLp1MTrmFy/8lcM+gaUhNS\nadi1i+J7f0/Fa68BYPx+An37kjjgeJIGDCDx+OMJ9OyJ8ftpqKyk6K7fsvPtt0numkLnwQX4h1/A\ny/1P53eL/sBZXc/i/lPvp6Kugnlb5jFn0xw+LVzAOR/VMvHDCNUdUqi5/Vq6vPQJdYu/oPurrxDo\n0WPfhq2vgkVPOauZZuTCj5+DTgMAZ1TejXNupLS6lDtPvnPvmhZz74O5v4fL34Wuow7p/WzOUVOc\nfV70OVe8dwUzzprBiJzW32VdRERah4qzg6PiTMCZ97WgYDvvryommOTnF6f3OujFQ3ZbW7KLqS8s\nZUh+BndOOP6QXmfmqmJueP4LOgeTmDAoh9x2SeQGk8ltl0TnYOI+c9aOCqvfcpZU79AHprzqLFTS\nWEMI1s11hrytfhvqKpzNwU+8Ek66du+8pVZm6+up37gRX2oq/pz95m999JAzd27oFGd1znANPDsB\nilfCZW+xrV0+0+ZPY1npMib2nsjNI27mwUUP8vxXz3PHyDuY2Gfi3tcK1cCrVzvzweICMPYWOPkX\ne+biAZRWl3L5e5ezcedGAE7ufDK3jLiFHhn7FURA/ZYt1C5fTs2KFdSuWEntypVEKisBMIEAiX37\nEi4rI7R1K1lTb6D9VVdhFv4FPrgbMrvz7PCJ/GnNP8hLzaOwshCLpXNKZ8Z1Gcf4/PH03WoonnYL\n4a3Oipcd77idzEmT9gaoKITPnnCGmdaWO3fCLnzcmf/YyI7aHUybN42FRQvplNKJVH8qKfFJpG79\nkuS4BFJ7n0dKQiqpCamkxKcwqvMo+mT2OfQ3lKOoOFuwdQHXzLyGv53zN4ZmD23FZCIi0ppUnB0c\nFWfiVp+t/5ZbXvmSDWVV7P8rY3ZaIFqwJZGfmcyAzhkMyssgr13SYS+YEDMFs+HFSZDeGaa8Dmk5\nsGE+rHjV2WC5ZgcEMqDf+c7+bj3G7lO8xMSce2He/TD8584Kl9+876w+2O98IDrM8Ys/8/TKp+mU\n0omiqiKm9J/CzcNv/u5rRSLw5YuQNxw69DrglyuqKuKhxQ9xVrezGJ8/vsXvtY1EqN+4kdqVq6hd\nsYLaFSuI1NTQ8Te3kjxs2N5P3PCxUyTXljNj+CXMCpUxJm8M47uMp0+7Pvt8vYaKCorvvRd8ceTc\ne4/zscLF8Ml0WPW6M8y03wRnX7f8EU0uShOOhPn7qr9TUF5AVaiKylAlVRWbqCrfSGVKJlVEqIpu\n/XDnqDu5uPfFLfqem3LUFGfzt8zn+g+u54XzXmBAhwGtmExERFqTirODo+JM3C7UEKGoopbNO6op\n3FFDYXnN3mP0cTji/E6ZmZLAwNwMBudlMCgvyKD8jBZvxm2tjX1ht2khPHcJ+BOdlQWrtzvL9Pc9\n1ynIeo6H+ADWWjaWVZOR5CeY7I9dbmth5h2w4M/O+XkPwPCrvvNp8zbP47aPb2NY9jAeHPvggRfM\ncIvKEmfj9PXznDtenQZBRl6jVUDznBU5d2sIO8Xzp9Nh80JnM+wTLoURV0O7phfSaVYkAjPOcPbE\nm7qYiD+J6lA18b54EuMPb3P55vpIT83wDDWEAIj3eSq2iIiIiKf543zkZyaTn5l8wI/XhRtYU7SL\nZVsq+HJzOcsLK/jLnFKi9Ro5GYn0zEol1BChLhyhNtRAXThCXaiB2kZHay0pCfGkBOJJTYweA3Gk\nJMSTGnDO++akceHQ3D2rUba6LifBz96Gd/7LmT92/IXOyoh+Z87e18W7eH3Jet5ctpUtO2oASPT7\nyMlIolN6IjnBRHIyEumUkURO9Dw3mERGUhsVcMbAmXc7d/QCqQcszABOyz+N2ZfMxu+LYSHZUqnZ\nMOU1mP8nZ17f2g/A7re3XVI7p1jLyIfi5c6+dsGucPZ9MHQyBNIOL4PPBz/4PTx1Fnz8CL5xvyE1\nIfXwXrMFPFXlhCJOceb3xfj2sYiIiIjsEYiPc+6S5QVhpHOnoro+zMqtO1kWLdY2llWTEO8jPclP\nVlqARH8cgXgfiX4fgfg4Ev3Osv1VdQ1U1YWpqg9TGX1cVllNZV2Yyrowf/80xB/fW8Okk7pw2ahu\nezbkblU5g+CqWXtOC8treGtZAa8vKeSrol34DIzulcW1p/WkLhyhqKKGbRW1FFXUsnDdtxTvrN1z\nJ3G3lIS4PcNAG8/fyw0mkZUa2DPibu/RebC7jGqXnEBSQhN3u4yB06Z977e1/z5mbla4s54vbMNH\nAAANNklEQVQnd55PQfpYRg0OcnpehN6BcszOQqcQ2705+Y71zpL3P7gX+py7d2GU1tDlJBhwkbMn\n2wmXOnfs2piKMxERERFpdckJ8Qzvlvm9y/cfDGstizfu4MkP1zF9bgFPzF/HDwfnctWY7vTLSf/+\nFzgI5dX1vLN8G28s3cpn678FYGiXIHdN6M95gzqTldb0CpYNEUtZZR1bK2rZFh36uSU6DHRreQ1L\nNpdTXh06qDxpifFcPaYHl4/uTupRvL3ButJKHp1bwGtLCgHokZXCH95fyx9w5jme1rsXp/U5mTHD\nsshIPgI1wRl3OStyzvota8c8RNf2yfjj2m7/P0+9s+FIGFBxJiIiInIsMsZwYrdMTuyWyYbtVTz9\n8XpeWrSFV77YwpheHbhqTA9O7dXhoIftVdaFWVlYwfLCClZEj+u2O4ug9MxK4aYze/PDIZ3p2j7l\n+18MiPMZstMTyU5PZEh+sMmvuTU6X6+sqp7d60Dsud9mdx8s1sKs1SU8MPNrnl6wgevG9mTyyK6H\nvJqnG63cWsH0uQX8e/k2AvE+Jo/sys9P7UFuMImSnbXM+7qUuV+X8t7KIl5evIU4n2FofpCxfbIY\n2yeb4zunt81wzWAXQiOuw7/gQW75YiDnnjOBK0d3b/2vE+WpBUFeWvMSd396N7Mvmb3vTt4iIuIq\nWhDk4GhBEJFDV15dz3MLN/Hsgg2U7Kqjd8dUTjmuQ6Nhk3EkxvsI+J2hk4nxcfjjfGwoq2J5tBBb\nv33vapQd0wMMzM1gQG4GZ/Tr2Ha/9B+CJZt28MD7X/PR2u10TA8wdXwvJp6YT0J803dyKqpDLCjY\nzvxvtrOgYDu1oQbaJSfsWcgkmJRAMCV6TPaTkeTcBNk9PzDUEKE+egw12D3PWesUjgDYvUXl7toi\nzucjOy1Ap4xEOmU48/CyUgPE73fXadGGb/nrnLXMWVNKWiCeKaO6csXo7nRoYm+9cEOEZVvKmbum\nlLlrSlleWAFA54xEzujfkTP6dWRkj/bNtsnBmLmqmPvfWMTztddRk5xL2vVzyDzMff+OmtUan1v9\nHPd9dh8f/vhDgokH/iuEiIjEnoqzg6PiTOTw1YcjvLVsK88s2MCG7VXUhhsINTT/e26n9EQG5GYw\nMDeDgXnpDMht+cqSsfRJQRl/en8NizfuID8ziV+e3psfDc0lzmf2FC/zv97O/G9KWba5nIiFtEA8\nI3u2JzM5gR3V9ZTXhKioDjmPq0PUN0Ra/PX9ceY7c+KMARM9MwbCDfY7r+kzkJ3mFGud0hMpq6rj\n8w07yExJ4MrR3Zk8suue4rClSnfVMXdNCTNXFfPhN9upCTWQGojntD5ZnNmvI+P6ZB/S8MctO6q5\n681VzFpdTO+OqTw+4Cu6f3wzXDQDBrbdUvreHNYY6/0kRERERMRVEuJ9XDQsj4uG7V20oSFiqQs3\nUBvau0Lk7mNuMKnZeWNuNqpne/517Sjmrinlj++t4aaXl/HovAJ6ZqWwYG0Zu+rC+AwMygtyw7jj\nOLV3FoPzg03OlbLWUhuKsKO6noqaEMZAQpwPf5yPQLxz9Mf7os+ZFt1JtNZSURPas1CKc6yhaKfz\nuKC0kgZr+e/z+/OTEfmHvPpmVlqAS07M55IT86kNNfDx2u3MWl3MzFUlvPPlNuJ8hhHdMhndqwND\n84MMyg82O2cv1BBhxkfreWTWNwDcek5frhjdHb8ZA3VfQYfeh5SzpTxVnGlBEBERERFpqTifITkh\nnmTvLFLYYsYYxvXN5rTeWby7soj/+eAbVhTu5LxBOYzplcUpx7Un2MJv3BhDUkIcSQlJdA4mtVq+\nYHICweSEVl+spSmJ/jhO79eR0/t15J4fWZZtKWfW6mJmrSrhj++tieaC3tlpDMkPMrRLkCFdgvTK\nTiPOZ/hs/bfc/vpyvi6u5Mz+HblzQn/y2jXaPuL8h9r8e/BWcaZ9zkRERERE9vD5DOcOzOHcgTmx\njuIqPp9haJd2DO3Sjmk/6Et5dT1LN5ezdHM5SzaV8+7KIv65aDPgbHPQMzuVL7dUkBtM4slLT+TM\n/h1jkttTVU56IJ0eGT3wmbZbvlJERERERI4uweQExvbJZmyfbMAZdrmhrJolm3awdHM5K7fu5D/H\n9mTq+OPaboPzFvBUcTap3yQm9ZsU6xgiIiIiIuJhxhi6d0ihe4cU/uOEtt9cuqV0C0pERERERMQF\nVJyJiIiIiIi4gIozERERERERF1BxJiIiIiIi4gIqzkRERERERFxAxZmIiIiIiIgLqDgTERERERFx\nARVnIiIiIiIiLqDiTERERERExAVUnImIiIiIiLiAijMREREREREXUHEmIiIiIiLiAirORERERERE\nXEDFmYiIiIiIiAuoOBMREREREXEBFWciIiIiIiIuoOJMRERERETEBVSciYiIiIiIuICKMxERERER\nERdQcSYiIiIiIuICKs5ERERERERcQMWZiIiIiIiIC6g4ExERERERcQFjrT1yX8yYUmDjYb5MB2B7\nK8Q5kryWWXnbntcyK2/b81rm78vb1VqbdaTCeF0r9Y9w9P07chuv5QXvZVbetue1zF7LC4fRRx7R\n4qw1GGMWWWtPjHWOg+G1zMrb9ryWWXnbntcyey3vscJr74vytj2vZVbetue1zF7LC4eXWcMaRURE\nREREXEDFmYiIiIiIiAt4sTh7ItYBDoHXMitv2/NaZuVte17L7LW8xwqvvS/K2/a8lll5257XMnst\nLxxGZs/NORMRERERETkaefHOmYiIiIiIyFFHxZmIiIiIiIgLeKo4M8acbYxZY4xZa4z5dazzfB9j\nzAZjzHJjzFJjzKJY5zkQY8xTxpgSY8yKRs9lGmNmGmO+iR7bxTJjY03kvcsYUxht56XGmHNjmbEx\nY0y+MWaOMWaVMWalMebG6POubONm8rq5jRONMZ8ZY5ZFM/82+nx3Y8zC6PXin8aYhFhnhWbzPmOM\nWd+ojYfEOmtjxpg4Y8wSY8zb0XNXtu+xymv9I7i/j/Ra/wjqI9ua1/pIr/WPoD4SPFScGWPigL8C\n5wD9gZ8aY/rHNlWLjLPWDnHx/gzPAGfv99yvgQ+stb2AD6LnbvEM380L8FC0nYdYa/99hDM1Jwzc\nZK3tD4wEro/+u3VrGzeVF9zbxnXAeGvtYGAIcLYxZiRwP07m44AdwJUxzNhYU3kBpjVq46Wxi3hA\nNwKrG527tX2POR7uH8HdfeQzeKt/BPWRbc1rfaTX+kdQH+md4gwYAay11q6z1tYDLwIXxDiT51lr\n5wPf7vf0BcCz0cfPAj86oqGa0URe17LWbrPWfhF9vAvnBzcXl7ZxM3ldyzoqo6f+6H8WGA/8K/q8\nm9q4qbyuZYzJA84D/jd6bnBp+x6j1D+2Aa/1j6A+sq15rY/0Wv8I6iPBW8VZLrC50fkWXPwDEWWB\n940xi40xV8c6zEHoaK3dFn1cBHSMZZgWusEY82V0SIcrhj/szxjTDRgKLMQDbbxfXnBxG0eHEywF\nSoCZQAFQbq0NRz/FVdeL/fNaa3e38T3RNn7IGBOIYcT9PQzcDESi5+1xcfseg7zYP4I3+0jXX7ub\n4Nrr927qI9uG1/pHUB/ppeLMi0Zba0/AGWpyvTHm1FgHOljW2WvB1X+xAB4FeuLc/t4GPBDbON9l\njEkFXgF+aa3d2fhjbmzjA+R1dRtbaxustUOAPJy7CH1jHKlZ++c1xgwAbsXJPRzIBG6JYcQ9jDHn\nAyXW2sWxziJHHU/3kW68djfB1ddvUB/ZlrzWP4L6SC8VZ4VAfqPzvOhzrmWtLYweS4DXcH4ovKDY\nGJMDED2WxDhPs6y1xdEf5AjwJC5rZ2OMH+ci/py19tXo065t4wPldXsb72atLQfmAKOAoDEmPvoh\nV14vGuU9Ozpcxlpr64CncU8bnwL80BizAWe43HjgETzQvscQz/WP4Nk+0rXX7qa4/fqtPvLI8Fr/\nCMduH+ml4uxzoFd09ZME4CfAmzHO1CRjTIoxJm33Y+AsYEXz/5drvAlcFn18GfBGDLN8r90X8KgL\ncVE7R8cdzwBWW2sfbPQhV7ZxU3ld3sZZxphg9HEScCbOPIA5wMXRT3NTGx8o71eNfhExOGPTXdHG\n1tpbrbV51tpuONfd2dbaSbi0fY9RnuofwdN9pCuv3c1x+fVbfWQb8lr/COojAYxzt9gbjLM06cNA\nHPCUtfaeGEdqkjGmB85fAgHigefdmNcY8wIwFugAFAN3Aq8DLwFdgI3ARGutKyYYN5F3LM5QAgts\nAK5pNFY9powxo4EPgeXsHYv8G5wx6q5r42by/hT3tvEgnMm2cTh/cHrJWvu76M/gizjDH5YAk6N/\ncYupZvLOBrIAAywFrm00KdoVjDFjgV9Za893a/seq7zUP4I3+kiv9Y+gPrKtea2P9Fr/COojwWPF\nmYiIiIiIyNHKS8MaRUREREREjloqzkRERERERFxAxZmIiIiIiIgLqDgTERERERFxARVnIiIiIiIi\nLqDiTERERERExAVUnImIiIiIiLjA/wN3SRFTyoMawgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 1080x720 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}