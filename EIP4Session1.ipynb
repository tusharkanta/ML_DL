{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "EIP4Session1.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tusharkanta/ML_DL/blob/master/EIP4Session1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_QGGMAyT9k7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYkd8v1sT9lC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Add, Activation, Convolution2D, MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "from keras.datasets import mnist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CdZFfsBxT9lG",
        "colab_type": "code",
        "outputId": "f88cc1e5-b123-4a6c-80b9-9904797c304e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        }
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "#print(Y_train)\n",
        "print (X_train.shape)\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.imshow(X_train[18])\n"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fb622b20550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nif8H69IVvP1A3+sAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "meUID7gLT9lO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], 28, 28,1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNmAkIJ5T9lZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.astype ('float32')\n",
        "X_test = X_test.astype ('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5SWXEP7T9lg",
        "colab_type": "code",
        "outputId": "d3449454-3c4b-487a-d572-e0a61ce83056",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_train[:10]"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHBH6meLT9lo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert 1-dimensional class arrays to 10-dimensional class matrices\n",
        "Y_train = np_utils.to_categorical(y_train, 10)\n",
        "Y_test = np_utils.to_categorical(y_test, 10)\n",
        "#print(Y_train)\n",
        "#print(Y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSNLs1OST9lv",
        "colab_type": "code",
        "outputId": "7cbad7b3-5e40-4996-a3f3-a48807dbd42b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "Y_train[:10]"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRdg3sCPT9l0",
        "colab_type": "code",
        "outputId": "6fbb460d-439e-4c97-d9f1-e2b690fe9ff4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "from keras.layers import Activation\n",
        "model = Sequential()\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Convolution2D(8, (3, 3), activation='relu', input_shape=(28,28,1)))\n",
        "model.add(Convolution2D(8, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(2, 2))\n",
        "model.add(Convolution2D(8, (3, 3), activation='relu'))\n",
        "model.add(Convolution2D(16, (3, 3), activation='relu'))\n",
        "model.add(Convolution2D(32, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(2, 2))\n",
        "model.add(Convolution2D(10, (3, 3)))\n",
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))\n",
        "model.summary()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_19 (Conv2D)           (None, 26, 26, 8)         80        \n",
            "_________________________________________________________________\n",
            "conv2d_20 (Conv2D)           (None, 24, 24, 8)         584       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 12, 12, 8)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_21 (Conv2D)           (None, 10, 10, 8)         584       \n",
            "_________________________________________________________________\n",
            "conv2d_22 (Conv2D)           (None, 8, 8, 16)          1168      \n",
            "_________________________________________________________________\n",
            "conv2d_23 (Conv2D)           (None, 6, 6, 32)          4640      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 3, 3, 32)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_24 (Conv2D)           (None, 1, 1, 10)          2890      \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 9,946\n",
            "Trainable params: 9,946\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NR88WRjT9l6",
        "colab_type": "code",
        "outputId": "fffcdf81-f1e3-49f8-ed5a-7c6e55f52c62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_19 (Conv2D)           (None, 26, 26, 8)         80        \n",
            "_________________________________________________________________\n",
            "conv2d_20 (Conv2D)           (None, 24, 24, 8)         584       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 12, 12, 8)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_21 (Conv2D)           (None, 10, 10, 8)         584       \n",
            "_________________________________________________________________\n",
            "conv2d_22 (Conv2D)           (None, 8, 8, 16)          1168      \n",
            "_________________________________________________________________\n",
            "conv2d_23 (Conv2D)           (None, 6, 6, 32)          4640      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 3, 3, 32)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_24 (Conv2D)           (None, 1, 1, 10)          2890      \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 9,946\n",
            "Trainable params: 9,946\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I686m2UiT9l_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer='adam',\n",
        "             metrics=['categorical_accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "it2QQkY-T9mC",
        "colab_type": "code",
        "outputId": "bc084fc6-9d3e-421b-bdcc-1e841afec826",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "# cross validation and dropouts are ways to address overfitting. \n",
        "# here we are taking cross validation route to addess this\n",
        "kfold = StratifiedKFold(n_splits=6, shuffle=True, random_state=7)\n",
        "cvscores = []\n",
        "(X, Y) = (X_train, y_train)\n",
        "for trainIDX, testIDX in kfold.split(X, Y):\n",
        "    # Fit the model\n",
        "    model.fit(X[trainIDX], Y_train[trainIDX], epochs=15, batch_size=96, verbose=1, validation_data=(X_test, Y_test))\n",
        "    # Evaluate the model\n",
        "    scores = model.evaluate(X[testIDX], Y_train[testIDX], verbose=0)\n",
        "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "    cvscores.append(scores[1] * 100)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 49995 samples, validate on 10000 samples\n",
            "Epoch 1/15\n",
            "49995/49995 [==============================] - 34s 678us/step - loss: 0.3806 - categorical_accuracy: 0.8853 - val_loss: 0.1131 - val_categorical_accuracy: 0.9659\n",
            "Epoch 2/15\n",
            "49995/49995 [==============================] - 33s 661us/step - loss: 0.1070 - categorical_accuracy: 0.9672 - val_loss: 0.0663 - val_categorical_accuracy: 0.9797\n",
            "Epoch 3/15\n",
            "49995/49995 [==============================] - 33s 666us/step - loss: 0.0771 - categorical_accuracy: 0.9756 - val_loss: 0.0708 - val_categorical_accuracy: 0.9779\n",
            "Epoch 4/15\n",
            "49995/49995 [==============================] - 33s 667us/step - loss: 0.0620 - categorical_accuracy: 0.9806 - val_loss: 0.0495 - val_categorical_accuracy: 0.9834\n",
            "Epoch 5/15\n",
            "49995/49995 [==============================] - 33s 666us/step - loss: 0.0534 - categorical_accuracy: 0.9834 - val_loss: 0.0452 - val_categorical_accuracy: 0.9849\n",
            "Epoch 6/15\n",
            "49995/49995 [==============================] - 33s 657us/step - loss: 0.0449 - categorical_accuracy: 0.9856 - val_loss: 0.0458 - val_categorical_accuracy: 0.9841\n",
            "Epoch 7/15\n",
            "49995/49995 [==============================] - 33s 666us/step - loss: 0.0385 - categorical_accuracy: 0.9877 - val_loss: 0.0392 - val_categorical_accuracy: 0.9876\n",
            "Epoch 8/15\n",
            "49995/49995 [==============================] - 34s 671us/step - loss: 0.0349 - categorical_accuracy: 0.9889 - val_loss: 0.0665 - val_categorical_accuracy: 0.9785\n",
            "Epoch 9/15\n",
            "49995/49995 [==============================] - 33s 670us/step - loss: 0.0314 - categorical_accuracy: 0.9905 - val_loss: 0.0336 - val_categorical_accuracy: 0.9896\n",
            "Epoch 10/15\n",
            "49995/49995 [==============================] - 33s 658us/step - loss: 0.0296 - categorical_accuracy: 0.9899 - val_loss: 0.0435 - val_categorical_accuracy: 0.9855\n",
            "Epoch 11/15\n",
            "49995/49995 [==============================] - 33s 665us/step - loss: 0.0252 - categorical_accuracy: 0.9916 - val_loss: 0.0322 - val_categorical_accuracy: 0.9901\n",
            "Epoch 12/15\n",
            "49995/49995 [==============================] - 33s 655us/step - loss: 0.0250 - categorical_accuracy: 0.9918 - val_loss: 0.0399 - val_categorical_accuracy: 0.9868\n",
            "Epoch 13/15\n",
            "49995/49995 [==============================] - 33s 662us/step - loss: 0.0207 - categorical_accuracy: 0.9930 - val_loss: 0.0576 - val_categorical_accuracy: 0.9831\n",
            "Epoch 14/15\n",
            "49995/49995 [==============================] - 33s 659us/step - loss: 0.0202 - categorical_accuracy: 0.9934 - val_loss: 0.0438 - val_categorical_accuracy: 0.9875\n",
            "Epoch 15/15\n",
            "49995/49995 [==============================] - 33s 665us/step - loss: 0.0189 - categorical_accuracy: 0.9937 - val_loss: 0.0495 - val_categorical_accuracy: 0.9857\n",
            "categorical_accuracy: 98.50%\n",
            "Train on 49998 samples, validate on 10000 samples\n",
            "Epoch 1/15\n",
            "49998/49998 [==============================] - 33s 664us/step - loss: 0.0246 - categorical_accuracy: 0.9926 - val_loss: 0.0486 - val_categorical_accuracy: 0.9856\n",
            "Epoch 2/15\n",
            "49998/49998 [==============================] - 33s 669us/step - loss: 0.0213 - categorical_accuracy: 0.9932 - val_loss: 0.0362 - val_categorical_accuracy: 0.9895\n",
            "Epoch 3/15\n",
            "49998/49998 [==============================] - 34s 673us/step - loss: 0.0171 - categorical_accuracy: 0.9943 - val_loss: 0.0409 - val_categorical_accuracy: 0.9890\n",
            "Epoch 4/15\n",
            "49998/49998 [==============================] - 33s 661us/step - loss: 0.0171 - categorical_accuracy: 0.9948 - val_loss: 0.0339 - val_categorical_accuracy: 0.9901\n",
            "Epoch 5/15\n",
            "49998/49998 [==============================] - 33s 661us/step - loss: 0.0146 - categorical_accuracy: 0.9953 - val_loss: 0.0404 - val_categorical_accuracy: 0.9898\n",
            "Epoch 6/15\n",
            "49998/49998 [==============================] - 32s 648us/step - loss: 0.0145 - categorical_accuracy: 0.9951 - val_loss: 0.0472 - val_categorical_accuracy: 0.9888\n",
            "Epoch 7/15\n",
            "49998/49998 [==============================] - 32s 648us/step - loss: 0.0146 - categorical_accuracy: 0.9950 - val_loss: 0.0382 - val_categorical_accuracy: 0.9902\n",
            "Epoch 8/15\n",
            "49998/49998 [==============================] - 34s 671us/step - loss: 0.0112 - categorical_accuracy: 0.9963 - val_loss: 0.0507 - val_categorical_accuracy: 0.9877\n",
            "Epoch 9/15\n",
            "49998/49998 [==============================] - 32s 646us/step - loss: 0.0125 - categorical_accuracy: 0.9958 - val_loss: 0.0428 - val_categorical_accuracy: 0.9888\n",
            "Epoch 10/15\n",
            "49998/49998 [==============================] - 33s 661us/step - loss: 0.0098 - categorical_accuracy: 0.9966 - val_loss: 0.0455 - val_categorical_accuracy: 0.9901\n",
            "Epoch 11/15\n",
            "49998/49998 [==============================] - 33s 669us/step - loss: 0.0087 - categorical_accuracy: 0.9972 - val_loss: 0.0493 - val_categorical_accuracy: 0.9890\n",
            "Epoch 12/15\n",
            "49998/49998 [==============================] - 33s 667us/step - loss: 0.0112 - categorical_accuracy: 0.9964 - val_loss: 0.0449 - val_categorical_accuracy: 0.9912\n",
            "Epoch 13/15\n",
            "49998/49998 [==============================] - 33s 661us/step - loss: 0.0080 - categorical_accuracy: 0.9975 - val_loss: 0.0519 - val_categorical_accuracy: 0.9895\n",
            "Epoch 14/15\n",
            "49998/49998 [==============================] - 33s 661us/step - loss: 0.0088 - categorical_accuracy: 0.9973 - val_loss: 0.0483 - val_categorical_accuracy: 0.9906\n",
            "Epoch 15/15\n",
            "49998/49998 [==============================] - 33s 659us/step - loss: 0.0084 - categorical_accuracy: 0.9973 - val_loss: 0.0476 - val_categorical_accuracy: 0.9904\n",
            "categorical_accuracy: 99.17%\n",
            "Train on 49999 samples, validate on 10000 samples\n",
            "Epoch 1/15\n",
            "49999/49999 [==============================] - 34s 675us/step - loss: 0.0167 - categorical_accuracy: 0.9947 - val_loss: 0.0487 - val_categorical_accuracy: 0.9877\n",
            "Epoch 2/15\n",
            "49999/49999 [==============================] - 34s 673us/step - loss: 0.0091 - categorical_accuracy: 0.9969 - val_loss: 0.0490 - val_categorical_accuracy: 0.9886\n",
            "Epoch 3/15\n",
            "49999/49999 [==============================] - 33s 667us/step - loss: 0.0085 - categorical_accuracy: 0.9971 - val_loss: 0.0495 - val_categorical_accuracy: 0.9893\n",
            "Epoch 4/15\n",
            "49999/49999 [==============================] - 34s 676us/step - loss: 0.0100 - categorical_accuracy: 0.9965 - val_loss: 0.0609 - val_categorical_accuracy: 0.9862\n",
            "Epoch 5/15\n",
            "49999/49999 [==============================] - 33s 664us/step - loss: 0.0081 - categorical_accuracy: 0.9974 - val_loss: 0.0515 - val_categorical_accuracy: 0.9896\n",
            "Epoch 6/15\n",
            "49999/49999 [==============================] - 33s 667us/step - loss: 0.0088 - categorical_accuracy: 0.9969 - val_loss: 0.0461 - val_categorical_accuracy: 0.9904\n",
            "Epoch 7/15\n",
            "49999/49999 [==============================] - 33s 667us/step - loss: 0.0055 - categorical_accuracy: 0.9983 - val_loss: 0.0483 - val_categorical_accuracy: 0.9902\n",
            "Epoch 8/15\n",
            "49999/49999 [==============================] - 33s 661us/step - loss: 0.0061 - categorical_accuracy: 0.9980 - val_loss: 0.0689 - val_categorical_accuracy: 0.9874\n",
            "Epoch 9/15\n",
            "49999/49999 [==============================] - 33s 662us/step - loss: 0.0080 - categorical_accuracy: 0.9972 - val_loss: 0.0509 - val_categorical_accuracy: 0.9896\n",
            "Epoch 10/15\n",
            "49999/49999 [==============================] - 33s 659us/step - loss: 0.0063 - categorical_accuracy: 0.9980 - val_loss: 0.0490 - val_categorical_accuracy: 0.9910\n",
            "Epoch 11/15\n",
            "49999/49999 [==============================] - 33s 659us/step - loss: 0.0070 - categorical_accuracy: 0.9976 - val_loss: 0.0526 - val_categorical_accuracy: 0.9900\n",
            "Epoch 12/15\n",
            "49999/49999 [==============================] - 33s 658us/step - loss: 0.0050 - categorical_accuracy: 0.9985 - val_loss: 0.0687 - val_categorical_accuracy: 0.9879\n",
            "Epoch 13/15\n",
            "49999/49999 [==============================] - 33s 657us/step - loss: 0.0071 - categorical_accuracy: 0.9980 - val_loss: 0.0642 - val_categorical_accuracy: 0.9893\n",
            "Epoch 14/15\n",
            "49999/49999 [==============================] - 33s 654us/step - loss: 0.0072 - categorical_accuracy: 0.9977 - val_loss: 0.0675 - val_categorical_accuracy: 0.9883\n",
            "Epoch 15/15\n",
            "49999/49999 [==============================] - 33s 657us/step - loss: 0.0074 - categorical_accuracy: 0.9975 - val_loss: 0.0484 - val_categorical_accuracy: 0.9908\n",
            "categorical_accuracy: 99.43%\n",
            "Train on 50001 samples, validate on 10000 samples\n",
            "Epoch 1/15\n",
            "50001/50001 [==============================] - 33s 657us/step - loss: 0.0113 - categorical_accuracy: 0.9963 - val_loss: 0.0620 - val_categorical_accuracy: 0.9877\n",
            "Epoch 2/15\n",
            "50001/50001 [==============================] - 33s 659us/step - loss: 0.0071 - categorical_accuracy: 0.9979 - val_loss: 0.0580 - val_categorical_accuracy: 0.9890\n",
            "Epoch 3/15\n",
            "50001/50001 [==============================] - 33s 658us/step - loss: 0.0066 - categorical_accuracy: 0.9977 - val_loss: 0.0522 - val_categorical_accuracy: 0.9894\n",
            "Epoch 4/15\n",
            "50001/50001 [==============================] - 33s 659us/step - loss: 0.0053 - categorical_accuracy: 0.9981 - val_loss: 0.0627 - val_categorical_accuracy: 0.9892\n",
            "Epoch 5/15\n",
            "50001/50001 [==============================] - 33s 659us/step - loss: 0.0061 - categorical_accuracy: 0.9981 - val_loss: 0.0624 - val_categorical_accuracy: 0.9885\n",
            "Epoch 6/15\n",
            "50001/50001 [==============================] - 33s 657us/step - loss: 0.0052 - categorical_accuracy: 0.9983 - val_loss: 0.0680 - val_categorical_accuracy: 0.9872\n",
            "Epoch 7/15\n",
            "50001/50001 [==============================] - 33s 654us/step - loss: 0.0057 - categorical_accuracy: 0.9981 - val_loss: 0.0563 - val_categorical_accuracy: 0.9904\n",
            "Epoch 8/15\n",
            "50001/50001 [==============================] - 33s 652us/step - loss: 0.0061 - categorical_accuracy: 0.9980 - val_loss: 0.0601 - val_categorical_accuracy: 0.9894\n",
            "Epoch 9/15\n",
            "50001/50001 [==============================] - 33s 652us/step - loss: 0.0058 - categorical_accuracy: 0.9981 - val_loss: 0.0720 - val_categorical_accuracy: 0.9882\n",
            "Epoch 10/15\n",
            "50001/50001 [==============================] - 33s 663us/step - loss: 0.0055 - categorical_accuracy: 0.9984 - val_loss: 0.0641 - val_categorical_accuracy: 0.9896\n",
            "Epoch 11/15\n",
            "50001/50001 [==============================] - 32s 648us/step - loss: 0.0061 - categorical_accuracy: 0.9984 - val_loss: 0.0667 - val_categorical_accuracy: 0.9881\n",
            "Epoch 12/15\n",
            "50001/50001 [==============================] - 33s 654us/step - loss: 0.0032 - categorical_accuracy: 0.9994 - val_loss: 0.0626 - val_categorical_accuracy: 0.9896\n",
            "Epoch 13/15\n",
            "50001/50001 [==============================] - 32s 648us/step - loss: 0.0056 - categorical_accuracy: 0.9982 - val_loss: 0.0677 - val_categorical_accuracy: 0.9886\n",
            "Epoch 14/15\n",
            "50001/50001 [==============================] - 33s 655us/step - loss: 0.0056 - categorical_accuracy: 0.9984 - val_loss: 0.0768 - val_categorical_accuracy: 0.9892\n",
            "Epoch 15/15\n",
            "50001/50001 [==============================] - 33s 662us/step - loss: 0.0049 - categorical_accuracy: 0.9984 - val_loss: 0.0753 - val_categorical_accuracy: 0.9871\n",
            "categorical_accuracy: 99.39%\n",
            "Train on 50003 samples, validate on 10000 samples\n",
            "Epoch 1/15\n",
            "50003/50003 [==============================] - 33s 654us/step - loss: 0.0124 - categorical_accuracy: 0.9966 - val_loss: 0.0624 - val_categorical_accuracy: 0.9893\n",
            "Epoch 2/15\n",
            "50003/50003 [==============================] - 33s 667us/step - loss: 0.0038 - categorical_accuracy: 0.9988 - val_loss: 0.0547 - val_categorical_accuracy: 0.9906\n",
            "Epoch 3/15\n",
            "50003/50003 [==============================] - 33s 653us/step - loss: 0.0045 - categorical_accuracy: 0.9985 - val_loss: 0.0801 - val_categorical_accuracy: 0.9854\n",
            "Epoch 4/15\n",
            "50003/50003 [==============================] - 33s 660us/step - loss: 0.0046 - categorical_accuracy: 0.9985 - val_loss: 0.0570 - val_categorical_accuracy: 0.9901\n",
            "Epoch 5/15\n",
            "50003/50003 [==============================] - 33s 654us/step - loss: 0.0013 - categorical_accuracy: 0.9996 - val_loss: 0.0581 - val_categorical_accuracy: 0.9910\n",
            "Epoch 6/15\n",
            "50003/50003 [==============================] - 33s 651us/step - loss: 0.0081 - categorical_accuracy: 0.9978 - val_loss: 0.0565 - val_categorical_accuracy: 0.9907\n",
            "Epoch 7/15\n",
            "50003/50003 [==============================] - 33s 661us/step - loss: 0.0061 - categorical_accuracy: 0.9980 - val_loss: 0.0626 - val_categorical_accuracy: 0.9897\n",
            "Epoch 8/15\n",
            "50003/50003 [==============================] - 33s 656us/step - loss: 0.0039 - categorical_accuracy: 0.9986 - val_loss: 0.0534 - val_categorical_accuracy: 0.9906\n",
            "Epoch 9/15\n",
            "50003/50003 [==============================] - 33s 652us/step - loss: 7.7779e-04 - categorical_accuracy: 0.9997 - val_loss: 0.0550 - val_categorical_accuracy: 0.9908\n",
            "Epoch 10/15\n",
            "50003/50003 [==============================] - 33s 655us/step - loss: 0.0068 - categorical_accuracy: 0.9981 - val_loss: 0.0770 - val_categorical_accuracy: 0.9878\n",
            "Epoch 11/15\n",
            "50003/50003 [==============================] - 32s 648us/step - loss: 0.0070 - categorical_accuracy: 0.9977 - val_loss: 0.0605 - val_categorical_accuracy: 0.9900\n",
            "Epoch 12/15\n",
            "50003/50003 [==============================] - 32s 649us/step - loss: 0.0045 - categorical_accuracy: 0.9986 - val_loss: 0.0559 - val_categorical_accuracy: 0.9901\n",
            "Epoch 13/15\n",
            "50003/50003 [==============================] - 33s 658us/step - loss: 0.0025 - categorical_accuracy: 0.9992 - val_loss: 0.0598 - val_categorical_accuracy: 0.9901\n",
            "Epoch 14/15\n",
            "50003/50003 [==============================] - 33s 657us/step - loss: 0.0046 - categorical_accuracy: 0.9988 - val_loss: 0.0590 - val_categorical_accuracy: 0.9899\n",
            "Epoch 15/15\n",
            "50003/50003 [==============================] - 33s 652us/step - loss: 0.0022 - categorical_accuracy: 0.9993 - val_loss: 0.0609 - val_categorical_accuracy: 0.9904\n",
            "categorical_accuracy: 99.75%\n",
            "Train on 50004 samples, validate on 10000 samples\n",
            "Epoch 1/15\n",
            "50004/50004 [==============================] - 33s 659us/step - loss: 0.0080 - categorical_accuracy: 0.9978 - val_loss: 0.0665 - val_categorical_accuracy: 0.9894\n",
            "Epoch 2/15\n",
            "50004/50004 [==============================] - 33s 656us/step - loss: 0.0065 - categorical_accuracy: 0.9981 - val_loss: 0.0639 - val_categorical_accuracy: 0.9895\n",
            "Epoch 3/15\n",
            "50004/50004 [==============================] - 33s 657us/step - loss: 0.0051 - categorical_accuracy: 0.9985 - val_loss: 0.0586 - val_categorical_accuracy: 0.9905\n",
            "Epoch 4/15\n",
            "50004/50004 [==============================] - 33s 652us/step - loss: 0.0013 - categorical_accuracy: 0.9997 - val_loss: 0.0597 - val_categorical_accuracy: 0.9913\n",
            "Epoch 5/15\n",
            "50004/50004 [==============================] - 33s 654us/step - loss: 0.0044 - categorical_accuracy: 0.9989 - val_loss: 0.0779 - val_categorical_accuracy: 0.9895\n",
            "Epoch 6/15\n",
            "50004/50004 [==============================] - 33s 654us/step - loss: 0.0082 - categorical_accuracy: 0.9979 - val_loss: 0.0687 - val_categorical_accuracy: 0.9908\n",
            "Epoch 7/15\n",
            "50004/50004 [==============================] - 33s 653us/step - loss: 0.0052 - categorical_accuracy: 0.9986 - val_loss: 0.0806 - val_categorical_accuracy: 0.9896\n",
            "Epoch 8/15\n",
            "50004/50004 [==============================] - 33s 655us/step - loss: 0.0046 - categorical_accuracy: 0.9987 - val_loss: 0.0716 - val_categorical_accuracy: 0.9894\n",
            "Epoch 9/15\n",
            "50004/50004 [==============================] - 33s 659us/step - loss: 0.0054 - categorical_accuracy: 0.9985 - val_loss: 0.0884 - val_categorical_accuracy: 0.9889\n",
            "Epoch 10/15\n",
            "50004/50004 [==============================] - 33s 662us/step - loss: 0.0041 - categorical_accuracy: 0.9988 - val_loss: 0.0727 - val_categorical_accuracy: 0.9907\n",
            "Epoch 11/15\n",
            "50004/50004 [==============================] - 33s 654us/step - loss: 0.0045 - categorical_accuracy: 0.9988 - val_loss: 0.0654 - val_categorical_accuracy: 0.9908\n",
            "Epoch 12/15\n",
            "50004/50004 [==============================] - 34s 672us/step - loss: 0.0045 - categorical_accuracy: 0.9988 - val_loss: 0.0693 - val_categorical_accuracy: 0.9903\n",
            "Epoch 13/15\n",
            "50004/50004 [==============================] - 33s 663us/step - loss: 0.0021 - categorical_accuracy: 0.9994 - val_loss: 0.0796 - val_categorical_accuracy: 0.9881\n",
            "Epoch 14/15\n",
            "50004/50004 [==============================] - 33s 656us/step - loss: 0.0031 - categorical_accuracy: 0.9990 - val_loss: 0.0760 - val_categorical_accuracy: 0.9900\n",
            "Epoch 15/15\n",
            "50004/50004 [==============================] - 33s 664us/step - loss: 0.0062 - categorical_accuracy: 0.9983 - val_loss: 0.0712 - val_categorical_accuracy: 0.9907\n",
            "categorical_accuracy: 99.79%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQBN1AYIT9mf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cvscores\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOrpcd9PT9mm",
        "colab_type": "code",
        "outputId": "1f7928f4-e8b0-427a-8057-e05e08e897a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(score)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.07118246783003451, 0.9907]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oB4rskNlT9mp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cq33xksJT9mt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "layer_dict = dict([(layer.name, layer) for layer in model.layers])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLntqkquT9mv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from keras import backend as K\n",
        "%matplotlib inline\n",
        "# util function to convert a tensor into a valid image\n",
        "def deprocess_image(x):\n",
        "    # normalize tensor: center on 0., ensure std is 0.1\n",
        "    x -= x.mean()\n",
        "    x /= (x.std() + 1e-5)\n",
        "    x *= 0.1\n",
        "\n",
        "    # clip to [0, 1]\n",
        "    x += 0.5\n",
        "    x = np.clip(x, 0, 1)\n",
        "\n",
        "    # convert to RGB array\n",
        "    x *= 255\n",
        "    #x = x.transpose((1, 2, 0))\n",
        "    x = np.clip(x, 0, 255).astype('uint8')\n",
        "    return x\n",
        "\n",
        "def vis_img_in_filter(img = np.array(X_train[3]).reshape((1, 28, 28, 1)).astype(np.float64), \n",
        "                      layer_name = 'conv2d_1'):\n",
        "    layer_output = layer_dict[layer_name].output\n",
        "    img_ascs = list()\n",
        "    for filter_index in range(layer_output.shape[3]):\n",
        "        # build a loss function that maximizes the activation\n",
        "        # of the nth filter of the layer considered\n",
        "        loss = K.mean(layer_output[:, :, :, filter_index])\n",
        "\n",
        "        # compute the gradient of the input picture wrt this loss\n",
        "        grads = K.gradients(loss, model.input)[0]\n",
        "\n",
        "        # normalization trick: we normalize the gradient\n",
        "        grads /= (K.sqrt(K.mean(K.square(grads))) + 1e-5)\n",
        "\n",
        "        # this function returns the loss and grads given the input picture\n",
        "        iterate = K.function([model.input], [loss, grads])\n",
        "\n",
        "        # step size for gradient ascent\n",
        "        step = 5.\n",
        "\n",
        "        img_asc = np.array(img)\n",
        "        # run gradient ascent for 20 steps\n",
        "        for i in range(20):\n",
        "            loss_value, grads_value = iterate([img_asc])\n",
        "            img_asc += grads_value * step\n",
        "\n",
        "        img_asc = img_asc[0]\n",
        "        img_ascs.append(deprocess_image(img_asc).reshape((28, 28)))\n",
        "        \n",
        "    if layer_output.shape[3] >= 35:\n",
        "        plot_x, plot_y = 6, 6\n",
        "    elif layer_output.shape[3] >= 23:\n",
        "        plot_x, plot_y = 4, 6\n",
        "    elif layer_output.shape[3] >= 11:\n",
        "        plot_x, plot_y = 2, 6\n",
        "    else:\n",
        "        plot_x, plot_y = 1, 2\n",
        "    fig, ax = plt.subplots(plot_x, plot_y, figsize = (12, 12))\n",
        "    ax[0, 0].imshow(img.reshape((28, 28)), cmap = 'gray')\n",
        "    ax[0, 0].set_title('Input image')\n",
        "    fig.suptitle('Input image and %s filters' % (layer_name,))\n",
        "    fig.tight_layout(pad = 0.3, rect = [0, 0, 0.9, 0.9])\n",
        "    for (x, y) in [(i, j) for i in range(plot_x) for j in range(plot_y)]:\n",
        "        if x == 0 and y == 0:\n",
        "            continue\n",
        "        ax[x, y].imshow(img_ascs[x * plot_y + y - 1], cmap = 'gray')\n",
        "        ax[x, y].set_title('filter %d' % (x * plot_y + y - 1))\n",
        "\n",
        "vis_img_in_filter()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TrD5TI9qT9my",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}