{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "MNISTClassification_S1.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tusharkanta/ML_DL/blob/master/MNISTClassification_S1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URpaSlCt6ZvB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTp-zldS6ZvV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Add, Activation, Convolution2D, MaxPooling2D, BatchNormalization\n",
        "from keras.utils import np_utils\n",
        "from keras.datasets import mnist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6o1d0vcd6Zvp",
        "colab_type": "code",
        "outputId": "6e987c53-c72e-4b47-c8d3-bdb3f82c607f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        }
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "#print(Y_train)\n",
        "print (X_train.shape)\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.imshow(X_train[18])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f218edb76a0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nif8H69IVvP1A3+sAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAsygv276Zv2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], 28, 28,1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ernzdbe66ZwA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.astype ('float32')\n",
        "X_test = X_test.astype ('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YfJSmkM96ZwN",
        "colab_type": "code",
        "outputId": "7a2c13ea-68de-4f21-c240-12069e2d9bda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "y_train[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jni5jTYD6Zwd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert 1-dimensional class arrays to 10-dimensional class matrices\n",
        "Y_train = np_utils.to_categorical(y_train, 10)\n",
        "Y_test = np_utils.to_categorical(y_test, 10)\n",
        "#print(Y_train)\n",
        "#print(Y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4G-mZ4vt6Zwp",
        "colab_type": "code",
        "outputId": "7394fb7f-f184-4dcf-f46c-80071322eff3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        }
      },
      "source": [
        "Y_train[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXBQiR-K6Zw2",
        "colab_type": "code",
        "outputId": "29e3c899-0ce4-4c99-aeec-9b01efa20b45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras.layers import Activation\n",
        "model = Sequential()\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Convolution2D(8, (3, 3), activation='relu', input_shape=(28,28,1))) #26\n",
        "model.add(BatchNormalization())\n",
        "model.add(Convolution2D(8, (3, 3), activation='relu')) #24\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(2, 2)) #12\n",
        "model.add(Convolution2D(8, (3, 3), activation='relu')) #10\n",
        "model.add(BatchNormalization())\n",
        "model.add(Convolution2D(16, (3, 3), activation='relu')) #8\n",
        "model.add(BatchNormalization())\n",
        "model.add(Convolution2D(32, (3, 3), activation='relu')) #6\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(2, 2)) #3\n",
        "model.add(Convolution2D(10, (3, 3))) #1\n",
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_2 (Conv2D)            (None, 26, 26, 8)         80        \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 26, 26, 8)         32        \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 24, 24, 8)         584       \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 24, 24, 8)         32        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 8)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 10, 10, 8)         584       \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 10, 10, 8)         32        \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 8, 8, 16)          1168      \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 8, 8, 16)          64        \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 6, 6, 32)          4640      \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 6, 6, 32)          128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 3, 3, 32)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 1, 1, 10)          2890      \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 10,234\n",
            "Trainable params: 10,090\n",
            "Non-trainable params: 144\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NaQsW2su6ZxC",
        "colab_type": "code",
        "outputId": "e5d4645d-60dc-44de-ece9-e256d889cab9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 715
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_2 (Conv2D)            (None, 26, 26, 8)         80        \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 26, 26, 8)         32        \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 24, 24, 8)         584       \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 24, 24, 8)         32        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 8)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 10, 10, 8)         584       \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 10, 10, 8)         32        \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 8, 8, 16)          1168      \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 8, 8, 16)          64        \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 6, 6, 32)          4640      \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 6, 6, 32)          128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 3, 3, 32)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 1, 1, 10)          2890      \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 10,234\n",
            "Trainable params: 10,090\n",
            "Non-trainable params: 144\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xd6NBCyb6ZxK",
        "colab_type": "code",
        "outputId": "be3c4a64-2dfa-47dd-83c1-aa13fb0218c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        }
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer='adam',\n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5miKVls36ZxW",
        "colab_type": "code",
        "outputId": "6b4adb70-ae05-44c7-f9fd-55a30a55a1ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 937
        }
      },
      "source": [
        "model.fit(X_train, Y_train, batch_size=32, \n",
        "          epochs=20, verbose=1, \n",
        "          validation_data=(X_test, Y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "60000/60000 [==============================] - 78s 1ms/step - loss: 0.1567 - acc: 0.9516 - val_loss: 0.0567 - val_acc: 0.9824\n",
            "Epoch 2/20\n",
            "60000/60000 [==============================] - 79s 1ms/step - loss: 0.0520 - acc: 0.9839 - val_loss: 0.0507 - val_acc: 0.9840\n",
            "Epoch 3/20\n",
            "60000/60000 [==============================] - 79s 1ms/step - loss: 0.0390 - acc: 0.9876 - val_loss: 0.0484 - val_acc: 0.9859\n",
            "Epoch 4/20\n",
            "60000/60000 [==============================] - 78s 1ms/step - loss: 0.0324 - acc: 0.9896 - val_loss: 0.0391 - val_acc: 0.9887\n",
            "Epoch 5/20\n",
            "60000/60000 [==============================] - 79s 1ms/step - loss: 0.0270 - acc: 0.9910 - val_loss: 0.0315 - val_acc: 0.9911\n",
            "Epoch 6/20\n",
            "60000/60000 [==============================] - 80s 1ms/step - loss: 0.0254 - acc: 0.9920 - val_loss: 0.0476 - val_acc: 0.9862\n",
            "Epoch 7/20\n",
            "60000/60000 [==============================] - 80s 1ms/step - loss: 0.0210 - acc: 0.9933 - val_loss: 0.0329 - val_acc: 0.9907\n",
            "Epoch 8/20\n",
            "60000/60000 [==============================] - 80s 1ms/step - loss: 0.0207 - acc: 0.9935 - val_loss: 0.0316 - val_acc: 0.9910\n",
            "Epoch 9/20\n",
            "60000/60000 [==============================] - 79s 1ms/step - loss: 0.0173 - acc: 0.9943 - val_loss: 0.0373 - val_acc: 0.9901\n",
            "Epoch 10/20\n",
            "60000/60000 [==============================] - 79s 1ms/step - loss: 0.0160 - acc: 0.9948 - val_loss: 0.0321 - val_acc: 0.9911\n",
            "Epoch 11/20\n",
            "60000/60000 [==============================] - 78s 1ms/step - loss: 0.0148 - acc: 0.9950 - val_loss: 0.0309 - val_acc: 0.9920\n",
            "Epoch 12/20\n",
            "60000/60000 [==============================] - 77s 1ms/step - loss: 0.0144 - acc: 0.9953 - val_loss: 0.0371 - val_acc: 0.9901\n",
            "Epoch 13/20\n",
            "60000/60000 [==============================] - 78s 1ms/step - loss: 0.0117 - acc: 0.9960 - val_loss: 0.0362 - val_acc: 0.9910\n",
            "Epoch 14/20\n",
            "60000/60000 [==============================] - 77s 1ms/step - loss: 0.0109 - acc: 0.9962 - val_loss: 0.0364 - val_acc: 0.9912\n",
            "Epoch 15/20\n",
            "60000/60000 [==============================] - 78s 1ms/step - loss: 0.0108 - acc: 0.9965 - val_loss: 0.0369 - val_acc: 0.9911\n",
            "Epoch 16/20\n",
            "60000/60000 [==============================] - 78s 1ms/step - loss: 0.0089 - acc: 0.9970 - val_loss: 0.0334 - val_acc: 0.9916\n",
            "Epoch 17/20\n",
            "60000/60000 [==============================] - 78s 1ms/step - loss: 0.0096 - acc: 0.9968 - val_loss: 0.0387 - val_acc: 0.9915\n",
            "Epoch 18/20\n",
            "60000/60000 [==============================] - 78s 1ms/step - loss: 0.0082 - acc: 0.9972 - val_loss: 0.0309 - val_acc: 0.9923\n",
            "Epoch 19/20\n",
            "60000/60000 [==============================] - 78s 1ms/step - loss: 0.0090 - acc: 0.9967 - val_loss: 0.0417 - val_acc: 0.9915\n",
            "Epoch 20/20\n",
            "60000/60000 [==============================] - 77s 1ms/step - loss: 0.0079 - acc: 0.9973 - val_loss: 0.0412 - val_acc: 0.9910\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f21899236d8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cou5vjqD6Zxd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "score = model.evaluate(X_test, Y_test, verbose=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YoAr4aZP6Zxm",
        "colab_type": "code",
        "outputId": "19a34dfc-840e-4dec-a85e-043e1b1548c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(score)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.041218858633232276, 0.991]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qepwp6fw6Zxw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbgvlwX26Zx2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "layer_dict = dict([(layer.name, layer) for layer in model.layers])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcsjvJEN6Zx_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from keras import backend as K\n",
        "%matplotlib inline\n",
        "# util function to convert a tensor into a valid image\n",
        "def deprocess_image(x):\n",
        "    # normalize tensor: center on 0., ensure std is 0.1\n",
        "    x -= x.mean()\n",
        "    x /= (x.std() + 1e-5)\n",
        "    x *= 0.1\n",
        "\n",
        "    # clip to [0, 1]\n",
        "    x += 0.5\n",
        "    x = np.clip(x, 0, 1)\n",
        "\n",
        "    # convert to RGB array\n",
        "    x *= 255\n",
        "    #x = x.transpose((1, 2, 0))\n",
        "    x = np.clip(x, 0, 255).astype('uint8')\n",
        "    return x\n",
        "\n",
        "def vis_img_in_filter(img = np.array(X_train[3]).reshape((1, 28, 28, 1)).astype(np.float64), \n",
        "                      layer_name = 'conv2d_1'):\n",
        "    layer_output = layer_dict[layer_name].output\n",
        "    img_ascs = list()\n",
        "    for filter_index in range(layer_output.shape[3]):\n",
        "        # build a loss function that maximizes the activation\n",
        "        # of the nth filter of the layer considered\n",
        "        loss = K.mean(layer_output[:, :, :, filter_index])\n",
        "\n",
        "        # compute the gradient of the input picture wrt this loss\n",
        "        grads = K.gradients(loss, model.input)[0]\n",
        "\n",
        "        # normalization trick: we normalize the gradient\n",
        "        grads /= (K.sqrt(K.mean(K.square(grads))) + 1e-5)\n",
        "\n",
        "        # this function returns the loss and grads given the input picture\n",
        "        iterate = K.function([model.input], [loss, grads])\n",
        "\n",
        "        # step size for gradient ascent\n",
        "        step = 5.\n",
        "\n",
        "        img_asc = np.array(img)\n",
        "        # run gradient ascent for 20 steps\n",
        "        for i in range(20):\n",
        "            loss_value, grads_value = iterate([img_asc])\n",
        "            img_asc += grads_value * step\n",
        "\n",
        "        img_asc = img_asc[0]\n",
        "        img_ascs.append(deprocess_image(img_asc).reshape((28, 28)))\n",
        "        \n",
        "    if layer_output.shape[3] >= 35:\n",
        "        plot_x, plot_y = 6, 6\n",
        "    elif layer_output.shape[3] >= 23:\n",
        "        plot_x, plot_y = 4, 6\n",
        "    elif layer_output.shape[3] >= 11:\n",
        "        plot_x, plot_y = 2, 6\n",
        "    else:\n",
        "        plot_x, plot_y = 1, 2\n",
        "    fig, ax = plt.subplots(plot_x, plot_y, figsize = (12, 12))\n",
        "    ax[0, 0].imshow(img.reshape((28, 28)), cmap = 'gray')\n",
        "    ax[0, 0].set_title('Input image')\n",
        "    fig.suptitle('Input image and %s filters' % (layer_name,))\n",
        "    fig.tight_layout(pad = 0.3, rect = [0, 0, 0.9, 0.9])\n",
        "    for (x, y) in [(i, j) for i in range(plot_x) for j in range(plot_y)]:\n",
        "        if x == 0 and y == 0:\n",
        "            continue\n",
        "        ax[x, y].imshow(img_ascs[x * plot_y + y - 1], cmap = 'gray')\n",
        "        ax[x, y].set_title('filter %d' % (x * plot_y + y - 1))\n",
        "\n",
        "vis_img_in_filter()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fV4Crrc86ZyH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}