# -*- coding: utf-8 -*-
"""ModelTrainTest.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gzcHzd5b9bu_7ZC-9dAocynBGlRP-gCj
"""



# Commented out IPython magic to ensure Python compatibility.
#%matplotlib inline
from tqdm import tqdm
import matplotlib.pyplot as plt
import numpy as np
import torch.nn.functional as F
import torch
import torch.nn as nn
import utils as utils
from sklearn.metrics import accuracy_score as jsc

def train(model, criterion, device, trainloader, optimizer, epoch):
    model.train()
    pbar = tqdm(trainloader)
    for batch_idx, (data, bg, target, target2) in enumerate(pbar):
        bgfg = data.to(device)
        bg = bg.to(device)
        # data["mask"] = data["mask"].to(device)
        depth = target.to(device)
        # print('depth shape:',depth.shape)
        mask = target2.to(device)
        #print(depth.shape)
        # print('mask shape:',mask.shape)
        optimizer.zero_grad()
        z = torch.cat([bgfg, bg], dim=1)
        output = model(z)
        output1 = output[0]
        output2 = output[1]
        loss1 = criterion(output1, mask)
        loss2 = criterion(output2, depth)
        loss = 2 * loss1 + loss2
        # print('loss: {}'.format(loss))
        print('\nEpoch:', epoch)
        if (batch_idx % 200 == 0) and (epoch == 13):
            pbar.set_description(desc="Total Loss={:.4f} Mask loss={:.2f} Depth loss={:.2f}".format(loss.item(), loss1.item(), loss2.item()))
        #    pbar.set_description(desc="Total Loss={:.4f} Mask loss={:.2f} Depth loss={:.2f}".format(loss.item(), loss1.item(),loss2.item()))
        # pbar.set_description(desc= "Overall Loss={:.4f} Mask loss={:.2f} Depth loss={:.2f}".format(loss.item(),loss1.item(), loss2.item()))
        loss.backward()
        optimizer.step()
        # print('Optimizer step completed')
        # print('batch_idx: {}'.format(batch_idx))
        # plt.imshow( output[1].detach().cpu().permute(1, 2, 0)  )
        # plt.imshow(output[1].detach().cpu().squeeze(), cmap='gray')
        # plt.imshow(data['mask'][0].detach().cpu().squeeze(), cmap='gray')
        # reshape to channel first:
        # plot_img_array(output1)
        # output1 = output2.data.cpu().numpy()
        # print('output1 shape:',output1.shape)
        # np.array(Image.fromarray((output1 * 255).astype(np.uint8)).resize((224, 224)).convert('RGB')
        # pred_rgb = Image.fromarray((output1 * 255).astype(np.uint8),mode='RGBA')
        # im1 = pred_rgb.save("test1.png")
        # output1 = output1.permute(0, 2, 3, 1)
        # print('output1..perumtted shape:',output1.shape)
        # im1.show()
        # print(pred_rgb.shape)
        # pred_rgb = [masks_to_colorimg(x) for x in output1]
        # tensor_image1=output1
        # tensor_image1 = tensor_image1.view(tensor_image1.shape[2], tensor_image1.shape[0], tensor_image1.shape[1])
        # print(type(tensor_image1), tensor_image1.shape)

        # If you try to plot image with shape (C, H, W)
        # You will get TypeError:
        # plt.imshow(tensor_image)

        # So we need to reshape it to (H, W, C):
        # tensor_image1 = output1.view(output1.shape[1], output1.shape[2], output1.shape[3])
        # print(type(tensor_image1), tensor_image1.shape)

        # plt.imshow(tensor_image1.detach().cpu())
        # plt.show()
        # show(output1)
        # show(output2)

        if batch_idx % 10 == 0:
            torch.cuda.empty_cache()


def test(model, criterion, device, test_loader, epoch,last_epoch=1,prnt=100):
    model.eval()
    validation_loss = []
    mask_loss = []
    depth_loss = []
    iou_score_overall = []
    loss1 = 0
    loss2 = 0
    correct = 0
    i = 0
    with torch.no_grad():
        for bgfg, bg, depthtgt, masktgt in test_loader:
            bgfg = bgfg.to(device)
            bg = bg.to(device)
            depth = depthtgt.to(device)
            mask = masktgt.to(device)
            # print('mask shape:',mask.shape)
            z = torch.cat([bgfg, bg], dim=1)
            output = model(z)
            maskop = output[0]
            depthop = output[1]
            ioumask = iou_pytorch(maskop, mask)
            ioudepth = iou_pytorch(depthop, depth)
            #print('ioumask:', ioumask)
            #print('ioudepth:', ioudepth)

            loss1 = criterion(maskop, mask).item()
            loss2 = criterion(depthop, depth).item()
            test_loss = 2 * loss1 + loss2
            validation_loss.append(test_loss)
            mask_loss.append(loss1)
            depth_loss.append(loss2)
            # lbl = mask.cpu().numpy().reshape(-1)
            # predictedop = maskop.cpu().numpy().reshape(-1)
            # union = np.logical_or(mask.cpu(), maskop.cpu())
            # print('union',union)
            # intersection = np.logical_and(mask.cpu(), maskop.cpu())
            # print('intersection',intersection)
            # iou_score = np.sum(intersection) / np.sum(union)
            # iou_score_overall.append(iou_score)
            i = i + 1
            if (i % prnt == 0):
                print('inside save plot')
                utils.saveplot(maskop.detach().cpu(), '/content/drive/My Drive/EVA4/S15/output_run2_full_20epochs/run_3/' + str(epoch) + '_' + str(i) + '_predicted_mask.jpg')
                utils.saveplot(mask.detach().cpu(), '/content/drive/My Drive/EVA4/S15/output_run2_full_20epochs/run_3/' + str(epoch) + '_' + str(i) + '_actual_mask.jpg')
                utils.saveplot(depthop.detach().cpu(), '/content/drive/My Drive/EVA4/S15/output_run2_full_20epochs/run_3/' + str(epoch) + '_' + str(i) + '_predicted_depth.png')
                utils.saveplot(depth.detach().cpu(), '/content/drive/My Drive/EVA4/S15/output_run2_full_20epochs/run_3/' + str(epoch) + '_' + str(i) + '_actual_depth.jpg')
                utils.saveplot(bgfg.detach().cpu(), '/content/drive/My Drive/EVA4/S15/output_run2_full_20epochs/run_3/' + str(epoch) + '_' + str(i) + '_actual_bg_fg.jpg')

            # test_loss = len(test_loader.dataset)
            # loss1 /= len(test_loader.dataset)
            # loss2 /= len(test_loader.dataset)
            # print('Test loss:',test_loss)
            if i == 374 and epoch == last_epoch:
                #utils.show(maskop)
                #utils.show(depthop)
                torch.save(model.state_dict(), '/content/drive/My Drive/EVA4/S15/output_run2_full_20epochs/run_3/model/'+str(epoch)+ '_' + str(i) + '.pth')
        print('\nTest set: Avg loss: {:.4f}, Mask Loss: {:.2f}, Depth Loss: {:.2f}\n'.format(np.mean(test_loss),
                                                                                             np.mean(mask_loss),
                                                                                             np.mean(depth_loss)))
        # print('\nTest set: Mean IoU Score: {:.2f}\n'.format(np.mean(iou_score_overall)))

def train_unet(model, criterion, device, trainloader, optimizer, epoch):
    model.train()
    pbar = tqdm(trainloader)
    for batch_idx, (data, bg, target, target2) in enumerate(pbar):
        bgfg = data.to(device)
        bg = bg.to(device)
        # data["mask"] = data["mask"].to(device)
        depth = target.to(device)
        # print('depth shape:',depth.shape)
        mask = target2.to(device)
        #print(depth.shape)
        # print('mask shape:',mask.shape)
        optimizer.zero_grad()
        z = torch.cat([bgfg, bg], dim=1)
        output = model(z)
        output1 = output[0]
        output2 = output[1]
        loss1 = criterion(output1, mask)
        loss2 = criterion(output2, depth)
        if(epoch <= 2):
            loss = loss1
        else:
            loss=loss2
        # print('loss: {}'.format(loss))
        print('\nEpoch:', epoch)
        if (batch_idx % 200 == 0) and (epoch == 13):
            pbar.set_description(desc="Total Loss={:.4f} Mask loss={:.2f} Depth loss={:.2f}".format(loss.item(), loss1.item(), loss2.item()))
        #    pbar.set_description(desc="Total Loss={:.4f} Mask loss={:.2f} Depth loss={:.2f}".format(loss.item(), loss1.item(),loss2.item()))
        # pbar.set_description(desc= "Overall Loss={:.4f} Mask loss={:.2f} Depth loss={:.2f}".format(loss.item(),loss1.item(), loss2.item()))
        loss.backward()
        optimizer.step()
        # print('Optimizer step completed')
        # print('batch_idx: {}'.format(batch_idx))
        # plt.imshow( output[1].detach().cpu().permute(1, 2, 0)  )
        # plt.imshow(output[1].detach().cpu().squeeze(), cmap='gray')
        # plt.imshow(data['mask'][0].detach().cpu().squeeze(), cmap='gray')
        # reshape to channel first:
        # plot_img_array(output1)
        # output1 = output2.data.cpu().numpy()
        # print('output1 shape:',output1.shape)
        # np.array(Image.fromarray((output1 * 255).astype(np.uint8)).resize((224, 224)).convert('RGB')
        # pred_rgb = Image.fromarray((output1 * 255).astype(np.uint8),mode='RGBA')
        # im1 = pred_rgb.save("test1.png")
        # output1 = output1.permute(0, 2, 3, 1)
        # print('output1..perumtted shape:',output1.shape)
        # im1.show()
        # print(pred_rgb.shape)
        # pred_rgb = [masks_to_colorimg(x) for x in output1]
        # tensor_image1=output1
        # tensor_image1 = tensor_image1.view(tensor_image1.shape[2], tensor_image1.shape[0], tensor_image1.shape[1])
        # print(type(tensor_image1), tensor_image1.shape)

        # If you try to plot image with shape (C, H, W)
        # You will get TypeError:
        # plt.imshow(tensor_image)

        # So we need to reshape it to (H, W, C):
        # tensor_image1 = output1.view(output1.shape[1], output1.shape[2], output1.shape[3])
        # print(type(tensor_image1), tensor_image1.shape)

        # plt.imshow(tensor_image1.detach().cpu())
        # plt.show()
        # show(output1)
        # show(output2)

        if batch_idx % 10 == 0:
            torch.cuda.empty_cache()


def test_unet(model, criterion, device, test_loader, epoch,last_epoch=1,prnt=100):
    model.eval()
    validation_loss = []
    mask_loss = []
    depth_loss = []
    iou_score_overall = []
    loss1 = 0
    loss2 = 0
    correct = 0
    i = 0
    with torch.no_grad():
        for bgfg, bg, depthtgt, masktgt in test_loader:
            bgfg = bgfg.to(device)
            bg = bg.to(device)
            depth = depthtgt.to(device)
            mask = masktgt.to(device)
            # print('mask shape:',mask.shape)
            z = torch.cat([bgfg, bg], dim=1)
            output = model(z)
            maskop = output[0]
            depthop = output[1]
            ioumask = iou_pytorch(maskop, mask)
            ioudepth = iou_pytorch(depthop, depth)
            #print('ioumask:', ioumask)
            #print('ioudepth:', ioudepth)

            loss1 = criterion(maskop, mask).item()
            loss2 = criterion(depthop, depth).item()
            #test_loss = 2 * loss1 + loss2
            if (epoch <= 2):
                test_loss = loss1
            else:
                test_loss = loss2

            validation_loss.append(test_loss)
            mask_loss.append(loss1)
            depth_loss.append(loss2)
            # lbl = mask.cpu().numpy().reshape(-1)
            # predictedop = maskop.cpu().numpy().reshape(-1)
            # union = np.logical_or(mask.cpu(), maskop.cpu())
            # print('union',union)
            # intersection = np.logical_and(mask.cpu(), maskop.cpu())
            # print('intersection',intersection)
            # iou_score = np.sum(intersection) / np.sum(union)
            # iou_score_overall.append(iou_score)
            i = i + 1
            if (i % prnt == 0) and (epoch <=2):
                utils.saveplot(maskop.detach().cpu(), '/content/drive/My Drive/EVA4/S15/unet_run/' + str(epoch) + '_' + str(i) + '_predicted_mask.jpg')
                utils.saveplot(mask.detach().cpu(), '/content/drive/My Drive/EVA4/S15/unet_run/' + str(epoch) + '_' + str(i) + '_actual_mask.jpg')
                utils.saveplot(bgfg.detach().cpu(), '/content/drive/My Drive/EVA4/S15/unet_run/' + str(epoch) + '_' + str(i) + '_actual_bg_fg.jpg')
            elif (i % prnt == 0) and (epoch > 2):
                utils.saveplot(depthop.detach().cpu(),  '/content/drive/My Drive/EVA4/S15/unet_run/' + str(epoch) + '_' + str(i) + '_predicted_depth.jpg')
                utils.saveplot(depth.detach().cpu(),'/content/drive/My Drive/EVA4/S15/unet_run/' + str(epoch) + '_' + str(i) + '_actual_depth.jpg')
                utils.saveplot(bgfg.detach().cpu(), '/content/drive/My Drive/EVA4/S15/unet_run/' + str(epoch) + '_' + str(i) + '_actual_bg_fg.jpg')
            # test_loss = len(test_loader.dataset)
            # loss1 /= len(test_loader.dataset)
            # loss2 /= len(test_loader.dataset)
            # print('Test loss:',test_loss)

        print('\nTest set: Avg loss: {:.4f}, Mask Loss: {:.2f}, Depth Loss: {:.2f}\n'.format(np.mean(test_loss),
                                                                                             np.mean(mask_loss),
                                                                                             np.mean(depth_loss)))
        # print('\nTest set: Mean IoU Score: {:.2f}\n'.format(np.mean(iou_score_overall)))




SMOOTH = 1e-6


def iou_pytorch1(outputs: torch.Tensor, labels: torch.Tensor):
    # You can comment out this line if you are passing tensors of equal shape
    # But if you are passing output from UNet or something it will most probably
    # be with the BATCH x 1 x H x W shape
    outputs = outputs.squeeze(1)  # BATCH x 1 x H x W => BATCH x H x W

    intersection = (outputs & labels).float().sum((1, 2))  # Will be zero if Truth=0 or Prediction=0
    union = (outputs | labels).float().sum((1, 2))  # Will be zzero if both are 0

    iou = (intersection + SMOOTH) / (union + SMOOTH)  # We smooth our devision to avoid 0/0

    thresholded = torch.clamp(20 * (iou - 0.5), 0, 10).ceil() / 10  # This is equal to comparing with thresolds

    return thresholded  # Or thresholded.mean() if you are interested in average across the batch


# Numpy version
# Well, it's the same function, so I'm going to omit the comments

def iou_pytorch(outputs, labels):
    outputs = outputs.squeeze(1)
    outputs = outputs.detach().cpu().numpy()
    labels = labels.detach().cpu().numpy()
    intersection = np.sum(np.logical_and(outputs, labels))
    union = np.sum(np.logical_or(outputs, labels))

    iou = (intersection + SMOOTH) / (union + SMOOTH)
    iou = iou.mean()
    thresholded = np.ceil(np.clip(20 * (iou - 0.5), 0, 10)) / 10

    return thresholded.mean()


def dice_coeff(pred, target, smooth=1.):
    pred = pred.contiguous()
    target = target.contiguous()

    intersection = (pred * target).sum(dim=2).sum(dim=2)

    iou = intersection / ((pred.sum(dim=2).sum(dim=2) + target.sum(dim=2).sum(dim=2)) - intersection)
    # losstensor=torch.abs(loss)
    coeff = iou.mean().item()
    return coeff


def calculate_iou(pred, target, smooth=100):
    # pred = pred.contiguous()
    # target = target.contiguous()
    pred = pred.detach().cpu()
    target = target.detach().cpu()
    intersection = np.sum(np.absolute(pred * target), axis=-1)
    sum = np.sum((np.absolute(pred) + np.absolute(target)), axis=-1)
    union = sum - intersection
    iouscore = (intersection + smooth) / (union + smooth)
    return iouscore